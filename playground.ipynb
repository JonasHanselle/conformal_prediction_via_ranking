{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "import openml\n",
    "from simple_model import DyadOneHotPairDataset, DyadRankingModel, create_dyads, ConformalPredictor, ConformalRankingPredictor, MCDyadOneHotPairDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(35)\n",
    "X, y, _, _ = dataset.get_data(\n",
    "    target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "# Automatically identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(\n",
    "    include=[\"object\", \"category\"]\n",
    ").columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Preprocessing for numerical data: Impute missing values, then scale\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocessing for categorical data: Impute missing values, then one-hot encode\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "if not isinstance(X_train, np.ndarray):\n",
    "    X_train = X_train.toarray()\n",
    "if not isinstance(y_train, np.ndarray):\n",
    "    y_train = y_train.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training.\n",
      "Stopping training.\n"
     ]
    }
   ],
   "source": [
    "from simple_model import ClassifierModel, DyadRankingModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import log2, ceil\n",
    "\n",
    "# clf = ClassifierModel(input_dim = X_train.shape[1], hidden_dim=16, output_dim=y.max()+1)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "clf = ClassifierModel(input_dim=X_train.shape[1], hidden_dim=16, output_dim=num_classes)\n",
    "\n",
    "cp_net = ConformalPredictor(clf, alpha=0.05)\n",
    "cp_rf = ConformalPredictor(rf, alpha=0.05)\n",
    "\n",
    "crps = [ConformalRankingPredictor(num_classes=y_train.max()+1, alpha= 0.05) for i in range(4)]\n",
    "\n",
    "cp_net.fit(X_train, y_train, num_epochs=100, random_state=1, patience=8)\n",
    "cp_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "crps[0].fit(X_train,y_train, random_state=1, use_cross_isntance_data=False, num_epochs=100, patience=64)\n",
    "crps[1].fit(X_train,y_train, random_state=1, use_cross_isntance_data=True, num_epochs=100, patience=64, num_pairs=len(X_train))\n",
    "crps[2].fit(X_train,y_train, random_state=1, use_cross_isntance_data=True, num_epochs=100, patience=64, num_pairs=len(X_train)*(num_classes-1))\n",
    "crps[3].fit(X_train,y_train, random_state=1, use_cross_isntance_data=True, num_epochs=10000, patience=64, num_pairs=len(X_train)*(num_classes-1)*ceil(log2(len(X_train))))\n",
    "\n",
    "if not isinstance(X_test, np.ndarray):\n",
    "    X_test = X_test.toarray()\n",
    "if not isinstance(y_test, np.ndarray):\n",
    "    y_test = y_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)*(num_classes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9594594594594594\n",
      "Coverage 0.9459459459459459 efficiency 4.418918918918919\n",
      "\n",
      "\n",
      "Accuracy 0.33783783783783783\n",
      "Coverage 1.0 efficiency 5.621621621621622\n",
      "\n",
      "\n",
      "Accuracy 0.9594594594594594\n",
      "Coverage 0.9594594594594594 efficiency 1.0405405405405406\n",
      "\n",
      "\n",
      "Accuracy 0.33783783783783783\n",
      "Coverage 0.0 efficiency 0.0\n",
      "\n",
      "\n",
      "Accuracy 1.0\n",
      "Coverage 0.9594594594594594 efficiency 0.9594594594594594\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sets\n",
    "pred_sets_clf = cp_net.predict_set(X_test)\n",
    "pred_sets_rf = cp_rf.predict_set(X_test)\n",
    "\n",
    "def evaluate_method(method):\n",
    "    pred_sets = method.predict_set(X_test)\n",
    "    y_test_model = method.model.predict(X_test)\n",
    "    coverage = np.mean([y_test[i] in pred_sets[i] for i in range(len(y_test))])\n",
    "    efficiency = np.mean([len(pred_sets[i]) for i in range(len(y_test))])\n",
    "    print(f\"Accuracy {accuracy_score(y_test_model, y_test)}\")\n",
    "    print(f\"Coverage {coverage} efficiency {efficiency}\")\n",
    "\n",
    "# coverage_clf = np.mean([y_test[i] in pred_sets_clf[i] for i in range(len(y_test))])\n",
    "# efficiency_clf = np.mean([len(pred_sets_clf[i]) for i in range(len(y_test))])\n",
    "\n",
    "for crp in crps:\n",
    "    evaluate_method(crp)\n",
    "    print(\"\\n\")\n",
    "evaluate_method(cp_net)\n",
    "\n",
    "\n",
    "# print(f\"Coverage clf {coverage_clf} efficiency clf {efficiency_clf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 1, 2, 2, 2, 4, 3, 5, 2, 0, 4, 1, 3, 1, 1, 2, 0, 1, 0, 0, 0,\n",
       "       2, 0, 3, 5, 3, 3, 4, 1, 1, 0, 2, 0, 0, 0, 0, 4, 3, 1, 4, 1, 2, 2,\n",
       "       3, 4, 2, 3, 4, 4, 3, 3, 1, 0, 2, 1, 0, 0, 2, 1, 2, 3, 5, 0, 2, 4,\n",
       "       0, 1, 3, 3, 1, 0, 1, 3, 0, 0, 0, 5, 4, 4, 3, 4, 0, 3, 0, 2, 0, 4,\n",
       "       5, 4, 3, 2, 5, 4, 2, 0, 1, 1, 0, 0, 0, 0, 1, 3, 3, 0, 1, 0, 0, 2,\n",
       "       4, 3, 0, 0, 2, 5, 0, 4, 2, 3, 5, 2, 1, 1, 1, 1, 4, 1, 0, 0, 1, 0,\n",
       "       1, 4, 0, 1, 5, 0, 4, 0, 1, 2, 1, 0, 2, 0, 2, 0, 2, 1, 0, 2, 2, 1,\n",
       "       4, 0, 4, 2, 3, 1, 0, 0, 3, 0, 2, 2, 1, 0, 4, 0, 1, 3, 0, 1, 2, 1,\n",
       "       0, 5, 0, 4, 0, 1, 3, 0, 0, 5, 2, 0, 1, 3, 4, 0, 0, 1, 0, 5, 2, 4,\n",
       "       2, 0, 5, 0, 1, 4, 0, 4, 3, 1, 3, 2, 0, 4, 2, 3, 0, 0, 4, 2, 3, 0,\n",
       "       4, 2, 5, 2, 0, 5, 2, 3, 0, 1, 2, 3, 5, 1, 4, 2, 1, 0, 0, 4, 0, 2,\n",
       "       1, 3, 4, 0, 3, 5, 1, 1, 3, 0, 4, 2, 0, 0, 4, 4, 5, 2, 4, 0, 2, 0,\n",
       "       2, 4, 0, 0, 2, 0, 0, 0, 2, 4, 2, 1, 2, 2, 0, 2, 3, 0, 5, 3, 2, 0,\n",
       "       4, 4, 2, 2, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_model import MCDyadOneHotPairDataset, DyadOneHotPairDataset\n",
    "ds = DyadOneHotPairDataset(X, y, num_classes=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

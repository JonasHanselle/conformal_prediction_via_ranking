{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "import openml\n",
    "from simple_model import DyadOneHotPairDataset, DyadRankingModel, create_dyads, ConformalPredictor, ConformalRankingPredictor, MCDyadOneHotPairDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(41)\n",
    "X, y, _, _ = dataset.get_data(\n",
    "    target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "# Automatically identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(\n",
    "    include=[\"object\", \"category\"]\n",
    ").columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=3\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Preprocessing for numerical data: Impute missing values, then scale\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocessing for categorical data: Impute missing values, then one-hot encode\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (input): Linear(in_features=9, out_features=16, bias=True)\n",
       "  (hidden): Linear(in_features=16, out_features=6, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simple_model import ClassifierModel, DyadRankingModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# clf = ClassifierModel(input_dim = X_train.shape[1], hidden_dim=16, output_dim=y.max()+1)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "clf = ClassifierModel(input_dim=X_train.shape[1], hidden_dim=16, output_dim=num_classes)\n",
    "\n",
    "cp = ConformalPredictor(clf, alpha=0.05)\n",
    "\n",
    "if not isinstance(X_train, np.ndarray):\n",
    "    X_train = X_train.to_numpy()\n",
    "if not isinstance(y_train, np.ndarray):\n",
    "    y_train = y_train.to_numpy()\n",
    "if not isinstance(X_test, np.ndarray):\n",
    "    X_test = X_test.to_numpy()\n",
    "if not isinstance(y_test, np.ndarray):\n",
    "    y_test = y_test.to_numpy()\n",
    "\n",
    "clf\n",
    "cp.fit(X_train, y_train, num_epochs=1000, random_state=1, patience=64)\n",
    "pred_sets_clf = cp.predict_set(X_test)\n",
    "\n",
    "crp = ConformalRankingPredictor(num_classes=y_train.max()+1, alpha= 0.05)\n",
    "crp.fit(X_train,y_train, random_state=1, use_cross_isntance_data=True, num_epochs=1000, patience=64)\n",
    "\n",
    "pred_sets_rnk = crp.predict_set(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.model.gradient_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy clf 0.11627906976744186\n",
      "Accuracy rf 0.11627906976744186\n",
      "Accuracy rnk 0.37209302325581395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not isinstance(X_test, np.ndarray):\n",
    "    X_test = X_test.to_numpy()\n",
    "if not isinstance(y_test, np.ndarray):\n",
    "    y_test = y_test.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "coverage_clf = np.mean([y_test[i] in pred_sets_clf[i] for i in range(len(y_test))])\n",
    "efficiency_clf = np.mean([len(pred_sets_clf[i]) for i in range(len(y_test))])\n",
    "\n",
    "# coverage_rnk = np.mean([y_test[i] in pred_sets_rnk[i] for i in range(len(y_test))])\n",
    "# efficiency_rnk = np.mean([len(pred_sets_rnk[i]) for i in range(len(y_test))])\n",
    "y_test_clf = cp.model.predict(X_test)\n",
    "y_test_rnk = crp.model.predict(X_test)\n",
    "y_test_rf = rf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy clf {accuracy_score(y_test_clf, y_test)}\")\n",
    "print(f\"Accuracy rf {accuracy_score(y_test_rf, y_test)}\")\n",
    "print(f\"Accuracy rnk {accuracy_score(y_test_rnk, y_test)}\")\n",
    "\n",
    "# print(f\"Coverage clf {coverage_clf} efficiency clf {efficiency_clf}\")\n",
    "# print(f\"Coverage rnk {coverage_rnk} efficiency rnk {efficiency_rnk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 3, 3, 2, 3, 0, 3, 1, 1, 0,\n",
       "       2, 2, 1, 4, 1, 0, 5, 3, 1, 0, 1, 2, 5, 0, 4, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.sum(X, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_model import MCDyadOneHotPairDataset, DyadOneHotPairDataset\n",
    "ds = DyadOneHotPairDataset(X, y, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 0.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [1., 1., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for x in ds:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [1., 1., 0., 1., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 0.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [0., 1., 1., 0., 0.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [1., 1., 0., 1., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [1., 1., 0., 1., 0.]])\n",
      "tensor([[1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [1., 1., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds_mc = MCDyadOneHotPairDataset(X, y, num_classes=3, num_pairs=-1)\n",
    "for x in ds_mc:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from simple_model import TabularDataset\n",
    "random_state = 1\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_classes=5, n_informative=5)\n",
    "dataset = TabularDataset(X, y)\n",
    "gen = torch.Generator().manual_seed(random_state)\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [1 - 1/3, 1/3], generator=gen\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for input, labels in train_loader:\n",
    "    print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from simple_model import TabularDataset\n",
    "from math import ceil, log2\n",
    "random_state = 1\n",
    "num_classes=5\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_classes=num_classes, n_informative=5)\n",
    "num_pairs = ceil(len(X_train) * log2(len(X_train)) * num_classes)\n",
    "dataset = MCDyadOneHotPairDataset(X, y,num_classes=num_classes,num_pairs=num_pairs, random_state=random_state)\n",
    "gen = torch.Generator().manual_seed(random_state)\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [1 - 1/3, 1/3], generator=gen\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for x in train_loader:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

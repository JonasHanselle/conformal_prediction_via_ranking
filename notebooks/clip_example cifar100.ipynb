{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\cp_rank\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoProcessor, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\cp_rank\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jonas\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from zmq import device\n",
    "\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(\"cuda\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # CLIP expects 224x224 images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])  # CLIP normalization\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "cifar_data_train = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "cifar_data_test = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "calib_data = Subset(cifar_data_train, range(1000))  # for demonstration purposes\n",
    "# train_data = Subset(cifar_data, range(250,1000))  # for demonstration purposes\n",
    "# test_data = Subset(cifar_data_test, range(2000))\n",
    "test_data = cifar_data_test\n",
    "calib_loader = DataLoader(calib_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = cifar_data_train.classes  # CIFAR-10 class names\n",
    "text_inputs = processor(text=class_names, return_tensors=\"pt\", padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\cp_rank\\Lib\\site-packages\\torch\\utils\\_device.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.368732452392578, 26.452966690063477, 25.229278564453125, 25.598283767700195, 25.935531616210938, 27.184476852416992, 26.504697799682617, 29.575803756713867, 28.322383880615234, 28.204208374023438, 24.665494918823242, 25.596296310424805, 27.46965217590332, 28.72529411315918, 26.64809799194336, 28.156179428100586, 25.208477020263672, 27.227535247802734, 28.48607635498047, 29.22666358947754, 29.37409210205078, 26.907634735107422, 23.374475479125977, 25.624265670776367, 24.328384399414062, 28.5148983001709, 26.394155502319336, 25.76992416381836, 29.074817657470703, 21.481353759765625, 24.412639617919922, 27.268293380737305, 28.223346710205078, 25.43918228149414, 29.101478576660156, 25.410106658935547, 27.693742752075195, 27.118778228759766, 26.9343204498291, 25.910694122314453, 27.50600814819336, 27.50728416442871, 27.578697204589844, 29.839933395385742, 27.475521087646484, 28.36693000793457, 27.00468635559082, 24.789363861083984, 26.871427536010742, 24.7781925201416, 25.733720779418945, 29.295848846435547, 28.715595245361328, 29.278549194335938, 27.90549087524414, 25.445255279541016, 25.919918060302734, 28.49530601501465, 26.602523803710938, 27.415943145751953, 25.22004508972168, 26.838916778564453, 26.30678367614746, 23.838685989379883, 28.915679931640625, 25.761404037475586, 26.08875274658203, 25.5093936920166, 29.588634490966797, 27.13821029663086, 26.231380462646484, 28.10160255432129, 24.30982208251953, 23.39986801147461, 23.764171600341797, 27.978906631469727, 26.395893096923828, 26.63673210144043, 26.226871490478516, 26.172388076782227, 27.360979080200195, 25.863269805908203, 28.013492584228516, 29.3980770111084, 26.872236251831055, 29.212743759155273, 28.9252872467041, 29.093435287475586, 24.54158592224121, 26.94643783569336, 24.86651611328125, 27.02457618713379, 26.82832145690918, 25.187551498413086, 26.44523048400879, 28.878063201904297, 27.37615394592285, 25.072824478149414, 28.16687774658203, 26.437419891357422, 26.961692810058594, 27.167552947998047, 27.801183700561523, 25.79202651977539, 28.01194190979004, 27.175548553466797, 28.050188064575195, 25.437332153320312, 28.925243377685547, 27.203645706176758, 28.543746948242188, 26.385679244995117, 26.833843231201172, 27.91565704345703, 27.606157302856445, 25.37154197692871, 24.20445442199707, 25.879159927368164, 27.139177322387695, 27.243852615356445, 28.16253662109375, 26.733272552490234, 27.028390884399414, 28.561798095703125, 28.211149215698242, 25.01572036743164, 24.970703125, 25.987422943115234, 27.820480346679688, 23.387645721435547, 23.56798553466797, 26.46879768371582, 24.90025520324707, 25.89154624938965, 28.934690475463867, 27.642431259155273, 27.99839973449707, 26.353078842163086, 27.810659408569336, 27.938711166381836, 28.884410858154297, 26.343048095703125, 25.464811325073242, 26.743820190429688, 29.37912940979004, 29.56385612487793, 25.166553497314453, 27.823505401611328, 29.03779411315918, 28.574260711669922, 26.716590881347656, 29.1481876373291, 27.476573944091797, 28.769346237182617, 22.005191802978516, 27.301448822021484, 26.685718536376953, 26.54436492919922, 27.923858642578125, 22.74618911743164, 28.40998077392578, 24.530550003051758, 25.951723098754883, 30.046791076660156, 23.15898895263672, 25.742889404296875, 22.644977569580078, 27.77300453186035, 26.53297996520996, 27.162166595458984, 27.597280502319336, 24.706790924072266, 29.76127815246582, 29.010751724243164, 26.763586044311523, 28.335861206054688, 26.637014389038086, 27.11789894104004, 28.64348602294922, 24.94129180908203, 29.715978622436523, 27.709897994995117, 27.444934844970703, 27.5732479095459, 28.759979248046875, 24.586915969848633, 26.979143142700195, 27.46424102783203, 28.61903953552246, 24.044742584228516, 26.815690994262695, 19.891727447509766, 26.66391944885254, 25.76774024963379, 29.827054977416992, 27.234216690063477, 26.54252052307129, 28.1286678314209, 30.018468856811523, 25.77730369567871, 26.88111114501953, 25.36550521850586, 28.951913833618164, 26.939136505126953, 25.567413330078125, 27.04203987121582, 26.965341567993164, 25.601970672607422, 24.74839973449707, 25.435739517211914, 27.944711685180664, 27.838882446289062, 28.155437469482422, 27.892812728881836, 27.884071350097656, 26.941850662231445, 26.420650482177734, 25.096723556518555, 25.886381149291992, 24.68800163269043, 27.532514572143555, 24.91367530822754, 26.169321060180664, 22.044580459594727, 23.956506729125977, 26.590383529663086, 26.92689323425293, 26.785999298095703, 26.720890045166016, 26.685199737548828, 26.649024963378906, 25.990116119384766, 26.910348892211914, 25.762378692626953, 24.167522430419922, 26.73111343383789, 26.7618350982666, 29.76728630065918, 27.042722702026367, 27.005788803100586, 26.320022583007812, 26.4854736328125, 26.645273208618164, 29.30078125, 26.904579162597656, 29.94824981689453, 27.141630172729492, 26.187225341796875, 26.497364044189453, 29.16131591796875, 27.73668098449707, 23.3837947845459, 26.77606964111328, 28.51959800720215, 28.728506088256836, 26.759464263916016, 29.173076629638672, 25.82468032836914, 24.968109130859375, 24.69703483581543, 27.807865142822266, 26.845476150512695, 27.190309524536133, 27.03365135192871, 25.744709014892578, 25.75001335144043, 26.315799713134766, 28.47127914428711, 27.92225456237793, 26.763851165771484, 25.587186813354492, 27.64006233215332, 29.849836349487305, 27.19881248474121, 26.433696746826172, 25.962203979492188, 26.597352981567383, 28.451705932617188, 26.796403884887695, 26.686351776123047, 27.96544647216797, 26.784622192382812, 28.174570083618164, 27.82205581665039, 24.81544303894043, 28.257291793823242, 28.615110397338867, 27.31655502319336, 25.20393943786621, 29.32003402709961, 23.99686050415039, 26.13580322265625, 29.310876846313477, 24.665699005126953, 29.074405670166016, 25.583574295043945, 24.279796600341797, 26.653675079345703, 28.242752075195312, 29.47466278076172, 25.797344207763672, 26.780303955078125, 27.554052352905273, 27.225143432617188, 27.241718292236328, 25.722536087036133, 24.67024803161621, 27.2707576751709, 27.266895294189453, 25.59412956237793, 24.133378982543945, 25.40190887451172, 26.433584213256836, 29.586755752563477, 27.838727951049805, 24.892858505249023, 29.059120178222656, 26.3118896484375, 29.126007080078125, 27.98818016052246, 29.392606735229492, 24.217741012573242, 27.839351654052734, 26.25762176513672, 26.9555721282959, 27.034860610961914, 30.372724533081055, 22.121440887451172, 26.42844581604004, 27.68000030517578, 28.664243698120117, 27.779821395874023, 25.783315658569336, 27.10167121887207, 27.910512924194336, 25.093183517456055, 30.160966873168945, 27.68060302734375, 27.464168548583984, 26.4597110748291, 29.588130950927734, 24.07405662536621, 24.979707717895508, 29.25360870361328, 26.228832244873047, 24.590850830078125, 29.339599609375, 25.183048248291016, 25.99027442932129, 27.557512283325195, 24.490854263305664, 25.239294052124023, 25.465810775756836, 25.46187973022461, 27.577194213867188, 29.49289321899414, 29.077356338500977, 28.730022430419922, 28.215211868286133, 28.610437393188477, 26.2056941986084, 25.803688049316406, 28.207555770874023, 29.924428939819336, 26.528728485107422, 27.53974723815918, 27.83063316345215, 26.847261428833008, 24.355749130249023, 29.437381744384766, 27.44101905822754, 25.80046272277832, 26.954442977905273, 26.268333435058594, 28.311813354492188, 26.628494262695312, 24.017507553100586, 26.86062240600586, 27.36739730834961, 25.174579620361328, 25.84320831298828, 28.86998748779297, 26.932483673095703, 28.63060760498047, 27.641698837280273, 22.97132682800293, 26.606945037841797, 26.06666374206543, 28.094985961914062, 27.923587799072266, 28.243844985961914, 28.31684112548828, 25.638797760009766, 22.668237686157227, 28.647777557373047, 27.78168296813965, 26.948272705078125, 24.719663619995117, 29.62750816345215, 26.80017852783203, 24.760208129882812, 24.623897552490234, 27.570619583129883, 27.82314682006836, 23.89552116394043, 26.381555557250977, 27.62627601623535, 25.303264617919922, 26.179969787597656, 28.39847183227539, 26.03411102294922, 27.108461380004883, 28.407520294189453, 28.449365615844727, 25.18858528137207, 26.318702697753906, 27.643835067749023, 23.524442672729492, 26.099035263061523, 26.85657501220703, 28.635961532592773, 26.63733673095703, 27.873144149780273, 24.92755126953125, 25.811874389648438, 29.366779327392578, 26.738300323486328, 25.673870086669922, 23.327035903930664, 24.657413482666016, 26.671070098876953, 27.935108184814453, 25.920501708984375, 28.178531646728516, 28.174135208129883, 24.499942779541016, 24.97494888305664, 26.21581268310547, 24.272485733032227, 25.243934631347656, 28.556591033935547, 26.94839859008789, 25.473155975341797, 27.453670501708984, 29.374921798706055, 26.187301635742188, 27.673208236694336, 22.12278938293457, 25.667957305908203, 28.834489822387695, 28.32853126525879, 24.843585968017578, 29.26526641845703, 26.23416519165039, 26.66236114501953, 23.83740234375, 25.4761905670166, 27.82561492919922, 29.214689254760742, 26.15496253967285, 25.42939567565918, 28.151649475097656, 26.46949577331543, 27.475933074951172, 24.72132110595703, 26.767879486083984, 25.681432723999023, 23.131248474121094, 27.31874656677246, 28.000625610351562, 26.461410522460938, 27.20441436767578, 26.692428588867188, 28.44659996032715, 24.72296714782715, 25.57695770263672, 26.64421844482422, 27.64333724975586, 29.008743286132812, 27.410911560058594, 27.978191375732422, 22.87677574157715, 25.71536636352539, 28.109115600585938, 28.748628616333008, 27.350204467773438, 26.32655143737793, 27.955856323242188, 27.88804817199707, 30.161588668823242, 26.982379913330078, 28.287399291992188, 27.050155639648438, 24.6032772064209, 27.98095703125, 26.89131736755371, 28.093427658081055, 26.193225860595703, 27.24132537841797, 27.55109977722168, 23.560758590698242, 25.312885284423828, 26.5203914642334, 26.9375057220459, 26.688518524169922, 28.40353775024414, 25.007530212402344, 28.406593322753906, 27.504146575927734, 27.91826629638672, 27.883264541625977, 28.08291244506836, 25.811782836914062, 27.635345458984375, 28.612380981445312, 28.50132942199707, 29.14290428161621, 27.768383026123047, 26.67935562133789, 25.14531707763672, 29.072471618652344, 28.4696102142334, 28.398609161376953, 26.873233795166016, 26.9966983795166, 28.179561614990234, 26.695589065551758, 26.992372512817383, 28.77425765991211, 25.568056106567383, 26.33255386352539, 29.54168701171875, 29.521936416625977, 27.25432586669922, 28.184324264526367, 27.713960647583008, 24.065549850463867, 27.732887268066406, 29.518890380859375, 29.07086944580078, 29.239898681640625, 27.151611328125, 27.467987060546875, 29.110193252563477, 25.666004180908203, 28.16600227355957, 24.169519424438477, 27.188995361328125, 27.19489097595215, 28.11879539489746, 29.0157470703125, 26.55912971496582, 27.277751922607422, 27.265363693237305, 26.472797393798828, 24.658063888549805, 27.194673538208008, 24.061824798583984, 28.233713150024414, 27.74307632446289, 27.233427047729492, 27.66230010986328, 25.532514572143555, 29.158634185791016, 26.953006744384766, 26.82015037536621, 26.90008544921875, 29.810806274414062, 27.60400390625, 25.378551483154297, 28.768795013427734, 23.753360748291016, 28.074932098388672, 27.894502639770508, 26.04594612121582, 30.137834548950195, 28.50007438659668, 28.36396026611328, 26.642396926879883, 26.258621215820312, 24.934131622314453, 30.014923095703125, 25.752517700195312, 26.439407348632812, 23.824222564697266, 28.984046936035156, 29.21796989440918, 28.762508392333984, 27.831100463867188, 23.868606567382812, 24.986345291137695, 26.754966735839844, 26.473907470703125, 25.67201805114746, 26.030540466308594, 29.497194290161133, 27.535179138183594, 23.770341873168945, 25.534778594970703, 26.241493225097656, 22.81566619873047, 26.38312530517578, 24.91245460510254, 22.671689987182617, 23.352249145507812, 24.2518253326416, 23.126585006713867, 25.894948959350586, 25.766584396362305, 27.252180099487305, 26.136350631713867, 28.051015853881836, 27.788639068603516, 26.883087158203125, 26.504981994628906, 27.579334259033203, 26.944828033447266, 27.806079864501953, 27.26774787902832, 25.749767303466797, 25.84163475036621, 20.48430061340332, 27.707305908203125, 28.33612060546875, 27.367076873779297, 27.00396728515625, 21.956037521362305, 25.940826416015625, 25.298954010009766, 27.988035202026367, 27.043851852416992, 23.446292877197266, 28.962989807128906, 23.354570388793945, 26.484331130981445, 26.602018356323242, 28.674089431762695, 25.975135803222656, 24.000152587890625, 26.143827438354492, 21.8167724609375, 27.21151351928711, 25.314823150634766, 28.806358337402344, 27.179584503173828, 29.226490020751953, 29.129430770874023, 24.52686882019043, 28.153276443481445, 24.777313232421875, 26.635541915893555, 27.85239601135254, 26.71455955505371, 29.02982521057129, 26.399564743041992, 28.797266006469727, 27.730693817138672, 26.789796829223633, 26.794675827026367, 26.289302825927734, 24.477113723754883, 29.243600845336914, 28.598833084106445, 24.727258682250977, 26.598846435546875, 29.228744506835938, 25.338830947875977, 22.16193389892578, 27.886125564575195, 26.60318946838379, 28.472126007080078, 28.945758819580078, 27.52082061767578, 26.606670379638672, 29.00139617919922, 27.507034301757812, 24.72430992126465, 28.928693771362305, 25.96108627319336, 27.961376190185547, 25.708276748657227, 28.475860595703125, 25.437911987304688, 26.206039428710938, 21.793567657470703, 25.924747467041016, 26.572275161743164, 26.5385799407959, 28.306106567382812, 22.9620304107666, 27.396244049072266, 26.85036277770996, 27.085861206054688, 29.006084442138672, 27.30203628540039, 24.717666625976562, 25.890302658081055, 24.427106857299805, 27.338844299316406, 27.843612670898438, 25.12795066833496, 28.125280380249023, 23.427732467651367, 26.27297019958496, 26.79067039489746, 28.393083572387695, 26.783859252929688, 27.802244186401367, 22.504728317260742, 28.584835052490234, 28.70948600769043, 26.6081485748291, 25.05269432067871, 22.297977447509766, 27.75634765625, 26.714134216308594, 28.235288619995117, 27.619171142578125, 26.411596298217773, 27.204524993896484, 28.02520179748535, 26.0556640625, 25.7747745513916, 23.648143768310547, 25.337800979614258, 22.48366928100586, 25.973283767700195, 27.453521728515625, 26.121801376342773, 27.3568058013916, 25.351869583129883, 24.26137351989746, 29.146760940551758, 27.897850036621094, 25.100452423095703, 26.650882720947266, 27.747547149658203, 24.809425354003906, 26.93283462524414, 29.746171951293945, 26.874452590942383, 24.83004379272461, 26.91448402404785, 26.92050552368164, 29.40269660949707, 24.58427619934082, 27.346006393432617, 24.488492965698242, 27.09819984436035, 26.360733032226562, 27.10823631286621, 27.53761100769043, 25.389375686645508, 22.926986694335938, 22.006511688232422, 26.560283660888672, 26.289913177490234, 27.61158561706543, 29.28873062133789, 29.18071746826172, 27.175861358642578, 26.898128509521484, 28.326152801513672, 27.329994201660156, 27.782306671142578, 28.780200958251953, 26.535276412963867, 27.216005325317383, 28.494728088378906, 26.371192932128906, 22.571117401123047, 26.863107681274414, 26.59071922302246, 25.963926315307617, 27.56122589111328, 25.214540481567383, 27.062583923339844, 26.332643508911133, 27.302860260009766, 29.079896926879883, 29.36806297302246, 25.02615737915039, 25.5340518951416, 25.4176025390625, 27.442228317260742, 24.300966262817383, 26.539793014526367, 28.66590118408203, 26.974952697753906, 28.559860229492188, 28.771018981933594, 25.573942184448242, 26.802513122558594, 26.057270050048828, 26.890039443969727, 28.245595932006836, 29.803943634033203, 28.56592559814453, 25.771028518676758, 26.078811645507812, 29.155853271484375, 24.041040420532227, 27.931774139404297, 27.09352684020996, 23.90726089477539, 25.72951889038086, 27.416748046875, 26.202524185180664, 29.376876831054688, 26.99872589111328, 23.24298667907715, 25.20592498779297, 23.21904754638672, 25.148406982421875, 28.577682495117188, 28.764225006103516, 28.61528968811035, 24.98797607421875, 26.617345809936523, 24.1099853515625, 27.20905876159668, 27.89328956604004, 25.633358001708984, 28.585344314575195, 24.11586570739746, 28.51482582092285, 27.331369400024414, 28.19223403930664, 22.831907272338867, 27.573978424072266, 28.678325653076172, 25.90090560913086, 25.50543785095215, 26.960674285888672, 26.78733253479004, 26.92306900024414, 25.6168212890625, 28.630191802978516, 29.004850387573242, 28.124927520751953, 26.31429100036621, 26.45752716064453, 29.336780548095703, 22.63097381591797, 26.82777976989746, 26.17620849609375, 27.31859588623047, 27.899450302124023, 27.034591674804688, 25.681804656982422, 23.503976821899414, 27.488189697265625, 27.039722442626953, 24.25060272216797, 29.536762237548828, 26.896337509155273, 28.847900390625, 28.279224395751953, 28.110641479492188, 26.60968017578125, 25.76838493347168, 27.176082611083984, 23.763551712036133, 26.472774505615234, 26.543859481811523, 27.889787673950195, 25.77001190185547, 26.893768310546875, 25.236215591430664, 25.9766902923584, 27.580341339111328, 25.275972366333008, 24.40165138244629, 25.888378143310547, 29.136844635009766, 27.6546573638916, 31.223960876464844, 28.596145629882812, 23.23785972595215, 27.612733840942383, 27.34629249572754, 27.16672134399414, 24.588558197021484, 27.84736442565918, 25.97252082824707, 28.382972717285156, 27.914825439453125, 30.01163673400879, 27.73206329345703, 26.06747055053711, 26.4857234954834, 25.379392623901367, 24.82208824157715, 28.136241912841797, 24.463123321533203, 26.313671112060547, 28.35839080810547, 28.054704666137695, 28.5673828125, 25.642623901367188, 24.794248580932617, 25.010141372680664, 27.101642608642578, 23.6991024017334, 26.830551147460938, 25.985795974731445, 25.375022888183594, 27.817535400390625, 27.099937438964844, 25.699275970458984, 27.27981185913086, 25.652647018432617, 28.167898178100586, 28.99869155883789, 25.530784606933594, 25.96694564819336, 28.70321273803711, 28.23779296875, 28.206512451171875, 28.398773193359375, 30.027324676513672, 28.70372200012207, 26.08918571472168, 25.218053817749023, 27.850082397460938, 27.900043487548828, 25.89328384399414, 21.766578674316406, 28.548309326171875, 27.974346160888672, 22.946531295776367, 25.765859603881836, 27.325435638427734, 29.008358001708984, 25.414566040039062, 29.744831085205078, 26.151857376098633, 24.976564407348633, 25.18845558166504, 25.100473403930664, 23.94683837890625, 24.38869857788086, 27.60329818725586, 29.295900344848633, 25.9582576751709, 28.411916732788086, 28.91058921813965, 28.167978286743164, 29.65967559814453, 27.275678634643555, 28.056293487548828, 26.88472557067871, 27.820486068725586, 27.28042221069336, 28.015037536621094, 24.4959774017334, 28.767391204833984, 28.6834774017334, 26.997148513793945, 29.473093032836914, 26.43274688720703, 26.79235076904297, 27.583181381225586, 23.19178009033203, 25.87683868408203, 24.913127899169922, 26.084930419921875, 25.64318084716797, 25.927946090698242, 28.16244125366211, 27.291378021240234, 26.51288604736328, 28.597911834716797, 25.90110969543457, 23.116605758666992, 27.385080337524414, 29.27202606201172, 28.833003997802734, 27.591049194335938, 25.284088134765625, 25.332460403442383, 27.038175582885742, 27.428800582885742, 27.243486404418945, 26.856609344482422, 26.830015182495117, 25.239818572998047, 26.006624221801758, 27.312002182006836, 24.177753448486328, 29.059627532958984, 27.98732566833496, 23.04108428955078, 25.3013916015625, 29.135725021362305, 24.967857360839844, 28.176265716552734, 27.22063636779785, 26.7971248626709, 29.612659454345703]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def denormalize(img: torch.Tensor, mean: torch.Tensor, std: torch.Tensor):\n",
    "    \"\"\"Denormalizes the image given the mean and standard deviation.\"\"\"\n",
    "    return img * torch.tensor(std, device=\"cpu\").view(3, 1, 1) + torch.tensor(mean, device=\"cpu\").view(3, 1, 1)\n",
    "\n",
    "# Forward pass through CLIP\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "scores = []\n",
    "\n",
    "# Compute nonconformity scores\n",
    "\n",
    "for images, labels in calib_loader:\n",
    "\n",
    "    pil_images = [transforms.ToPILImage()(denormalize(img, processor.image_processor.image_mean, processor.image_processor.image_std)) for img in images]\n",
    "    \n",
    "    # Process images using CLIP's processor (automatically normalizes them)\n",
    "    inputs = processor(images=pil_images, return_tensors=\"pt\").to(\"cuda\")\n",
    "    input_image_processed = inputs['pixel_values'].squeeze(0)\n",
    "\n",
    "    outputs = model(**inputs, **text_inputs)\n",
    "    logits_per_image = outputs.logits_per_image  # Image-to-text similarity scores\n",
    "    probs = logits_per_image.softmax(dim=1)  # Convert to probabilities\n",
    "    predictions = probs.argmax(dim=1)\n",
    "    all_labels.extend(labels.tolist())\n",
    "    all_predictions.extend(predictions.tolist())\n",
    "    scores += logits_per_image.take_along_dim(torch.tensor(labels).unsqueeze(-1),dim=1).squeeze().tolist()\n",
    "    \n",
    "\n",
    "\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.02\n",
      "accuracy =\t\t 0.8498\n",
      "coverage =\t\t 0.9797\n",
      "mean set size =\t\t 3.5607\n",
      "median set size =\t 3.0\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.05\n",
      "accuracy =\t\t 0.8498\n",
      "coverage =\t\t 0.9518\n",
      "mean set size =\t\t 2.4033\n",
      "median set size =\t 2.0\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.1\n",
      "accuracy =\t\t 0.8498\n",
      "coverage =\t\t 0.8904\n",
      "mean set size =\t\t 1.5704\n",
      "median set size =\t 1.0\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.2\n",
      "accuracy =\t\t 0.8498\n",
      "coverage =\t\t 0.7985\n",
      "mean set size =\t\t 1.0915\n",
      "median set size =\t 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "alphas = [0.02, 0.05, 0.1, 0.2]\n",
    "for alpha in alphas:\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"alpha =\\t\\t\\t {alpha}\")\n",
    "    # Compute the quantile for the nonconformity scores\n",
    "    n = len(scores)\n",
    "    threshold = np.quantile(scores, np.ceil((n+1)*(alpha))/n, method=\"inverted_cdf\")\n",
    "    prediction_sets = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        pil_images = [transforms.ToPILImage()(denormalize(img, processor.image_processor.image_mean, processor.image_processor.image_std)) for img in images]\n",
    "        \n",
    "        # Process images using CLIP's processor (automatically normalizes them)\n",
    "        inputs = processor(images=pil_images, return_tensors=\"pt\").to(\"cuda\")\n",
    "        input_image_processed = inputs['pixel_values'].squeeze(0)\n",
    "\n",
    "        outputs = model(**inputs, **text_inputs)\n",
    "        logits_per_image = outputs.logits_per_image  # Image-to-text similarity scores\n",
    "        probs = logits_per_image.softmax(dim=1)  # Convert to probabilities\n",
    "        predictions = probs.argmax(dim=1)\n",
    "        all_labels.extend(labels.tolist())\n",
    "        all_predictions.extend(predictions.tolist())\n",
    "        indices = (logits_per_image > threshold).nonzero(as_tuple=True)\n",
    "        row_indices = [indices[1][indices[0] == i] for i in range(logits_per_image.size(0))]\n",
    "        prediction_sets.extend(row_indices)\n",
    "\n",
    "    pred_sets = [x.tolist() for x in prediction_sets]\n",
    "    coverage = np.mean([all_labels[i] in pred_sets[i] for i in range(len(all_labels))])\n",
    "    avg_set_size = np.mean([len(s) for s in pred_sets])\n",
    "    median_set_size = np.median([len(s) for s in pred_sets])\n",
    "    acc_score = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"accuracy =\\t\\t {acc_score}\")\n",
    "    print(f\"coverage =\\t\\t {coverage}\")\n",
    "    print(f\"mean set size =\\t\\t {avg_set_size}\")\n",
    "    print(f\"median set size =\\t {median_set_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_rank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

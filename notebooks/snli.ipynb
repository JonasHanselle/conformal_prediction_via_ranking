{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No ranker config provided, no ranker loaded, please load ranker first through load_ranker()\n",
      "WARNING:root:No fuser config provided, no fuser loaded, please load fuser first through load_fuser()\n",
      "/home/ra43rid/torch_plnet/venv/lib/python3.10/site-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type load_checkpoint detected when decoding RankerConfig.\n",
      "  warnings.warn(\n",
      "/home/ra43rid/torch_plnet/venv/lib/python3.10/site-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type device detected when decoding RankerConfig.\n",
      "  warnings.warn(\n",
      "/home/ra43rid/torch_plnet/venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ranker from  /home/ra43rid/.cache/huggingface/hub/llm-blender/PairRM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import llm_blender\n",
    "blender = llm_blender.Blender()\n",
    "blender.loadranker(\"llm-blender/PairRM\", device=\"cuda\") # load PairRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# Load SNLI dataset\n",
    "ds = load_dataset(\"ag_news\").shuffle(seed=42)\n",
    "full_dataset = concatenate_datasets([ds[\"train\"], ds[\"test\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 127600\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = full_dataset.select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "Ranking candidates: 100%|██████████| 400/400 [02:20<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.02\n",
      "coverage =\t\t 0.99\n",
      "mean set size =\t\t 2.9675\n",
      "median set size =\t 3.0\n",
      "accuracy =\t 0.7875\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.05\n",
      "coverage =\t\t 0.94\n",
      "mean set size =\t\t 1.84\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7875\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.1\n",
      "coverage =\t\t 0.89\n",
      "mean set size =\t\t 1.425\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.7875\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.2\n",
      "coverage =\t\t 0.74\n",
      "mean set size =\t\t 0.99\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.7875\n",
      "Fold: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 100/100 [00:36<00:00,  2.75it/s]\n",
      "Ranking candidates: 100%|██████████| 400/400 [02:23<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.02\n",
      "coverage =\t\t 0.97\n",
      "mean set size =\t\t 2.2125\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7825\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.05\n",
      "coverage =\t\t 0.95\n",
      "mean set size =\t\t 1.76\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7825\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.1\n",
      "coverage =\t\t 0.85\n",
      "mean set size =\t\t 1.28\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.7825\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.2\n",
      "coverage =\t\t 0.8\n",
      "mean set size =\t\t 0.9625\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.7825\n",
      "Fold: 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "Ranking candidates: 100%|██████████| 400/400 [02:22<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.02\n",
      "coverage =\t\t 1.0\n",
      "mean set size =\t\t 3.6125\n",
      "median set size =\t 4.0\n",
      "accuracy =\t 0.7925\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.05\n",
      "coverage =\t\t 0.92\n",
      "mean set size =\t\t 1.8\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7925\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.1\n",
      "coverage =\t\t 0.88\n",
      "mean set size =\t\t 1.56\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7925\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.2\n",
      "coverage =\t\t 0.79\n",
      "mean set size =\t\t 1.0175\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.7925\n",
      "Fold: 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Ranking candidates: 100%|██████████| 400/400 [02:21<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.02\n",
      "coverage =\t\t 0.97\n",
      "mean set size =\t\t 2.29\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7975\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.05\n",
      "coverage =\t\t 0.96\n",
      "mean set size =\t\t 1.84\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7975\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.1\n",
      "coverage =\t\t 0.93\n",
      "mean set size =\t\t 1.6275\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.7975\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.2\n",
      "coverage =\t\t 0.85\n",
      "mean set size =\t\t 1.17\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.7975\n",
      "Fold: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "Ranking candidates: 100%|██████████| 400/400 [02:22<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.02\n",
      "coverage =\t\t 0.96\n",
      "mean set size =\t\t 2.27\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.78\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.05\n",
      "coverage =\t\t 0.91\n",
      "mean set size =\t\t 1.665\n",
      "median set size =\t 2.0\n",
      "accuracy =\t 0.78\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.1\n",
      "coverage =\t\t 0.86\n",
      "mean set size =\t\t 1.3625\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.78\n",
      "\n",
      "\n",
      "\n",
      "alpha =\t\t\t 0.2\n",
      "coverage =\t\t 0.8\n",
      "mean set size =\t\t 1.0025\n",
      "median set size =\t 1.0\n",
      "accuracy =\t 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "classes = [\"World\", \"Sports\", \"Business\", \"Science and Technology\"]\n",
    "\n",
    "# Extract labels\n",
    "y = dataset['label']  # Keeping it in Hugging Face format\n",
    "\n",
    "# Define K-Fold Cross-Validation\n",
    "k_folds = 5  # Change as needed\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "def compute_cal_scores(ds):\n",
    "    inputs = [f\"{x['text']}\" for x in ds]\n",
    "    candidates_texts = [[f\"The category is {x}\" for x in classes]]*len(inputs)\n",
    "    return blender.rank(inputs, candidates_texts, return_scores=True, batch_size=1)\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (test_idx, cal_idx) in enumerate(skf.split(range(len(dataset)), y)):\n",
    "    print(f\"Fold: {fold}\\n\")\n",
    "    test_dataset = dataset.select(test_idx)  # Get training subset\n",
    "    cal_dataset = dataset.select(cal_idx)    # Get test subset\n",
    "\n",
    "    labels_cal = [x[\"label\"] for x in cal_dataset]\n",
    "    labels_test = [x[\"label\"] for x in test_dataset]\n",
    "\n",
    "    cal_scores = compute_cal_scores(cal_dataset)\n",
    "    # take scores of true labels\n",
    "    cal_scores = cal_scores[np.arange(cal_scores.shape[0]), labels_cal]\n",
    "    pred_scores = compute_cal_scores(test_dataset)\n",
    "\n",
    "\n",
    "    alphas = [0.02, 0.05, 0.1, 0.2]\n",
    "    for alpha in alphas:\n",
    "        print(\"\\n\\n\")\n",
    "        print(f\"alpha =\\t\\t\\t {alpha}\")\n",
    "        n = len(cal_scores)\n",
    "        threshold = np.quantile(cal_scores.flatten(), np.ceil((n+1)*(alpha))/n, method=\"inverted_cdf\")\n",
    "        pred_sets = [np.where(row > threshold)[0].tolist() for row in pred_scores]\n",
    "        predictions = np.argmax(pred_scores, axis=1)\n",
    "        coverage = np.mean([labels_test[i] in pred_sets[i] for i in range(n)])\n",
    "        avg_set_size = np.mean([len(s) for s in pred_sets])\n",
    "        median_set_size = np.median([len(s) for s in pred_sets])\n",
    "        accuracy = accuracy_score(labels_test, predictions)\n",
    "        print(f\"coverage =\\t\\t {coverage}\")\n",
    "        print(f\"mean set size =\\t\\t {avg_set_size}\")\n",
    "        print(f\"median set size =\\t {median_set_size}\")\n",
    "        print(f\"accuracy =\\t {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llm_blender.blender.blender.Blender at 0x7fe6d81f8160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

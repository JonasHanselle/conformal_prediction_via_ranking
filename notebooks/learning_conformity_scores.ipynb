{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import torch\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "class MultinomialSyntheticDataGenerator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, random_state=None):\n",
    "        \"\"\"\n",
    "        A custom estimator for generating synthetic data using multinomial logistic regression,\n",
    "        with the feature distribution inferred from the training data.\n",
    "        \n",
    "        Parameters:\n",
    "        - n_samples (int): Number of synthetic samples to generate.\n",
    "        - random_state (int): Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits a multinomial logistic regression model to the data and estimates the feature distribution.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        - y (ndarray): Target labels of shape (n_samples,).\n",
    "        \n",
    "        Returns:\n",
    "        - self: The fitted instance.\n",
    "        \"\"\"\n",
    "        # Store mean and covariance of features\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.feature_mean_ = np.mean(X, axis=0)\n",
    "        self.feature_cov_ = np.cov(X, rowvar=False)\n",
    "        \n",
    "        # Fit a logistic regression model\n",
    "        self.model_ = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=self.random_state)\n",
    "        self.model_.fit(X, y)\n",
    "        \n",
    "        # Store the number of classes and features\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for the given feature matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - probabilities (ndarray): Predicted probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, \"model_\")\n",
    "        return self.model_.predict_proba(X)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for the given feature matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - probabilities (ndarray): Predicted probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, \"model_\")\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def generate(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, [\"model_\", \"feature_mean_\", \"feature_cov_\"])\n",
    "        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        X_synthetic = np.random.multivariate_normal(self.feature_mean_, self.feature_cov_, n)\n",
    "        \n",
    "        # Compute class probabilities\n",
    "        P_Y_given_X = self.predict_proba(X_synthetic)\n",
    "        \n",
    "        # Sample synthetic labels\n",
    "        y_synthetic = np.array([np.random.choice(self.n_classes_, p=probs) for probs in P_Y_given_X])\n",
    "        \n",
    "        return X_synthetic, y_synthetic\n",
    "\n",
    "\n",
    "    def generate_instances(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, [\"model_\", \"feature_mean_\", \"feature_cov_\"])\n",
    "        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = np.random.multivariate_normal(self.feature_mean_, self.feature_cov_, n)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleAnnotator:\n",
    "    def __init__(self,mapie_clf, generator):\n",
    "        self.mapie_clf = mapie_clf\n",
    "        self.classes_ = mapie_clf.classes_\n",
    "        self.generator = generator\n",
    "\n",
    "    def generate_pairs_in_instance(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        X = self.generator.generate_instances(n)\n",
    "        X = np.repeat(X, repeats=2, axis=0)\n",
    "\n",
    "        y = np.hstack([np.random.choice(self.classes_, size=2, replace=False) for _ in range(n)])\n",
    "\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "        return X_pairs, y_pairs\n",
    "\n",
    "\n",
    "    def generate_pairs_cross_instance(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = self.generator.generate_instances(2*n)\n",
    "        y = np.random.choice(self.classes_, size=2*n, replace=True)\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "\n",
    "        return X_pairs, y_pairs\n",
    "    \n",
    "    # def create_pairs_for_classification_data(self, X):\n",
    "    #     \"\"\"\n",
    "    #     Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "    #     Returns:\n",
    "    #     - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "    #     - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "    #     \"\"\"\n",
    "    #     # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "    #     X = self.generator.generate_instances(2*n)\n",
    "    #     y = np.random.choice(self.classes_, size=2*n, replace=True)\n",
    "    #     conformities = self.get_conformity(X,y)\n",
    "\n",
    "    #     X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "    #     y_rs = y.reshape(n,2)\n",
    "    #     conformities_n_rs = - conformities.reshape(n,2)\n",
    "    #     sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "    #     X_rs[sort_idx]\n",
    "    #     y_rs[sort_idx,:]\n",
    "    #     X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "    #     y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "\n",
    "        return X_pairs, y_pairs\n",
    "\n",
    "    # we assume y is already label encoded\n",
    "    def get_conformity(self, X, y):\n",
    "        y_pred_proba = self.mapie_clf.estimator.predict_proba(X)\n",
    "        scores = self.mapie_clf.conformity_score_function_.get_conformity_scores(\n",
    "                        y, y_pred_proba, y_enc=y\n",
    "                    )\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.classification import MapieClassifier\n",
    "from mapie.conformity_scores.sets import APSConformityScore, LACConformityScore, NaiveConformityScore, TopKConformityScore\n",
    "from util.ranking_datasets import LabelPairDataset\n",
    "from models.ranking_models import LabelRankingModel\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "from models.ranking_models import SortLayer\n",
    "import torch\n",
    "\n",
    "def conduct_oracle_experiment(conformity_score, num_pairs_to_check, generator, X_cal, y_cal):\n",
    "    tau_corrs = []\n",
    "    # Generate a small dataset\n",
    "\n",
    "    mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "    # create mapie classifier for conformity scores\n",
    "    mapie_clf.fit(X_cal, y_cal)\n",
    "    # create \n",
    "    oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "    models = []\n",
    "\n",
    "    for num_pairs in num_pairs_to_check:\n",
    "        X_pairs, y_pairs = oracle_annotator.generate_pairs_cross_instance(num_pairs)\n",
    "        X_pairs_val, y_pairs_val = oracle_annotator.generate_pairs_cross_instance(num_pairs//3)\n",
    "        ds = LabelPairDataset()\n",
    "        ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "        pair_loader = DataLoader(ds, batch_size=64)\n",
    "        ds_val = LabelPairDataset()\n",
    "        ds_val.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "        val_loader = DataLoader(ds_val, batch_size=64)\n",
    "        print(len(ds))\n",
    "        model = LabelRankingModel(input_dim=generator.n_features_, hidden_dims=3*[generator.n_features_], activations=[torch.nn.Sigmoid(), SortLayer(),torch.nn.Identity()], output_dim=len(generator.classes_))\n",
    "        model.num_classes = generator.n_classes_\n",
    "        model.to(\"cuda\")\n",
    "        device = next(model.parameters()).device\n",
    "        print(f\"Model is on: {device}\")\n",
    "        model._fit(pair_loader, val_loader=pair_loader, num_epochs=100, learning_rate=0.01, patience=100, verbose=True)\n",
    "\n",
    "\n",
    "        # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "        X_test, y_test = generator.generate(n=100)\n",
    "        skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "        conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "        tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "        tau_corrs.append(tau_corr)\n",
    "        models.append(models)\n",
    "        torch.cuda.empty_cache()\n",
    "    return tau_corrs, skills_from_model, conformity_scores, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\cp_rank\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.7146\n",
      "  Val Loss: 0.7047\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.7047\n",
      "  Val Loss: 0.6957\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.6957\n",
      "  Val Loss: 0.6876\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.6876\n",
      "  Val Loss: 0.6805\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.6805\n",
      "  Val Loss: 0.6745\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.6745\n",
      "  Val Loss: 0.6696\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.6696\n",
      "  Val Loss: 0.6657\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.6657\n",
      "  Val Loss: 0.6630\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.6630\n",
      "  Val Loss: 0.6611\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.6611\n",
      "  Val Loss: 0.6600\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.6600\n",
      "  Val Loss: 0.6593\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.6593\n",
      "  Val Loss: 0.6588\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.6588\n",
      "  Val Loss: 0.6582\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.6582\n",
      "  Val Loss: 0.6573\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.6573\n",
      "  Val Loss: 0.6560\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.6560\n",
      "  Val Loss: 0.6544\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.6544\n",
      "  Val Loss: 0.6525\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.6525\n",
      "  Val Loss: 0.6503\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.6503\n",
      "  Val Loss: 0.6481\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.6481\n",
      "  Val Loss: 0.6459\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.6459\n",
      "  Val Loss: 0.6437\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.6437\n",
      "  Val Loss: 0.6416\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.6416\n",
      "  Val Loss: 0.6394\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.6394\n",
      "  Val Loss: 0.6373\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.6373\n",
      "  Val Loss: 0.6351\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.6351\n",
      "  Val Loss: 0.6327\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.6327\n",
      "  Val Loss: 0.6302\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.6302\n",
      "  Val Loss: 0.6275\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.6275\n",
      "  Val Loss: 0.6245\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.6245\n",
      "  Val Loss: 0.6213\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.6213\n",
      "  Val Loss: 0.6177\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.6177\n",
      "  Val Loss: 0.6139\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.6139\n",
      "  Val Loss: 0.6097\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.6097\n",
      "  Val Loss: 0.6053\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.6053\n",
      "  Val Loss: 0.6007\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.6007\n",
      "  Val Loss: 0.5957\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.5957\n",
      "  Val Loss: 0.5904\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.5904\n",
      "  Val Loss: 0.5848\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.5848\n",
      "  Val Loss: 0.5793\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.5793\n",
      "  Val Loss: 0.5735\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.5735\n",
      "  Val Loss: 0.5674\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.5674\n",
      "  Val Loss: 0.5611\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.5611\n",
      "  Val Loss: 0.5544\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.5544\n",
      "  Val Loss: 0.5478\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.5478\n",
      "  Val Loss: 0.5411\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.5411\n",
      "  Val Loss: 0.5343\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.5343\n",
      "  Val Loss: 0.5273\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.5273\n",
      "  Val Loss: 0.5203\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.5203\n",
      "  Val Loss: 0.5132\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.5132\n",
      "  Val Loss: 0.5062\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.5062\n",
      "  Val Loss: 0.4991\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.4991\n",
      "  Val Loss: 0.4919\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.4919\n",
      "  Val Loss: 0.4847\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.4847\n",
      "  Val Loss: 0.4774\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.4774\n",
      "  Val Loss: 0.4700\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.4700\n",
      "  Val Loss: 0.4626\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.4626\n",
      "  Val Loss: 0.4553\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.4553\n",
      "  Val Loss: 0.4479\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.4479\n",
      "  Val Loss: 0.4405\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.4405\n",
      "  Val Loss: 0.4330\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.4330\n",
      "  Val Loss: 0.4255\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.4255\n",
      "  Val Loss: 0.4181\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.4181\n",
      "  Val Loss: 0.4107\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.4107\n",
      "  Val Loss: 0.4034\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.4034\n",
      "  Val Loss: 0.3961\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.3961\n",
      "  Val Loss: 0.3890\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.3890\n",
      "  Val Loss: 0.3820\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.3820\n",
      "  Val Loss: 0.3752\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.3752\n",
      "  Val Loss: 0.3686\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.3686\n",
      "  Val Loss: 0.3620\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.3620\n",
      "  Val Loss: 0.3557\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.3557\n",
      "  Val Loss: 0.3498\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.3498\n",
      "  Val Loss: 0.3439\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.3439\n",
      "  Val Loss: 0.3382\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.3382\n",
      "  Val Loss: 0.3325\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.3325\n",
      "  Val Loss: 0.3268\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.3268\n",
      "  Val Loss: 0.3215\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.3215\n",
      "  Val Loss: 0.3163\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.3163\n",
      "  Val Loss: 0.3111\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.3111\n",
      "  Val Loss: 0.3059\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.3059\n",
      "  Val Loss: 0.3009\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.3009\n",
      "  Val Loss: 0.2960\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.2960\n",
      "  Val Loss: 0.2912\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.2912\n",
      "  Val Loss: 0.2866\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.2866\n",
      "  Val Loss: 0.2821\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.2821\n",
      "  Val Loss: 0.2773\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.2773\n",
      "  Val Loss: 0.2724\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.2724\n",
      "  Val Loss: 0.2676\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.2676\n",
      "  Val Loss: 0.2630\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.2630\n",
      "  Val Loss: 0.2584\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.2584\n",
      "  Val Loss: 0.2537\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.2537\n",
      "  Val Loss: 0.2491\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.2491\n",
      "  Val Loss: 0.2443\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.2443\n",
      "  Val Loss: 0.2400\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.2400\n",
      "  Val Loss: 0.2355\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.2355\n",
      "  Val Loss: 0.2309\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.2309\n",
      "  Val Loss: 0.2262\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.2262\n",
      "  Val Loss: 0.2219\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.2219\n",
      "  Val Loss: 0.2176\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.2176\n",
      "  Val Loss: 0.2131\n",
      "141\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.2389\n",
      "  Val Loss: 0.2343\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.2313\n",
      "  Val Loss: 0.2286\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.2263\n",
      "  Val Loss: 0.2244\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.2227\n",
      "  Val Loss: 0.2214\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.2199\n",
      "  Val Loss: 0.2190\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.2177\n",
      "  Val Loss: 0.2169\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.2158\n",
      "  Val Loss: 0.2151\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.2140\n",
      "  Val Loss: 0.2134\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.2125\n",
      "  Val Loss: 0.2119\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.2110\n",
      "  Val Loss: 0.2105\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.2096\n",
      "  Val Loss: 0.2091\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.2083\n",
      "  Val Loss: 0.2078\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.2070\n",
      "  Val Loss: 0.2065\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.2058\n",
      "  Val Loss: 0.2052\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.2045\n",
      "  Val Loss: 0.2038\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.2031\n",
      "  Val Loss: 0.2022\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.2016\n",
      "  Val Loss: 0.2005\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.1998\n",
      "  Val Loss: 0.1985\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.1978\n",
      "  Val Loss: 0.1962\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.1956\n",
      "  Val Loss: 0.1937\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.1929\n",
      "  Val Loss: 0.1907\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.1899\n",
      "  Val Loss: 0.1874\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.1866\n",
      "  Val Loss: 0.1838\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.1831\n",
      "  Val Loss: 0.1800\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.1793\n",
      "  Val Loss: 0.1762\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.1755\n",
      "  Val Loss: 0.1724\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.1718\n",
      "  Val Loss: 0.1688\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.1683\n",
      "  Val Loss: 0.1656\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.1653\n",
      "  Val Loss: 0.1628\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.1626\n",
      "  Val Loss: 0.1605\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.1605\n",
      "  Val Loss: 0.1587\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.1587\n",
      "  Val Loss: 0.1571\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.1572\n",
      "  Val Loss: 0.1557\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.1558\n",
      "  Val Loss: 0.1545\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.1546\n",
      "  Val Loss: 0.1534\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.1535\n",
      "  Val Loss: 0.1524\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.1526\n",
      "  Val Loss: 0.1515\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.1517\n",
      "  Val Loss: 0.1507\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.1510\n",
      "  Val Loss: 0.1500\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.1503\n",
      "  Val Loss: 0.1494\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.1498\n",
      "  Val Loss: 0.1489\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.1493\n",
      "  Val Loss: 0.1483\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.1488\n",
      "  Val Loss: 0.1478\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.1483\n",
      "  Val Loss: 0.1474\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.1478\n",
      "  Val Loss: 0.1469\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.1473\n",
      "  Val Loss: 0.1465\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.1469\n",
      "  Val Loss: 0.1461\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.1464\n",
      "  Val Loss: 0.1457\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.1460\n",
      "  Val Loss: 0.1453\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.1456\n",
      "  Val Loss: 0.1449\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.1452\n",
      "  Val Loss: 0.1445\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.1448\n",
      "  Val Loss: 0.1441\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.1444\n",
      "  Val Loss: 0.1437\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.1440\n",
      "  Val Loss: 0.1433\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.1435\n",
      "  Val Loss: 0.1429\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.1431\n",
      "  Val Loss: 0.1424\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.1427\n",
      "  Val Loss: 0.1420\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.1423\n",
      "  Val Loss: 0.1416\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.1418\n",
      "  Val Loss: 0.1411\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.1413\n",
      "  Val Loss: 0.1407\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.1409\n",
      "  Val Loss: 0.1402\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.1404\n",
      "  Val Loss: 0.1397\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.1398\n",
      "  Val Loss: 0.1391\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.1393\n",
      "  Val Loss: 0.1386\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.1387\n",
      "  Val Loss: 0.1380\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.1382\n",
      "  Val Loss: 0.1374\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.1376\n",
      "  Val Loss: 0.1368\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.1369\n",
      "  Val Loss: 0.1362\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.1363\n",
      "  Val Loss: 0.1355\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.1356\n",
      "  Val Loss: 0.1348\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.1349\n",
      "  Val Loss: 0.1341\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.1341\n",
      "  Val Loss: 0.1333\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.1333\n",
      "  Val Loss: 0.1325\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.1325\n",
      "  Val Loss: 0.1316\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.1316\n",
      "  Val Loss: 0.1307\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.1307\n",
      "  Val Loss: 0.1297\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.1297\n",
      "  Val Loss: 0.1287\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.1286\n",
      "  Val Loss: 0.1277\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.1276\n",
      "  Val Loss: 0.1265\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.1264\n",
      "  Val Loss: 0.1254\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.1252\n",
      "  Val Loss: 0.1241\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.1240\n",
      "  Val Loss: 0.1229\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.1227\n",
      "  Val Loss: 0.1215\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.1213\n",
      "  Val Loss: 0.1201\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.1199\n",
      "  Val Loss: 0.1186\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.1184\n",
      "  Val Loss: 0.1171\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.1168\n",
      "  Val Loss: 0.1155\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.1152\n",
      "  Val Loss: 0.1139\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.1136\n",
      "  Val Loss: 0.1122\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.1118\n",
      "  Val Loss: 0.1104\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.1101\n",
      "  Val Loss: 0.1086\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.1083\n",
      "  Val Loss: 0.1068\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.1064\n",
      "  Val Loss: 0.1049\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.1045\n",
      "  Val Loss: 0.1030\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.1026\n",
      "  Val Loss: 0.1011\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.1007\n",
      "  Val Loss: 0.0991\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0987\n",
      "  Val Loss: 0.0971\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0967\n",
      "  Val Loss: 0.0951\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0947\n",
      "  Val Loss: 0.0932\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0928\n",
      "  Val Loss: 0.0912\n",
      "312\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.1388\n",
      "  Val Loss: 0.1380\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.1378\n",
      "  Val Loss: 0.1375\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.1372\n",
      "  Val Loss: 0.1369\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.1365\n",
      "  Val Loss: 0.1360\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.1355\n",
      "  Val Loss: 0.1349\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.1341\n",
      "  Val Loss: 0.1332\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.1322\n",
      "  Val Loss: 0.1308\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.1294\n",
      "  Val Loss: 0.1272\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.1253\n",
      "  Val Loss: 0.1221\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.1195\n",
      "  Val Loss: 0.1154\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.1124\n",
      "  Val Loss: 0.1076\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.1045\n",
      "  Val Loss: 0.0999\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0975\n",
      "  Val Loss: 0.0939\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0924\n",
      "  Val Loss: 0.0900\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0891\n",
      "  Val Loss: 0.0874\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0869\n",
      "  Val Loss: 0.0856\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0852\n",
      "  Val Loss: 0.0844\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0842\n",
      "  Val Loss: 0.0836\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0835\n",
      "  Val Loss: 0.0831\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0831\n",
      "  Val Loss: 0.0828\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0828\n",
      "  Val Loss: 0.0825\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0826\n",
      "  Val Loss: 0.0823\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0824\n",
      "  Val Loss: 0.0822\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0823\n",
      "  Val Loss: 0.0820\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0821\n",
      "  Val Loss: 0.0819\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0820\n",
      "  Val Loss: 0.0818\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0819\n",
      "  Val Loss: 0.0817\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0818\n",
      "  Val Loss: 0.0815\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0817\n",
      "  Val Loss: 0.0814\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0815\n",
      "  Val Loss: 0.0813\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0814\n",
      "  Val Loss: 0.0812\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0813\n",
      "  Val Loss: 0.0810\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0812\n",
      "  Val Loss: 0.0809\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0810\n",
      "  Val Loss: 0.0808\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0809\n",
      "  Val Loss: 0.0806\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0807\n",
      "  Val Loss: 0.0805\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0806\n",
      "  Val Loss: 0.0803\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0804\n",
      "  Val Loss: 0.0801\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0802\n",
      "  Val Loss: 0.0799\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0800\n",
      "  Val Loss: 0.0797\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0798\n",
      "  Val Loss: 0.0795\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0796\n",
      "  Val Loss: 0.0793\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0794\n",
      "  Val Loss: 0.0790\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0791\n",
      "  Val Loss: 0.0788\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0788\n",
      "  Val Loss: 0.0785\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0785\n",
      "  Val Loss: 0.0781\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0782\n",
      "  Val Loss: 0.0778\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0778\n",
      "  Val Loss: 0.0774\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0774\n",
      "  Val Loss: 0.0769\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0769\n",
      "  Val Loss: 0.0764\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0764\n",
      "  Val Loss: 0.0759\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0759\n",
      "  Val Loss: 0.0753\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0752\n",
      "  Val Loss: 0.0746\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0745\n",
      "  Val Loss: 0.0739\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0738\n",
      "  Val Loss: 0.0730\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0729\n",
      "  Val Loss: 0.0721\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0719\n",
      "  Val Loss: 0.0710\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0708\n",
      "  Val Loss: 0.0699\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0696\n",
      "  Val Loss: 0.0685\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0682\n",
      "  Val Loss: 0.0670\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0666\n",
      "  Val Loss: 0.0652\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0647\n",
      "  Val Loss: 0.0633\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0613\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0608\n",
      "  Val Loss: 0.0592\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0586\n",
      "  Val Loss: 0.0570\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0564\n",
      "  Val Loss: 0.0547\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0524\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0518\n",
      "  Val Loss: 0.0502\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0496\n",
      "  Val Loss: 0.0481\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0475\n",
      "  Val Loss: 0.0460\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0455\n",
      "  Val Loss: 0.0442\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0436\n",
      "  Val Loss: 0.0424\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0420\n",
      "  Val Loss: 0.0409\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0405\n",
      "  Val Loss: 0.0395\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0392\n",
      "  Val Loss: 0.0383\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0381\n",
      "  Val Loss: 0.0373\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0371\n",
      "  Val Loss: 0.0363\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0355\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0348\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0341\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0336\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0330\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0326\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0321\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0317\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0313\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0309\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0310\n",
      "  Val Loss: 0.0306\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0302\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0299\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0296\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0292\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0293\n",
      "  Val Loss: 0.0289\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0291\n",
      "  Val Loss: 0.0286\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0288\n",
      "  Val Loss: 0.0283\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0284\n",
      "  Val Loss: 0.0280\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0282\n",
      "  Val Loss: 0.0277\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0278\n",
      "  Val Loss: 0.0274\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0276\n",
      "  Val Loss: 0.0271\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0272\n",
      "  Val Loss: 0.0269\n",
      "689\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0620\n",
      "  Val Loss: 0.0607\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0596\n",
      "  Val Loss: 0.0579\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0559\n",
      "  Val Loss: 0.0529\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0500\n",
      "  Val Loss: 0.0463\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0435\n",
      "  Val Loss: 0.0405\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0390\n",
      "  Val Loss: 0.0376\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0371\n",
      "  Val Loss: 0.0364\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0358\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0353\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0347\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0341\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0334\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0327\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0320\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0312\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0305\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0296\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0294\n",
      "  Val Loss: 0.0287\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0285\n",
      "  Val Loss: 0.0278\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0276\n",
      "  Val Loss: 0.0268\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0266\n",
      "  Val Loss: 0.0258\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0256\n",
      "  Val Loss: 0.0248\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0245\n",
      "  Val Loss: 0.0237\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0235\n",
      "  Val Loss: 0.0227\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0225\n",
      "  Val Loss: 0.0217\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0215\n",
      "  Val Loss: 0.0208\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0207\n",
      "  Val Loss: 0.0200\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0199\n",
      "  Val Loss: 0.0193\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0193\n",
      "  Val Loss: 0.0187\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0187\n",
      "  Val Loss: 0.0182\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0182\n",
      "  Val Loss: 0.0177\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0177\n",
      "  Val Loss: 0.0172\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0173\n",
      "  Val Loss: 0.0169\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0170\n",
      "  Val Loss: 0.0165\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0166\n",
      "  Val Loss: 0.0162\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0164\n",
      "  Val Loss: 0.0160\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0161\n",
      "  Val Loss: 0.0157\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0159\n",
      "  Val Loss: 0.0155\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0157\n",
      "  Val Loss: 0.0153\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0155\n",
      "  Val Loss: 0.0151\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0150\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0148\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0150\n",
      "  Val Loss: 0.0147\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0149\n",
      "  Val Loss: 0.0146\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0148\n",
      "  Val Loss: 0.0145\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0147\n",
      "  Val Loss: 0.0143\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0146\n",
      "  Val Loss: 0.0142\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0145\n",
      "  Val Loss: 0.0142\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0144\n",
      "  Val Loss: 0.0141\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0143\n",
      "  Val Loss: 0.0140\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0143\n",
      "  Val Loss: 0.0139\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0142\n",
      "  Val Loss: 0.0138\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0141\n",
      "  Val Loss: 0.0137\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0140\n",
      "  Val Loss: 0.0137\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0140\n",
      "  Val Loss: 0.0136\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0139\n",
      "  Val Loss: 0.0135\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0138\n",
      "  Val Loss: 0.0135\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0138\n",
      "  Val Loss: 0.0134\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0137\n",
      "  Val Loss: 0.0133\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0137\n",
      "  Val Loss: 0.0133\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.0132\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.0132\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0135\n",
      "  Val Loss: 0.0131\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0134\n",
      "  Val Loss: 0.0130\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0134\n",
      "  Val Loss: 0.0130\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0133\n",
      "  Val Loss: 0.0129\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0133\n",
      "  Val Loss: 0.0129\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0133\n",
      "  Val Loss: 0.0128\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0132\n",
      "  Val Loss: 0.0128\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0132\n",
      "  Val Loss: 0.0127\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0127\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0126\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0130\n",
      "  Val Loss: 0.0126\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0130\n",
      "  Val Loss: 0.0125\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0125\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0125\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0124\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0124\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0123\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0123\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0122\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0122\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0122\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0121\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0121\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0121\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0120\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0120\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0119\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0119\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0119\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0118\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0118\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0118\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0117\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0117\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0117\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0117\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0116\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0116\n",
      "1521\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0292\n",
      "  Val Loss: 0.0271\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0256\n",
      "  Val Loss: 0.0234\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0211\n",
      "  Val Loss: 0.0189\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0187\n",
      "  Val Loss: 0.0179\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0183\n",
      "  Val Loss: 0.0176\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0178\n",
      "  Val Loss: 0.0172\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0171\n",
      "  Val Loss: 0.0165\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0163\n",
      "  Val Loss: 0.0156\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0145\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0142\n",
      "  Val Loss: 0.0133\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0122\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0112\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0112\n",
      "  Val Loss: 0.0104\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0105\n",
      "  Val Loss: 0.0098\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0100\n",
      "  Val Loss: 0.0093\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0095\n",
      "  Val Loss: 0.0089\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0092\n",
      "  Val Loss: 0.0086\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0089\n",
      "  Val Loss: 0.0084\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0086\n",
      "  Val Loss: 0.0081\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0083\n",
      "  Val Loss: 0.0079\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0081\n",
      "  Val Loss: 0.0077\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0079\n",
      "  Val Loss: 0.0075\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0077\n",
      "  Val Loss: 0.0073\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0075\n",
      "  Val Loss: 0.0071\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0073\n",
      "  Val Loss: 0.0069\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0071\n",
      "  Val Loss: 0.0067\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0066\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0064\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0062\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0060\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0059\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0057\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0056\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0054\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0053\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0052\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0051\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0049\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0048\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0047\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0046\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0045\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0040\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0040\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0040\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0040\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0039\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0039\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0039\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0039\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0039\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0038\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0038\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0038\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0038\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0038\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0037\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0038\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0037\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0037\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0037\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "3360\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0112\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0096\n",
      "  Val Loss: 0.0087\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0088\n",
      "  Val Loss: 0.0086\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0086\n",
      "  Val Loss: 0.0084\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0081\n",
      "  Val Loss: 0.0073\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0048\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0041\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0038\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0036\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0034\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0032\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0030\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0026\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0025\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0024\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0022\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0022\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0021\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0020\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0020\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0019\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0019\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0019\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0019\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0018\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0018\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0018\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0017\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0017\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0017\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0017\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0017\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0016\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0016\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0016\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0016\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0016\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0015\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0015\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0015\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0014\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0013\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0011\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "7419\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0037\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0022\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0017\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "16384\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0009\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0002\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0001\n",
      "  Val Loss: 0.0001\n",
      "64\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.7562\n",
      "  Val Loss: 0.7434\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.7434\n",
      "  Val Loss: 0.7316\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.7316\n",
      "  Val Loss: 0.7208\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.7208\n",
      "  Val Loss: 0.7111\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.7111\n",
      "  Val Loss: 0.7024\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.7024\n",
      "  Val Loss: 0.6947\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.6947\n",
      "  Val Loss: 0.6879\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.6879\n",
      "  Val Loss: 0.6820\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.6820\n",
      "  Val Loss: 0.6770\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.6770\n",
      "  Val Loss: 0.6730\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.6730\n",
      "  Val Loss: 0.6698\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.6698\n",
      "  Val Loss: 0.6675\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.6675\n",
      "  Val Loss: 0.6659\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.6659\n",
      "  Val Loss: 0.6649\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.6649\n",
      "  Val Loss: 0.6644\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.6644\n",
      "  Val Loss: 0.6640\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.6640\n",
      "  Val Loss: 0.6635\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.6635\n",
      "  Val Loss: 0.6629\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.6629\n",
      "  Val Loss: 0.6618\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.6618\n",
      "  Val Loss: 0.6604\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.6604\n",
      "  Val Loss: 0.6587\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.6587\n",
      "  Val Loss: 0.6567\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.6567\n",
      "  Val Loss: 0.6545\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.6545\n",
      "  Val Loss: 0.6522\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.6522\n",
      "  Val Loss: 0.6499\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.6499\n",
      "  Val Loss: 0.6477\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.6477\n",
      "  Val Loss: 0.6454\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.6454\n",
      "  Val Loss: 0.6432\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.6432\n",
      "  Val Loss: 0.6410\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.6410\n",
      "  Val Loss: 0.6387\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.6387\n",
      "  Val Loss: 0.6363\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.6363\n",
      "  Val Loss: 0.6338\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.6338\n",
      "  Val Loss: 0.6311\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.6311\n",
      "  Val Loss: 0.6283\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.6283\n",
      "  Val Loss: 0.6252\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.6252\n",
      "  Val Loss: 0.6219\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.6219\n",
      "  Val Loss: 0.6184\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.6184\n",
      "  Val Loss: 0.6147\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.6147\n",
      "  Val Loss: 0.6108\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.6108\n",
      "  Val Loss: 0.6067\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.6067\n",
      "  Val Loss: 0.6025\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.6025\n",
      "  Val Loss: 0.5980\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.5980\n",
      "  Val Loss: 0.5935\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.5935\n",
      "  Val Loss: 0.5887\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.5887\n",
      "  Val Loss: 0.5838\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.5838\n",
      "  Val Loss: 0.5787\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.5787\n",
      "  Val Loss: 0.5734\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.5734\n",
      "  Val Loss: 0.5679\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.5679\n",
      "  Val Loss: 0.5622\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.5622\n",
      "  Val Loss: 0.5566\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.5566\n",
      "  Val Loss: 0.5509\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.5509\n",
      "  Val Loss: 0.5452\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.5452\n",
      "  Val Loss: 0.5394\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.5394\n",
      "  Val Loss: 0.5338\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.5338\n",
      "  Val Loss: 0.5283\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.5283\n",
      "  Val Loss: 0.5228\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.5228\n",
      "  Val Loss: 0.5176\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.5176\n",
      "  Val Loss: 0.5125\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.5125\n",
      "  Val Loss: 0.5075\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.5075\n",
      "  Val Loss: 0.5026\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.5026\n",
      "  Val Loss: 0.4979\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.4979\n",
      "  Val Loss: 0.4933\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.4933\n",
      "  Val Loss: 0.4888\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.4888\n",
      "  Val Loss: 0.4845\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.4845\n",
      "  Val Loss: 0.4805\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.4805\n",
      "  Val Loss: 0.4767\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.4767\n",
      "  Val Loss: 0.4732\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.4732\n",
      "  Val Loss: 0.4698\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.4698\n",
      "  Val Loss: 0.4666\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.4666\n",
      "  Val Loss: 0.4637\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.4637\n",
      "  Val Loss: 0.4610\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.4610\n",
      "  Val Loss: 0.4586\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.4586\n",
      "  Val Loss: 0.4563\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.4563\n",
      "  Val Loss: 0.4541\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.4541\n",
      "  Val Loss: 0.4521\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.4521\n",
      "  Val Loss: 0.4503\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.4503\n",
      "  Val Loss: 0.4487\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.4487\n",
      "  Val Loss: 0.4471\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.4471\n",
      "  Val Loss: 0.4457\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.4457\n",
      "  Val Loss: 0.4444\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.4444\n",
      "  Val Loss: 0.4433\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.4433\n",
      "  Val Loss: 0.4422\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.4422\n",
      "  Val Loss: 0.4412\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.4412\n",
      "  Val Loss: 0.4401\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.4401\n",
      "  Val Loss: 0.4392\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.4392\n",
      "  Val Loss: 0.4382\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.4382\n",
      "  Val Loss: 0.4372\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.4372\n",
      "  Val Loss: 0.4362\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.4362\n",
      "  Val Loss: 0.4351\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.4351\n",
      "  Val Loss: 0.4341\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.4341\n",
      "  Val Loss: 0.4331\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.4331\n",
      "  Val Loss: 0.4320\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.4320\n",
      "  Val Loss: 0.4309\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.4309\n",
      "  Val Loss: 0.4297\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.4297\n",
      "  Val Loss: 0.4286\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.4286\n",
      "  Val Loss: 0.4274\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.4274\n",
      "  Val Loss: 0.4263\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.4263\n",
      "  Val Loss: 0.4251\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.4251\n",
      "  Val Loss: 0.4239\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.4239\n",
      "  Val Loss: 0.4228\n",
      "141\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.2387\n",
      "  Val Loss: 0.2363\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.2353\n",
      "  Val Loss: 0.2340\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.2332\n",
      "  Val Loss: 0.2322\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.2315\n",
      "  Val Loss: 0.2308\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.2301\n",
      "  Val Loss: 0.2296\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.2291\n",
      "  Val Loss: 0.2287\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.2283\n",
      "  Val Loss: 0.2281\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.2277\n",
      "  Val Loss: 0.2275\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.2271\n",
      "  Val Loss: 0.2269\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.2266\n",
      "  Val Loss: 0.2263\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.2259\n",
      "  Val Loss: 0.2256\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.2252\n",
      "  Val Loss: 0.2248\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.2243\n",
      "  Val Loss: 0.2236\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.2230\n",
      "  Val Loss: 0.2221\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.2212\n",
      "  Val Loss: 0.2201\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.2190\n",
      "  Val Loss: 0.2174\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.2160\n",
      "  Val Loss: 0.2139\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.2120\n",
      "  Val Loss: 0.2092\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.2067\n",
      "  Val Loss: 0.2032\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.2002\n",
      "  Val Loss: 0.1958\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.1923\n",
      "  Val Loss: 0.1873\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.1834\n",
      "  Val Loss: 0.1780\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.1740\n",
      "  Val Loss: 0.1687\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.1650\n",
      "  Val Loss: 0.1602\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.1570\n",
      "  Val Loss: 0.1531\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.1507\n",
      "  Val Loss: 0.1477\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.1459\n",
      "  Val Loss: 0.1436\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.1422\n",
      "  Val Loss: 0.1400\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.1390\n",
      "  Val Loss: 0.1361\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.1352\n",
      "  Val Loss: 0.1321\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.1314\n",
      "  Val Loss: 0.1288\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.1284\n",
      "  Val Loss: 0.1264\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.1262\n",
      "  Val Loss: 0.1242\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.1241\n",
      "  Val Loss: 0.1226\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.1222\n",
      "  Val Loss: 0.1212\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.1209\n",
      "  Val Loss: 0.1200\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.1198\n",
      "  Val Loss: 0.1190\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.1188\n",
      "  Val Loss: 0.1181\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.1180\n",
      "  Val Loss: 0.1173\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.1173\n",
      "  Val Loss: 0.1167\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.1167\n",
      "  Val Loss: 0.1160\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.1161\n",
      "  Val Loss: 0.1154\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.1155\n",
      "  Val Loss: 0.1149\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.1150\n",
      "  Val Loss: 0.1143\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.1145\n",
      "  Val Loss: 0.1138\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.1140\n",
      "  Val Loss: 0.1133\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.1135\n",
      "  Val Loss: 0.1129\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.1131\n",
      "  Val Loss: 0.1125\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.1126\n",
      "  Val Loss: 0.1121\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.1123\n",
      "  Val Loss: 0.1117\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.1119\n",
      "  Val Loss: 0.1114\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.1116\n",
      "  Val Loss: 0.1111\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.1113\n",
      "  Val Loss: 0.1108\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.1110\n",
      "  Val Loss: 0.1105\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.1107\n",
      "  Val Loss: 0.1103\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.1105\n",
      "  Val Loss: 0.1101\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.1103\n",
      "  Val Loss: 0.1099\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.1100\n",
      "  Val Loss: 0.1097\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.1098\n",
      "  Val Loss: 0.1095\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.1096\n",
      "  Val Loss: 0.1093\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.1095\n",
      "  Val Loss: 0.1091\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.1092\n",
      "  Val Loss: 0.1089\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.1090\n",
      "  Val Loss: 0.1086\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.1087\n",
      "  Val Loss: 0.1084\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.1085\n",
      "  Val Loss: 0.1081\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.1082\n",
      "  Val Loss: 0.1079\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.1080\n",
      "  Val Loss: 0.1077\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.1078\n",
      "  Val Loss: 0.1074\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.1076\n",
      "  Val Loss: 0.1072\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.1074\n",
      "  Val Loss: 0.1071\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.1072\n",
      "  Val Loss: 0.1069\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.1070\n",
      "  Val Loss: 0.1067\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.1068\n",
      "  Val Loss: 0.1065\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.1067\n",
      "  Val Loss: 0.1063\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.1065\n",
      "  Val Loss: 0.1061\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.1063\n",
      "  Val Loss: 0.1059\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.1061\n",
      "  Val Loss: 0.1057\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.1059\n",
      "  Val Loss: 0.1056\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.1057\n",
      "  Val Loss: 0.1054\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.1056\n",
      "  Val Loss: 0.1052\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.1054\n",
      "  Val Loss: 0.1051\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.1052\n",
      "  Val Loss: 0.1049\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.1050\n",
      "  Val Loss: 0.1047\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.1048\n",
      "  Val Loss: 0.1045\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.1046\n",
      "  Val Loss: 0.1043\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.1045\n",
      "  Val Loss: 0.1041\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.1043\n",
      "  Val Loss: 0.1039\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.1041\n",
      "  Val Loss: 0.1037\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.1039\n",
      "  Val Loss: 0.1035\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.1037\n",
      "  Val Loss: 0.1033\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.1034\n",
      "  Val Loss: 0.1031\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.1032\n",
      "  Val Loss: 0.1028\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.1030\n",
      "  Val Loss: 0.1026\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.1027\n",
      "  Val Loss: 0.1023\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.1025\n",
      "  Val Loss: 0.1021\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.1022\n",
      "  Val Loss: 0.1018\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.1019\n",
      "  Val Loss: 0.1016\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.1017\n",
      "  Val Loss: 0.1013\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.1014\n",
      "  Val Loss: 0.1010\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.1011\n",
      "  Val Loss: 0.1007\n",
      "312\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.1395\n",
      "  Val Loss: 0.1384\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.1381\n",
      "  Val Loss: 0.1379\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.1377\n",
      "  Val Loss: 0.1374\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.1373\n",
      "  Val Loss: 0.1369\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.1368\n",
      "  Val Loss: 0.1365\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.1364\n",
      "  Val Loss: 0.1361\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.1359\n",
      "  Val Loss: 0.1356\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.1354\n",
      "  Val Loss: 0.1350\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.1347\n",
      "  Val Loss: 0.1341\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.1338\n",
      "  Val Loss: 0.1330\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.1324\n",
      "  Val Loss: 0.1313\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.1304\n",
      "  Val Loss: 0.1289\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.1275\n",
      "  Val Loss: 0.1253\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.1234\n",
      "  Val Loss: 0.1205\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.1180\n",
      "  Val Loss: 0.1144\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.1114\n",
      "  Val Loss: 0.1077\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.1048\n",
      "  Val Loss: 0.1018\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0996\n",
      "  Val Loss: 0.0978\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0963\n",
      "  Val Loss: 0.0955\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0947\n",
      "  Val Loss: 0.0942\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0935\n",
      "  Val Loss: 0.0929\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0923\n",
      "  Val Loss: 0.0914\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0908\n",
      "  Val Loss: 0.0897\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0891\n",
      "  Val Loss: 0.0879\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0874\n",
      "  Val Loss: 0.0861\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0855\n",
      "  Val Loss: 0.0843\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0837\n",
      "  Val Loss: 0.0824\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0819\n",
      "  Val Loss: 0.0807\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0803\n",
      "  Val Loss: 0.0792\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0788\n",
      "  Val Loss: 0.0779\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0776\n",
      "  Val Loss: 0.0768\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0767\n",
      "  Val Loss: 0.0760\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0759\n",
      "  Val Loss: 0.0754\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0753\n",
      "  Val Loss: 0.0749\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0749\n",
      "  Val Loss: 0.0744\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0744\n",
      "  Val Loss: 0.0740\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0741\n",
      "  Val Loss: 0.0736\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0737\n",
      "  Val Loss: 0.0733\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0734\n",
      "  Val Loss: 0.0729\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0731\n",
      "  Val Loss: 0.0726\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0728\n",
      "  Val Loss: 0.0724\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0725\n",
      "  Val Loss: 0.0721\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0722\n",
      "  Val Loss: 0.0718\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0720\n",
      "  Val Loss: 0.0716\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0717\n",
      "  Val Loss: 0.0714\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0715\n",
      "  Val Loss: 0.0711\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0713\n",
      "  Val Loss: 0.0709\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0711\n",
      "  Val Loss: 0.0707\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0709\n",
      "  Val Loss: 0.0705\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0707\n",
      "  Val Loss: 0.0703\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0705\n",
      "  Val Loss: 0.0701\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0703\n",
      "  Val Loss: 0.0700\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0701\n",
      "  Val Loss: 0.0698\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0700\n",
      "  Val Loss: 0.0696\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0698\n",
      "  Val Loss: 0.0695\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0697\n",
      "  Val Loss: 0.0694\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0695\n",
      "  Val Loss: 0.0692\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0694\n",
      "  Val Loss: 0.0691\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0693\n",
      "  Val Loss: 0.0690\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0692\n",
      "  Val Loss: 0.0689\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0690\n",
      "  Val Loss: 0.0688\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0689\n",
      "  Val Loss: 0.0687\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0689\n",
      "  Val Loss: 0.0686\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0688\n",
      "  Val Loss: 0.0685\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0687\n",
      "  Val Loss: 0.0684\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0685\n",
      "  Val Loss: 0.0682\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0684\n",
      "  Val Loss: 0.0681\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0683\n",
      "  Val Loss: 0.0680\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0682\n",
      "  Val Loss: 0.0680\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0682\n",
      "  Val Loss: 0.0679\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0681\n",
      "  Val Loss: 0.0678\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0680\n",
      "  Val Loss: 0.0677\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0677\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0676\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0678\n",
      "  Val Loss: 0.0675\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0677\n",
      "  Val Loss: 0.0675\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0677\n",
      "  Val Loss: 0.0674\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0676\n",
      "  Val Loss: 0.0674\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0676\n",
      "  Val Loss: 0.0673\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0675\n",
      "  Val Loss: 0.0673\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0675\n",
      "  Val Loss: 0.0672\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0672\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0671\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0673\n",
      "  Val Loss: 0.0671\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0673\n",
      "  Val Loss: 0.0670\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0672\n",
      "  Val Loss: 0.0670\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0672\n",
      "  Val Loss: 0.0670\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0672\n",
      "  Val Loss: 0.0669\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0671\n",
      "  Val Loss: 0.0669\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0671\n",
      "  Val Loss: 0.0668\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0671\n",
      "  Val Loss: 0.0668\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0670\n",
      "  Val Loss: 0.0668\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0670\n",
      "  Val Loss: 0.0667\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0670\n",
      "  Val Loss: 0.0667\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0667\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0666\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0666\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0668\n",
      "  Val Loss: 0.0666\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0668\n",
      "  Val Loss: 0.0666\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0668\n",
      "  Val Loss: 0.0665\n",
      "689\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0711\n",
      "  Val Loss: 0.0669\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0657\n",
      "  Val Loss: 0.0645\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0640\n",
      "  Val Loss: 0.0635\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0628\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0624\n",
      "  Val Loss: 0.0623\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0623\n",
      "  Val Loss: 0.0622\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0621\n",
      "  Val Loss: 0.0620\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0619\n",
      "  Val Loss: 0.0617\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0613\n",
      "  Val Loss: 0.0608\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0598\n",
      "  Val Loss: 0.0581\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0556\n",
      "  Val Loss: 0.0514\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0451\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0448\n",
      "  Val Loss: 0.0448\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0447\n",
      "  Val Loss: 0.0442\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0443\n",
      "  Val Loss: 0.0441\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0442\n",
      "  Val Loss: 0.0439\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0440\n",
      "  Val Loss: 0.0438\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.0437\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0437\n",
      "  Val Loss: 0.0435\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0435\n",
      "  Val Loss: 0.0433\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0433\n",
      "  Val Loss: 0.0430\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0430\n",
      "  Val Loss: 0.0426\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0425\n",
      "  Val Loss: 0.0421\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0419\n",
      "  Val Loss: 0.0414\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0412\n",
      "  Val Loss: 0.0405\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0402\n",
      "  Val Loss: 0.0394\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0391\n",
      "  Val Loss: 0.0381\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0378\n",
      "  Val Loss: 0.0368\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0367\n",
      "  Val Loss: 0.0358\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0350\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0345\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0341\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0338\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0338\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0335\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0339\n",
      "  Val Loss: 0.0334\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0337\n",
      "  Val Loss: 0.0333\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0332\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0332\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0331\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0335\n",
      "  Val Loss: 0.0331\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0330\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0330\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0330\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0329\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0329\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0329\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0329\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0329\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0328\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0328\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0328\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0328\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0328\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0328\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0328\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0328\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0327\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0327\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0327\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0327\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0327\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0327\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0326\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0326\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0325\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0325\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0325\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0325\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0325\n",
      "1521\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0287\n",
      "  Val Loss: 0.0278\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0271\n",
      "  Val Loss: 0.0257\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0237\n",
      "  Val Loss: 0.0216\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0210\n",
      "  Val Loss: 0.0209\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0205\n",
      "  Val Loss: 0.0204\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0200\n",
      "  Val Loss: 0.0197\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0192\n",
      "  Val Loss: 0.0187\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0180\n",
      "  Val Loss: 0.0173\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0168\n",
      "  Val Loss: 0.0161\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0159\n",
      "  Val Loss: 0.0155\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0156\n",
      "  Val Loss: 0.0154\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0156\n",
      "  Val Loss: 0.0153\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0155\n",
      "  Val Loss: 0.0152\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0155\n",
      "  Val Loss: 0.0152\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0154\n",
      "  Val Loss: 0.0151\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0154\n",
      "  Val Loss: 0.0151\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0154\n",
      "  Val Loss: 0.0151\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0151\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0151\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0150\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0150\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0150\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0150\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0150\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0150\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0149\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0152\n",
      "  Val Loss: 0.0149\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0149\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0149\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0149\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0151\n",
      "  Val Loss: 0.0149\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0150\n",
      "  Val Loss: 0.0148\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0150\n",
      "  Val Loss: 0.0148\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0150\n",
      "  Val Loss: 0.0148\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0150\n",
      "  Val Loss: 0.0148\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0150\n",
      "  Val Loss: 0.0148\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0149\n",
      "  Val Loss: 0.0147\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0149\n",
      "  Val Loss: 0.0147\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0149\n",
      "  Val Loss: 0.0147\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0148\n",
      "  Val Loss: 0.0147\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0148\n",
      "  Val Loss: 0.0146\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0148\n",
      "  Val Loss: 0.0146\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0147\n",
      "  Val Loss: 0.0145\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0147\n",
      "  Val Loss: 0.0145\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0146\n",
      "  Val Loss: 0.0144\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0146\n",
      "  Val Loss: 0.0144\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0145\n",
      "  Val Loss: 0.0143\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0144\n",
      "  Val Loss: 0.0142\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0144\n",
      "  Val Loss: 0.0141\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0143\n",
      "  Val Loss: 0.0140\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0141\n",
      "  Val Loss: 0.0139\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0140\n",
      "  Val Loss: 0.0138\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0139\n",
      "  Val Loss: 0.0136\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0137\n",
      "  Val Loss: 0.0134\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.0133\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0135\n",
      "  Val Loss: 0.0132\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0133\n",
      "  Val Loss: 0.0131\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0132\n",
      "  Val Loss: 0.0130\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0129\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0128\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0130\n",
      "  Val Loss: 0.0128\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0128\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0127\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0127\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0127\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0127\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0126\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0126\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0125\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0125\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0124\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0124\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0124\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0123\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0124\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0123\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0123\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0118\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0117\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0117\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0116\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0116\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0115\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0115\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0115\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0114\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0114\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0114\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0114\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0113\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0113\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0116\n",
      "  Val Loss: 0.0113\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0116\n",
      "  Val Loss: 0.0112\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0116\n",
      "  Val Loss: 0.0112\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0116\n",
      "  Val Loss: 0.0112\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0115\n",
      "  Val Loss: 0.0112\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0115\n",
      "  Val Loss: 0.0112\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0115\n",
      "  Val Loss: 0.0111\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0115\n",
      "  Val Loss: 0.0111\n",
      "3360\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0100\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0097\n",
      "  Val Loss: 0.0095\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0095\n",
      "  Val Loss: 0.0095\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0095\n",
      "  Val Loss: 0.0094\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0094\n",
      "  Val Loss: 0.0094\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0094\n",
      "  Val Loss: 0.0094\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0094\n",
      "  Val Loss: 0.0093\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0093\n",
      "  Val Loss: 0.0093\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0092\n",
      "  Val Loss: 0.0092\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0091\n",
      "  Val Loss: 0.0090\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0089\n",
      "  Val Loss: 0.0087\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0086\n",
      "  Val Loss: 0.0085\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0084\n",
      "  Val Loss: 0.0082\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0081\n",
      "  Val Loss: 0.0079\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0078\n",
      "  Val Loss: 0.0075\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0073\n",
      "  Val Loss: 0.0070\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0066\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0056\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0055\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0053\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0052\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0051\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0050\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0050\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0049\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0049\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0049\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0049\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0049\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0049\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0048\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0048\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0048\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0048\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0048\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "7419\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0045\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0044\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0032\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0029\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0026\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0025\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0024\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "16384\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0015\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "64\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.7858\n",
      "  Val Loss: 0.7756\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.7756\n",
      "  Val Loss: 0.7662\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.7662\n",
      "  Val Loss: 0.7578\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.7578\n",
      "  Val Loss: 0.7500\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.7500\n",
      "  Val Loss: 0.7429\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.7429\n",
      "  Val Loss: 0.7364\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.7364\n",
      "  Val Loss: 0.7303\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.7303\n",
      "  Val Loss: 0.7246\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.7246\n",
      "  Val Loss: 0.7193\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.7193\n",
      "  Val Loss: 0.7142\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.7142\n",
      "  Val Loss: 0.7093\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.7093\n",
      "  Val Loss: 0.7046\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.7046\n",
      "  Val Loss: 0.7000\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.7000\n",
      "  Val Loss: 0.6953\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.6953\n",
      "  Val Loss: 0.6909\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.6909\n",
      "  Val Loss: 0.6864\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.6864\n",
      "  Val Loss: 0.6819\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.6819\n",
      "  Val Loss: 0.6775\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.6775\n",
      "  Val Loss: 0.6732\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.6732\n",
      "  Val Loss: 0.6689\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.6689\n",
      "  Val Loss: 0.6647\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.6647\n",
      "  Val Loss: 0.6604\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.6604\n",
      "  Val Loss: 0.6561\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.6561\n",
      "  Val Loss: 0.6517\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.6517\n",
      "  Val Loss: 0.6474\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.6474\n",
      "  Val Loss: 0.6432\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.6432\n",
      "  Val Loss: 0.6392\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.6392\n",
      "  Val Loss: 0.6351\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.6351\n",
      "  Val Loss: 0.6308\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.6308\n",
      "  Val Loss: 0.6261\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.6261\n",
      "  Val Loss: 0.6212\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.6212\n",
      "  Val Loss: 0.6162\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.6162\n",
      "  Val Loss: 0.6112\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.6112\n",
      "  Val Loss: 0.6059\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.6059\n",
      "  Val Loss: 0.6002\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.6002\n",
      "  Val Loss: 0.5942\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.5942\n",
      "  Val Loss: 0.5880\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.5880\n",
      "  Val Loss: 0.5815\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.5815\n",
      "  Val Loss: 0.5747\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.5747\n",
      "  Val Loss: 0.5677\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.5677\n",
      "  Val Loss: 0.5605\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.5605\n",
      "  Val Loss: 0.5531\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.5531\n",
      "  Val Loss: 0.5461\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.5461\n",
      "  Val Loss: 0.5392\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.5392\n",
      "  Val Loss: 0.5320\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.5320\n",
      "  Val Loss: 0.5245\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.5245\n",
      "  Val Loss: 0.5166\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.5166\n",
      "  Val Loss: 0.5086\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.5086\n",
      "  Val Loss: 0.5006\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.5006\n",
      "  Val Loss: 0.4925\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.4925\n",
      "  Val Loss: 0.4844\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.4844\n",
      "  Val Loss: 0.4761\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.4761\n",
      "  Val Loss: 0.4676\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.4676\n",
      "  Val Loss: 0.4595\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.4595\n",
      "  Val Loss: 0.4514\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.4514\n",
      "  Val Loss: 0.4432\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.4432\n",
      "  Val Loss: 0.4348\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.4348\n",
      "  Val Loss: 0.4264\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.4264\n",
      "  Val Loss: 0.4181\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.4181\n",
      "  Val Loss: 0.4100\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.4100\n",
      "  Val Loss: 0.4020\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.4020\n",
      "  Val Loss: 0.3940\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.3940\n",
      "  Val Loss: 0.3859\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.3859\n",
      "  Val Loss: 0.3779\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.3779\n",
      "  Val Loss: 0.3702\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.3702\n",
      "  Val Loss: 0.3625\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.3625\n",
      "  Val Loss: 0.3548\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.3548\n",
      "  Val Loss: 0.3472\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.3472\n",
      "  Val Loss: 0.3399\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.3399\n",
      "  Val Loss: 0.3327\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.3327\n",
      "  Val Loss: 0.3257\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.3257\n",
      "  Val Loss: 0.3188\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.3188\n",
      "  Val Loss: 0.3121\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.3121\n",
      "  Val Loss: 0.3055\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.3055\n",
      "  Val Loss: 0.2993\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.2993\n",
      "  Val Loss: 0.2937\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.2937\n",
      "  Val Loss: 0.2880\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.2880\n",
      "  Val Loss: 0.2822\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.2822\n",
      "  Val Loss: 0.2766\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.2766\n",
      "  Val Loss: 0.2715\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.2715\n",
      "  Val Loss: 0.2665\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.2665\n",
      "  Val Loss: 0.2617\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.2617\n",
      "  Val Loss: 0.2570\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.2570\n",
      "  Val Loss: 0.2524\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.2524\n",
      "  Val Loss: 0.2480\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.2480\n",
      "  Val Loss: 0.2438\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.2438\n",
      "  Val Loss: 0.2397\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.2397\n",
      "  Val Loss: 0.2357\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.2357\n",
      "  Val Loss: 0.2319\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.2319\n",
      "  Val Loss: 0.2282\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.2282\n",
      "  Val Loss: 0.2247\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.2247\n",
      "  Val Loss: 0.2212\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.2212\n",
      "  Val Loss: 0.2178\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.2178\n",
      "  Val Loss: 0.2146\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.2146\n",
      "  Val Loss: 0.2115\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.2115\n",
      "  Val Loss: 0.2085\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.2085\n",
      "  Val Loss: 0.2055\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.2055\n",
      "  Val Loss: 0.2029\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.2029\n",
      "  Val Loss: 0.2001\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.2001\n",
      "  Val Loss: 0.1975\n",
      "141\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.2706\n",
      "  Val Loss: 0.2623\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.2606\n",
      "  Val Loss: 0.2552\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.2542\n",
      "  Val Loss: 0.2500\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.2493\n",
      "  Val Loss: 0.2458\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.2453\n",
      "  Val Loss: 0.2423\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.2419\n",
      "  Val Loss: 0.2394\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.2390\n",
      "  Val Loss: 0.2368\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.2365\n",
      "  Val Loss: 0.2345\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.2342\n",
      "  Val Loss: 0.2324\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.2322\n",
      "  Val Loss: 0.2306\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.2304\n",
      "  Val Loss: 0.2289\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.2288\n",
      "  Val Loss: 0.2274\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.2272\n",
      "  Val Loss: 0.2259\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.2257\n",
      "  Val Loss: 0.2245\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.2241\n",
      "  Val Loss: 0.2228\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.2223\n",
      "  Val Loss: 0.2209\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.2202\n",
      "  Val Loss: 0.2186\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.2177\n",
      "  Val Loss: 0.2158\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.2145\n",
      "  Val Loss: 0.2123\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.2107\n",
      "  Val Loss: 0.2081\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.2062\n",
      "  Val Loss: 0.2030\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.2007\n",
      "  Val Loss: 0.1971\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.1946\n",
      "  Val Loss: 0.1907\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.1879\n",
      "  Val Loss: 0.1838\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.1810\n",
      "  Val Loss: 0.1766\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.1740\n",
      "  Val Loss: 0.1696\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.1672\n",
      "  Val Loss: 0.1629\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.1609\n",
      "  Val Loss: 0.1570\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.1554\n",
      "  Val Loss: 0.1522\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.1509\n",
      "  Val Loss: 0.1484\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.1474\n",
      "  Val Loss: 0.1456\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.1449\n",
      "  Val Loss: 0.1435\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.1431\n",
      "  Val Loss: 0.1421\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.1419\n",
      "  Val Loss: 0.1412\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.1412\n",
      "  Val Loss: 0.1406\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.1407\n",
      "  Val Loss: 0.1401\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.1404\n",
      "  Val Loss: 0.1398\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.1402\n",
      "  Val Loss: 0.1396\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.1400\n",
      "  Val Loss: 0.1394\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.1398\n",
      "  Val Loss: 0.1393\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.1397\n",
      "  Val Loss: 0.1392\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.1396\n",
      "  Val Loss: 0.1390\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.1394\n",
      "  Val Loss: 0.1389\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.1393\n",
      "  Val Loss: 0.1388\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.1393\n",
      "  Val Loss: 0.1388\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.1392\n",
      "  Val Loss: 0.1385\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.1388\n",
      "  Val Loss: 0.1381\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.1383\n",
      "  Val Loss: 0.1376\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.1380\n",
      "  Val Loss: 0.1374\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.1379\n",
      "  Val Loss: 0.1374\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.1377\n",
      "  Val Loss: 0.1372\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.1374\n",
      "  Val Loss: 0.1370\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.1371\n",
      "  Val Loss: 0.1368\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.1371\n",
      "  Val Loss: 0.1368\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.1370\n",
      "  Val Loss: 0.1366\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.1368\n",
      "  Val Loss: 0.1364\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.1367\n",
      "  Val Loss: 0.1363\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.1366\n",
      "  Val Loss: 0.1361\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.1364\n",
      "  Val Loss: 0.1360\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.1362\n",
      "  Val Loss: 0.1358\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.1360\n",
      "  Val Loss: 0.1356\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.1358\n",
      "  Val Loss: 0.1354\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.1357\n",
      "  Val Loss: 0.1352\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.1355\n",
      "  Val Loss: 0.1351\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.1353\n",
      "  Val Loss: 0.1349\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.1352\n",
      "  Val Loss: 0.1347\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.1350\n",
      "  Val Loss: 0.1345\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.1348\n",
      "  Val Loss: 0.1344\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.1346\n",
      "  Val Loss: 0.1342\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.1344\n",
      "  Val Loss: 0.1340\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.1342\n",
      "  Val Loss: 0.1338\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.1340\n",
      "  Val Loss: 0.1336\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.1338\n",
      "  Val Loss: 0.1334\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.1336\n",
      "  Val Loss: 0.1332\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.1334\n",
      "  Val Loss: 0.1329\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.1332\n",
      "  Val Loss: 0.1327\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.1329\n",
      "  Val Loss: 0.1325\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.1327\n",
      "  Val Loss: 0.1323\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.1325\n",
      "  Val Loss: 0.1320\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.1322\n",
      "  Val Loss: 0.1318\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.1320\n",
      "  Val Loss: 0.1315\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.1317\n",
      "  Val Loss: 0.1312\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.1314\n",
      "  Val Loss: 0.1309\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.1311\n",
      "  Val Loss: 0.1306\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.1308\n",
      "  Val Loss: 0.1303\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.1304\n",
      "  Val Loss: 0.1300\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.1301\n",
      "  Val Loss: 0.1296\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.1298\n",
      "  Val Loss: 0.1292\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.1294\n",
      "  Val Loss: 0.1289\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.1290\n",
      "  Val Loss: 0.1284\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.1285\n",
      "  Val Loss: 0.1280\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.1281\n",
      "  Val Loss: 0.1275\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.1276\n",
      "  Val Loss: 0.1270\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.1271\n",
      "  Val Loss: 0.1265\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.1266\n",
      "  Val Loss: 0.1260\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.1260\n",
      "  Val Loss: 0.1254\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.1255\n",
      "  Val Loss: 0.1248\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.1248\n",
      "  Val Loss: 0.1242\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.1242\n",
      "  Val Loss: 0.1235\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.1235\n",
      "  Val Loss: 0.1228\n",
      "312\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.1488\n",
      "  Val Loss: 0.1425\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.1399\n",
      "  Val Loss: 0.1372\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.1363\n",
      "  Val Loss: 0.1356\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.1352\n",
      "  Val Loss: 0.1348\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.1341\n",
      "  Val Loss: 0.1335\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.1330\n",
      "  Val Loss: 0.1324\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.1321\n",
      "  Val Loss: 0.1315\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.1311\n",
      "  Val Loss: 0.1304\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.1298\n",
      "  Val Loss: 0.1288\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.1280\n",
      "  Val Loss: 0.1268\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.1258\n",
      "  Val Loss: 0.1243\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.1229\n",
      "  Val Loss: 0.1210\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.1193\n",
      "  Val Loss: 0.1172\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.1155\n",
      "  Val Loss: 0.1134\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.1118\n",
      "  Val Loss: 0.1099\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.1085\n",
      "  Val Loss: 0.1069\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.1057\n",
      "  Val Loss: 0.1044\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.1036\n",
      "  Val Loss: 0.1027\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.1021\n",
      "  Val Loss: 0.1015\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.1011\n",
      "  Val Loss: 0.1008\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.1005\n",
      "  Val Loss: 0.1002\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.1001\n",
      "  Val Loss: 0.0996\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0996\n",
      "  Val Loss: 0.0991\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0991\n",
      "  Val Loss: 0.0986\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0985\n",
      "  Val Loss: 0.0980\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0980\n",
      "  Val Loss: 0.0975\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0975\n",
      "  Val Loss: 0.0970\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0969\n",
      "  Val Loss: 0.0964\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0964\n",
      "  Val Loss: 0.0958\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0957\n",
      "  Val Loss: 0.0952\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0951\n",
      "  Val Loss: 0.0946\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0945\n",
      "  Val Loss: 0.0939\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0938\n",
      "  Val Loss: 0.0932\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0932\n",
      "  Val Loss: 0.0926\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0925\n",
      "  Val Loss: 0.0919\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0918\n",
      "  Val Loss: 0.0911\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0910\n",
      "  Val Loss: 0.0903\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0902\n",
      "  Val Loss: 0.0895\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0894\n",
      "  Val Loss: 0.0887\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0885\n",
      "  Val Loss: 0.0878\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0875\n",
      "  Val Loss: 0.0868\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0865\n",
      "  Val Loss: 0.0857\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0854\n",
      "  Val Loss: 0.0845\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0842\n",
      "  Val Loss: 0.0833\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0830\n",
      "  Val Loss: 0.0821\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0818\n",
      "  Val Loss: 0.0808\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0805\n",
      "  Val Loss: 0.0795\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0792\n",
      "  Val Loss: 0.0782\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0779\n",
      "  Val Loss: 0.0769\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0765\n",
      "  Val Loss: 0.0755\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0752\n",
      "  Val Loss: 0.0742\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0739\n",
      "  Val Loss: 0.0729\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0726\n",
      "  Val Loss: 0.0717\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0714\n",
      "  Val Loss: 0.0704\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0702\n",
      "  Val Loss: 0.0692\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0690\n",
      "  Val Loss: 0.0681\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0670\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0661\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0659\n",
      "  Val Loss: 0.0651\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0650\n",
      "  Val Loss: 0.0643\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0642\n",
      "  Val Loss: 0.0634\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0627\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0620\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0620\n",
      "  Val Loss: 0.0613\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0613\n",
      "  Val Loss: 0.0606\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0606\n",
      "  Val Loss: 0.0600\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0600\n",
      "  Val Loss: 0.0594\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0595\n",
      "  Val Loss: 0.0589\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0591\n",
      "  Val Loss: 0.0585\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0586\n",
      "  Val Loss: 0.0581\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0582\n",
      "  Val Loss: 0.0577\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0578\n",
      "  Val Loss: 0.0573\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0575\n",
      "  Val Loss: 0.0570\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0572\n",
      "  Val Loss: 0.0568\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0569\n",
      "  Val Loss: 0.0565\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0567\n",
      "  Val Loss: 0.0563\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0565\n",
      "  Val Loss: 0.0561\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0563\n",
      "  Val Loss: 0.0559\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0561\n",
      "  Val Loss: 0.0557\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0559\n",
      "  Val Loss: 0.0555\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0558\n",
      "  Val Loss: 0.0554\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0556\n",
      "  Val Loss: 0.0553\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0555\n",
      "  Val Loss: 0.0551\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0553\n",
      "  Val Loss: 0.0550\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0552\n",
      "  Val Loss: 0.0548\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0551\n",
      "  Val Loss: 0.0547\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0549\n",
      "  Val Loss: 0.0546\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0548\n",
      "  Val Loss: 0.0545\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0547\n",
      "  Val Loss: 0.0544\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0546\n",
      "  Val Loss: 0.0543\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0545\n",
      "  Val Loss: 0.0542\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0544\n",
      "  Val Loss: 0.0541\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0544\n",
      "  Val Loss: 0.0540\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0543\n",
      "  Val Loss: 0.0540\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0542\n",
      "  Val Loss: 0.0539\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0538\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0537\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0537\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0536\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0535\n",
      "689\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0661\n",
      "  Val Loss: 0.0637\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0612\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0605\n",
      "  Val Loss: 0.0596\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0589\n",
      "  Val Loss: 0.0578\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0564\n",
      "  Val Loss: 0.0546\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0527\n",
      "  Val Loss: 0.0502\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0458\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0445\n",
      "  Val Loss: 0.0430\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0427\n",
      "  Val Loss: 0.0417\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0416\n",
      "  Val Loss: 0.0409\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0410\n",
      "  Val Loss: 0.0403\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0404\n",
      "  Val Loss: 0.0397\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0398\n",
      "  Val Loss: 0.0392\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0392\n",
      "  Val Loss: 0.0386\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0386\n",
      "  Val Loss: 0.0380\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0380\n",
      "  Val Loss: 0.0373\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0373\n",
      "  Val Loss: 0.0366\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0366\n",
      "  Val Loss: 0.0359\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0352\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0345\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0339\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0338\n",
      "  Val Loss: 0.0333\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0329\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0324\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0321\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0318\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0316\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0314\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0312\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0311\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0309\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0308\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0310\n",
      "  Val Loss: 0.0307\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0309\n",
      "  Val Loss: 0.0306\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0308\n",
      "  Val Loss: 0.0305\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0305\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0304\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0306\n",
      "  Val Loss: 0.0303\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0305\n",
      "  Val Loss: 0.0302\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0304\n",
      "  Val Loss: 0.0301\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0300\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0302\n",
      "  Val Loss: 0.0299\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0299\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0298\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0297\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0297\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0296\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0296\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0295\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0295\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0294\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0294\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0293\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0293\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0295\n",
      "  Val Loss: 0.0293\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0295\n",
      "  Val Loss: 0.0292\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0295\n",
      "  Val Loss: 0.0292\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0294\n",
      "  Val Loss: 0.0291\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0294\n",
      "  Val Loss: 0.0291\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0293\n",
      "  Val Loss: 0.0291\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0293\n",
      "  Val Loss: 0.0290\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0292\n",
      "  Val Loss: 0.0290\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0292\n",
      "  Val Loss: 0.0290\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0292\n",
      "  Val Loss: 0.0289\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0291\n",
      "  Val Loss: 0.0289\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0291\n",
      "  Val Loss: 0.0288\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0291\n",
      "  Val Loss: 0.0288\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0290\n",
      "  Val Loss: 0.0288\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0290\n",
      "  Val Loss: 0.0287\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0289\n",
      "  Val Loss: 0.0287\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0289\n",
      "  Val Loss: 0.0286\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0289\n",
      "  Val Loss: 0.0286\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0288\n",
      "  Val Loss: 0.0286\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0288\n",
      "  Val Loss: 0.0285\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0288\n",
      "  Val Loss: 0.0285\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0287\n",
      "  Val Loss: 0.0285\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0287\n",
      "  Val Loss: 0.0284\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0287\n",
      "  Val Loss: 0.0284\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0286\n",
      "  Val Loss: 0.0284\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0286\n",
      "  Val Loss: 0.0283\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0286\n",
      "  Val Loss: 0.0283\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0285\n",
      "  Val Loss: 0.0283\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0284\n",
      "  Val Loss: 0.0282\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0284\n",
      "  Val Loss: 0.0282\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0284\n",
      "  Val Loss: 0.0281\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0283\n",
      "  Val Loss: 0.0281\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0283\n",
      "  Val Loss: 0.0281\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0282\n",
      "  Val Loss: 0.0280\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0282\n",
      "  Val Loss: 0.0280\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0282\n",
      "  Val Loss: 0.0279\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0281\n",
      "  Val Loss: 0.0279\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0281\n",
      "  Val Loss: 0.0279\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0280\n",
      "  Val Loss: 0.0278\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0280\n",
      "  Val Loss: 0.0277\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0279\n",
      "  Val Loss: 0.0277\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0279\n",
      "  Val Loss: 0.0276\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0278\n",
      "  Val Loss: 0.0276\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0278\n",
      "  Val Loss: 0.0276\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0278\n",
      "  Val Loss: 0.0275\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0277\n",
      "  Val Loss: 0.0275\n",
      "1521\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0277\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0274\n",
      "  Val Loss: 0.0268\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0260\n",
      "  Val Loss: 0.0246\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0224\n",
      "  Val Loss: 0.0193\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0182\n",
      "  Val Loss: 0.0171\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0168\n",
      "  Val Loss: 0.0160\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0159\n",
      "  Val Loss: 0.0153\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.0148\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0148\n",
      "  Val Loss: 0.0144\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0145\n",
      "  Val Loss: 0.0141\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0142\n",
      "  Val Loss: 0.0139\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0139\n",
      "  Val Loss: 0.0137\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0137\n",
      "  Val Loss: 0.0135\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.0133\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0135\n",
      "  Val Loss: 0.0132\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0133\n",
      "  Val Loss: 0.0131\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0132\n",
      "  Val Loss: 0.0130\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0132\n",
      "  Val Loss: 0.0130\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0129\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0130\n",
      "  Val Loss: 0.0128\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0130\n",
      "  Val Loss: 0.0127\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0127\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0129\n",
      "  Val Loss: 0.0127\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0126\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0128\n",
      "  Val Loss: 0.0126\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0125\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0125\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0127\n",
      "  Val Loss: 0.0125\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0124\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0124\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0126\n",
      "  Val Loss: 0.0124\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0123\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0123\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0125\n",
      "  Val Loss: 0.0123\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0122\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0122\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0122\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0122\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.0122\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0121\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0121\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0121\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0121\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0123\n",
      "  Val Loss: 0.0121\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0122\n",
      "  Val Loss: 0.0120\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0119\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0121\n",
      "  Val Loss: 0.0118\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0120\n",
      "  Val Loss: 0.0118\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0119\n",
      "  Val Loss: 0.0117\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0117\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0116\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0118\n",
      "  Val Loss: 0.0115\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0116\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0117\n",
      "  Val Loss: 0.0115\n",
      "3360\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0131\n",
      "  Val Loss: 0.0126\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0111\n",
      "  Val Loss: 0.0094\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0091\n",
      "  Val Loss: 0.0089\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0085\n",
      "  Val Loss: 0.0079\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0073\n",
      "  Val Loss: 0.0068\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0062\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0061\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0060\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0059\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0059\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0058\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0058\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0058\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0057\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0057\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0057\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0056\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0056\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0056\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0056\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0056\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0056\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0055\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0054\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0053\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0053\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0053\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0052\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0052\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0052\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0052\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0051\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0051\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0051\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0051\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0051\n",
      "7419\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0041\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0031\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0029\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0028\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0027\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0027\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "16384\n",
      "Model is on: cuda:0\n",
      "Epoch 1/100\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0014\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 9/100\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 10/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 11/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 12/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 13/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 14/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 15/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 16/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 17/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 18/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 19/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 20/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 21/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 22/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 23/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 24/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 25/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 26/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 27/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 28/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 29/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 30/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 31/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 32/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 33/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 34/100\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 35/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 36/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 37/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 38/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 39/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 40/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 41/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 42/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 43/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 44/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 45/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 46/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 47/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 48/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 49/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 50/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 51/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 52/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 53/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 54/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 55/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 56/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 57/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 58/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 59/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 60/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 61/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 62/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 63/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 64/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 65/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 66/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 67/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 68/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 69/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 70/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 71/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 72/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 73/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 74/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 75/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 76/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 77/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 78/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 79/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 80/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 81/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 82/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 83/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 84/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 85/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 86/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 87/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 88/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 89/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 90/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 91/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 92/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 93/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 94/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 95/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 96/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 97/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 98/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 99/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 100/100\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "num_pairs_to_check = np.geomspace(2**6,2**14,8).astype(int)\n",
    "X_train, y_train = make_classification(\n",
    "    n_samples=100, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and fit the generator\n",
    "generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "generator.fit(X_train, y_train)\n",
    "X_cal, y_cal = generator.generate(n=100)\n",
    "tau_corrs_LAC, skills_LAC, conformities_LAC, models_LAC = conduct_oracle_experiment(LACConformityScore(), num_pairs_to_check, generator, X_cal, y_cal)\n",
    "tau_corrs_APS, skills_APC, conformities_APC, models_APC = conduct_oracle_experiment(APSConformityScore(), num_pairs_to_check, generator, X_cal, y_cal)\n",
    "tau_corrs_TopK, skills_TopK, conformities_TopK, models_TopK = conduct_oracle_experiment(TopKConformityScore(), num_pairs_to_check, generator, X_cal, y_cal)\n",
    "# tau_corrs_Naive, skills_Naive, conformities_Naive = conduct_oracle_experiment(NaiveConformityScore(), num_pairs_to_check, generator, X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5,rc={'text.usetex' : True})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rc('font', **{'family': 'serif'})\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2, sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].set_title(\"LAC\")\n",
    "axes[0].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "axes[0].set_xlabel(r\"No. Pairs\")\n",
    "sns.lineplot(x=num_pairs_to_check, y=tau_corrs_LAC, ax = axes[0])\n",
    "axes[1].set_title(\"APS\")\n",
    "axes[1].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "axes[1].set_xlabel(r\"No. Pairs\")\n",
    "sns.lineplot(x=num_pairs_to_check, y=tau_corrs_APS, ax = axes[1])\n",
    "axes[2].set_title(\"TopK\")\n",
    "axes[2].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "axes[2].set_xlabel(r\"No. Pairs\")\n",
    "sns.lineplot(x=num_pairs_to_check, y=tau_corrs_TopK, ax = axes[2])\n",
    "fig.tight_layout()\n",
    "# axes[1].set_title(\"APS\")\n",
    "# axes[1].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "# axes[1].set_xlabel(r\"No. Pairs\")\n",
    "# sns.lineplot(x=num_pairs_to_check, y=tau_corrs_APS, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\cp_rank\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.5069, 0.4172, 0.2459],\n",
      "        [1.5069, 0.4172, 0.2459]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.5069, 0.4172, 0.2459],\n",
      "        [1.5069, 0.4172, 0.2459]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.5069, 0.4172, 0.2459],\n",
      "        [1.5069, 0.4172, 0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1367, -0.4950, -1.5344]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-2.6466,  2.2308,  1.7689]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "435\n",
      "Epoch 1/250\n",
      "  Train Loss: 0.0505\n",
      "  Val Loss: 0.0504\n",
      "Epoch 2/250\n",
      "  Train Loss: 0.0504\n",
      "  Val Loss: 0.0503\n",
      "Epoch 3/250\n",
      "  Train Loss: 0.0502\n",
      "  Val Loss: 0.0502\n",
      "Epoch 4/250\n",
      "  Train Loss: 0.0501\n",
      "  Val Loss: 0.0501\n",
      "Epoch 5/250\n",
      "  Train Loss: 0.0500\n",
      "  Val Loss: 0.0500\n",
      "Epoch 6/250\n",
      "  Train Loss: 0.0499\n",
      "  Val Loss: 0.0499\n",
      "Epoch 7/250\n",
      "  Train Loss: 0.0499\n",
      "  Val Loss: 0.0498\n",
      "Epoch 8/250\n",
      "  Train Loss: 0.0498\n",
      "  Val Loss: 0.0497\n",
      "Epoch 9/250\n",
      "  Train Loss: 0.0497\n",
      "  Val Loss: 0.0497\n",
      "Epoch 10/250\n",
      "  Train Loss: 0.0497\n",
      "  Val Loss: 0.0496\n",
      "Epoch 11/250\n",
      "  Train Loss: 0.0496\n",
      "  Val Loss: 0.0496\n",
      "Epoch 12/250\n",
      "  Train Loss: 0.0496\n",
      "  Val Loss: 0.0495\n",
      "Epoch 13/250\n",
      "  Train Loss: 0.0495\n",
      "  Val Loss: 0.0495\n",
      "Epoch 14/250\n",
      "  Train Loss: 0.0495\n",
      "  Val Loss: 0.0494\n",
      "Epoch 15/250\n",
      "  Train Loss: 0.0494\n",
      "  Val Loss: 0.0494\n",
      "Epoch 16/250\n",
      "  Train Loss: 0.0494\n",
      "  Val Loss: 0.0494\n",
      "Epoch 17/250\n",
      "  Train Loss: 0.0494\n",
      "  Val Loss: 0.0493\n",
      "Epoch 18/250\n",
      "  Train Loss: 0.0493\n",
      "  Val Loss: 0.0493\n",
      "Epoch 19/250\n",
      "  Train Loss: 0.0493\n",
      "  Val Loss: 0.0493\n",
      "Epoch 20/250\n",
      "  Train Loss: 0.0493\n",
      "  Val Loss: 0.0492\n",
      "Epoch 21/250\n",
      "  Train Loss: 0.0492\n",
      "  Val Loss: 0.0492\n",
      "Epoch 22/250\n",
      "  Train Loss: 0.0492\n",
      "  Val Loss: 0.0492\n",
      "Epoch 23/250\n",
      "  Train Loss: 0.0492\n",
      "  Val Loss: 0.0491\n",
      "Epoch 24/250\n",
      "  Train Loss: 0.0491\n",
      "  Val Loss: 0.0491\n",
      "Epoch 25/250\n",
      "  Train Loss: 0.0491\n",
      "  Val Loss: 0.0491\n",
      "Epoch 26/250\n",
      "  Train Loss: 0.0491\n",
      "  Val Loss: 0.0491\n",
      "Epoch 27/250\n",
      "  Train Loss: 0.0491\n",
      "  Val Loss: 0.0490\n",
      "Epoch 28/250\n",
      "  Train Loss: 0.0490\n",
      "  Val Loss: 0.0490\n",
      "Epoch 29/250\n",
      "  Train Loss: 0.0490\n",
      "  Val Loss: 0.0490\n",
      "Epoch 30/250\n",
      "  Train Loss: 0.0490\n",
      "  Val Loss: 0.0489\n",
      "Epoch 31/250\n",
      "  Train Loss: 0.0490\n",
      "  Val Loss: 0.0489\n",
      "Epoch 32/250\n",
      "  Train Loss: 0.0489\n",
      "  Val Loss: 0.0489\n",
      "Epoch 33/250\n",
      "  Train Loss: 0.0489\n",
      "  Val Loss: 0.0489\n",
      "Epoch 34/250\n",
      "  Train Loss: 0.0489\n",
      "  Val Loss: 0.0488\n",
      "Epoch 35/250\n",
      "  Train Loss: 0.0488\n",
      "  Val Loss: 0.0488\n",
      "Epoch 36/250\n",
      "  Train Loss: 0.0488\n",
      "  Val Loss: 0.0488\n",
      "Epoch 37/250\n",
      "  Train Loss: 0.0488\n",
      "  Val Loss: 0.0487\n",
      "Epoch 38/250\n",
      "  Train Loss: 0.0488\n",
      "  Val Loss: 0.0487\n",
      "Epoch 39/250\n",
      "  Train Loss: 0.0487\n",
      "  Val Loss: 0.0487\n",
      "Epoch 40/250\n",
      "  Train Loss: 0.0487\n",
      "  Val Loss: 0.0486\n",
      "Epoch 41/250\n",
      "  Train Loss: 0.0487\n",
      "  Val Loss: 0.0486\n",
      "Epoch 42/250\n",
      "  Train Loss: 0.0486\n",
      "  Val Loss: 0.0486\n",
      "Epoch 43/250\n",
      "  Train Loss: 0.0486\n",
      "  Val Loss: 0.0485\n",
      "Epoch 44/250\n",
      "  Train Loss: 0.0485\n",
      "  Val Loss: 0.0485\n",
      "Epoch 45/250\n",
      "  Train Loss: 0.0485\n",
      "  Val Loss: 0.0485\n",
      "Epoch 46/250\n",
      "  Train Loss: 0.0485\n",
      "  Val Loss: 0.0484\n",
      "Epoch 47/250\n",
      "  Train Loss: 0.0484\n",
      "  Val Loss: 0.0484\n",
      "Epoch 48/250\n",
      "  Train Loss: 0.0484\n",
      "  Val Loss: 0.0483\n",
      "Epoch 49/250\n",
      "  Train Loss: 0.0483\n",
      "  Val Loss: 0.0483\n",
      "Epoch 50/250\n",
      "  Train Loss: 0.0483\n",
      "  Val Loss: 0.0482\n",
      "Epoch 51/250\n",
      "  Train Loss: 0.0482\n",
      "  Val Loss: 0.0481\n",
      "Epoch 52/250\n",
      "  Train Loss: 0.0482\n",
      "  Val Loss: 0.0481\n",
      "Epoch 53/250\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0480\n",
      "Epoch 54/250\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0480\n",
      "Epoch 55/250\n",
      "  Train Loss: 0.0480\n",
      "  Val Loss: 0.0479\n",
      "Epoch 56/250\n",
      "  Train Loss: 0.0479\n",
      "  Val Loss: 0.0479\n",
      "Epoch 57/250\n",
      "  Train Loss: 0.0479\n",
      "  Val Loss: 0.0478\n",
      "Epoch 58/250\n",
      "  Train Loss: 0.0478\n",
      "  Val Loss: 0.0478\n",
      "Epoch 59/250\n",
      "  Train Loss: 0.0478\n",
      "  Val Loss: 0.0477\n",
      "Epoch 60/250\n",
      "  Train Loss: 0.0477\n",
      "  Val Loss: 0.0476\n",
      "Epoch 61/250\n",
      "  Train Loss: 0.0476\n",
      "  Val Loss: 0.0476\n",
      "Epoch 62/250\n",
      "  Train Loss: 0.0476\n",
      "  Val Loss: 0.0475\n",
      "Epoch 63/250\n",
      "  Train Loss: 0.0475\n",
      "  Val Loss: 0.0474\n",
      "Epoch 64/250\n",
      "  Train Loss: 0.0474\n",
      "  Val Loss: 0.0474\n",
      "Epoch 65/250\n",
      "  Train Loss: 0.0474\n",
      "  Val Loss: 0.0473\n",
      "Epoch 66/250\n",
      "  Train Loss: 0.0473\n",
      "  Val Loss: 0.0472\n",
      "Epoch 67/250\n",
      "  Train Loss: 0.0472\n",
      "  Val Loss: 0.0471\n",
      "Epoch 68/250\n",
      "  Train Loss: 0.0471\n",
      "  Val Loss: 0.0470\n",
      "Epoch 69/250\n",
      "  Train Loss: 0.0470\n",
      "  Val Loss: 0.0470\n",
      "Epoch 70/250\n",
      "  Train Loss: 0.0470\n",
      "  Val Loss: 0.0469\n",
      "Epoch 71/250\n",
      "  Train Loss: 0.0469\n",
      "  Val Loss: 0.0468\n",
      "Epoch 72/250\n",
      "  Train Loss: 0.0468\n",
      "  Val Loss: 0.0467\n",
      "Epoch 73/250\n",
      "  Train Loss: 0.0467\n",
      "  Val Loss: 0.0466\n",
      "Epoch 74/250\n",
      "  Train Loss: 0.0466\n",
      "  Val Loss: 0.0465\n",
      "Epoch 75/250\n",
      "  Train Loss: 0.0465\n",
      "  Val Loss: 0.0464\n",
      "Epoch 76/250\n",
      "  Train Loss: 0.0464\n",
      "  Val Loss: 0.0463\n",
      "Epoch 77/250\n",
      "  Train Loss: 0.0463\n",
      "  Val Loss: 0.0462\n",
      "Epoch 78/250\n",
      "  Train Loss: 0.0462\n",
      "  Val Loss: 0.0461\n",
      "Epoch 79/250\n",
      "  Train Loss: 0.0461\n",
      "  Val Loss: 0.0460\n",
      "Epoch 80/250\n",
      "  Train Loss: 0.0460\n",
      "  Val Loss: 0.0458\n",
      "Epoch 81/250\n",
      "  Train Loss: 0.0458\n",
      "  Val Loss: 0.0457\n",
      "Epoch 82/250\n",
      "  Train Loss: 0.0457\n",
      "  Val Loss: 0.0456\n",
      "Epoch 83/250\n",
      "  Train Loss: 0.0456\n",
      "  Val Loss: 0.0455\n",
      "Epoch 84/250\n",
      "  Train Loss: 0.0455\n",
      "  Val Loss: 0.0454\n",
      "Epoch 85/250\n",
      "  Train Loss: 0.0453\n",
      "  Val Loss: 0.0452\n",
      "Epoch 86/250\n",
      "  Train Loss: 0.0452\n",
      "  Val Loss: 0.0451\n",
      "Epoch 87/250\n",
      "  Train Loss: 0.0451\n",
      "  Val Loss: 0.0449\n",
      "Epoch 88/250\n",
      "  Train Loss: 0.0449\n",
      "  Val Loss: 0.0448\n",
      "Epoch 89/250\n",
      "  Train Loss: 0.0448\n",
      "  Val Loss: 0.0447\n",
      "Epoch 90/250\n",
      "  Train Loss: 0.0447\n",
      "  Val Loss: 0.0445\n",
      "Epoch 91/250\n",
      "  Train Loss: 0.0445\n",
      "  Val Loss: 0.0444\n",
      "Epoch 92/250\n",
      "  Train Loss: 0.0444\n",
      "  Val Loss: 0.0442\n",
      "Epoch 93/250\n",
      "  Train Loss: 0.0442\n",
      "  Val Loss: 0.0441\n",
      "Epoch 94/250\n",
      "  Train Loss: 0.0441\n",
      "  Val Loss: 0.0439\n",
      "Epoch 95/250\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.0438\n",
      "Epoch 96/250\n",
      "  Train Loss: 0.0437\n",
      "  Val Loss: 0.0436\n",
      "Epoch 97/250\n",
      "  Train Loss: 0.0436\n",
      "  Val Loss: 0.0434\n",
      "Epoch 98/250\n",
      "  Train Loss: 0.0434\n",
      "  Val Loss: 0.0433\n",
      "Epoch 99/250\n",
      "  Train Loss: 0.0432\n",
      "  Val Loss: 0.0431\n",
      "Epoch 100/250\n",
      "  Train Loss: 0.0431\n",
      "  Val Loss: 0.0429\n",
      "Epoch 101/250\n",
      "  Train Loss: 0.0429\n",
      "  Val Loss: 0.0427\n",
      "Epoch 102/250\n",
      "  Train Loss: 0.0427\n",
      "  Val Loss: 0.0426\n",
      "Epoch 103/250\n",
      "  Train Loss: 0.0426\n",
      "  Val Loss: 0.0424\n",
      "Epoch 104/250\n",
      "  Train Loss: 0.0424\n",
      "  Val Loss: 0.0422\n",
      "Epoch 105/250\n",
      "  Train Loss: 0.0422\n",
      "  Val Loss: 0.0420\n",
      "Epoch 106/250\n",
      "  Train Loss: 0.0420\n",
      "  Val Loss: 0.0419\n",
      "Epoch 107/250\n",
      "  Train Loss: 0.0419\n",
      "  Val Loss: 0.0417\n",
      "Epoch 108/250\n",
      "  Train Loss: 0.0417\n",
      "  Val Loss: 0.0415\n",
      "Epoch 109/250\n",
      "  Train Loss: 0.0415\n",
      "  Val Loss: 0.0413\n",
      "Epoch 110/250\n",
      "  Train Loss: 0.0413\n",
      "  Val Loss: 0.0412\n",
      "Epoch 111/250\n",
      "  Train Loss: 0.0411\n",
      "  Val Loss: 0.0410\n",
      "Epoch 112/250\n",
      "  Train Loss: 0.0410\n",
      "  Val Loss: 0.0408\n",
      "Epoch 113/250\n",
      "  Train Loss: 0.0408\n",
      "  Val Loss: 0.0406\n",
      "Epoch 114/250\n",
      "  Train Loss: 0.0406\n",
      "  Val Loss: 0.0405\n",
      "Epoch 115/250\n",
      "  Train Loss: 0.0404\n",
      "  Val Loss: 0.0403\n",
      "Epoch 116/250\n",
      "  Train Loss: 0.0403\n",
      "  Val Loss: 0.0401\n",
      "Epoch 117/250\n",
      "  Train Loss: 0.0401\n",
      "  Val Loss: 0.0399\n",
      "Epoch 118/250\n",
      "  Train Loss: 0.0399\n",
      "  Val Loss: 0.0398\n",
      "Epoch 119/250\n",
      "  Train Loss: 0.0398\n",
      "  Val Loss: 0.0396\n",
      "Epoch 120/250\n",
      "  Train Loss: 0.0396\n",
      "  Val Loss: 0.0395\n",
      "Epoch 121/250\n",
      "  Train Loss: 0.0394\n",
      "  Val Loss: 0.0393\n",
      "Epoch 122/250\n",
      "  Train Loss: 0.0393\n",
      "  Val Loss: 0.0391\n",
      "Epoch 123/250\n",
      "  Train Loss: 0.0391\n",
      "  Val Loss: 0.0390\n",
      "Epoch 124/250\n",
      "  Train Loss: 0.0390\n",
      "  Val Loss: 0.0388\n",
      "Epoch 125/250\n",
      "  Train Loss: 0.0388\n",
      "  Val Loss: 0.0387\n",
      "Epoch 126/250\n",
      "  Train Loss: 0.0387\n",
      "  Val Loss: 0.0386\n",
      "Epoch 127/250\n",
      "  Train Loss: 0.0386\n",
      "  Val Loss: 0.0384\n",
      "Epoch 128/250\n",
      "  Train Loss: 0.0384\n",
      "  Val Loss: 0.0383\n",
      "Epoch 129/250\n",
      "  Train Loss: 0.0383\n",
      "  Val Loss: 0.0381\n",
      "Epoch 130/250\n",
      "  Train Loss: 0.0382\n",
      "  Val Loss: 0.0380\n",
      "Epoch 131/250\n",
      "  Train Loss: 0.0380\n",
      "  Val Loss: 0.0379\n",
      "Epoch 132/250\n",
      "  Train Loss: 0.0379\n",
      "  Val Loss: 0.0378\n",
      "Epoch 133/250\n",
      "  Train Loss: 0.0378\n",
      "  Val Loss: 0.0376\n",
      "Epoch 134/250\n",
      "  Train Loss: 0.0377\n",
      "  Val Loss: 0.0375\n",
      "Epoch 135/250\n",
      "  Train Loss: 0.0375\n",
      "  Val Loss: 0.0374\n",
      "Epoch 136/250\n",
      "  Train Loss: 0.0374\n",
      "  Val Loss: 0.0373\n",
      "Epoch 137/250\n",
      "  Train Loss: 0.0373\n",
      "  Val Loss: 0.0372\n",
      "Epoch 138/250\n",
      "  Train Loss: 0.0372\n",
      "  Val Loss: 0.0371\n",
      "Epoch 139/250\n",
      "  Train Loss: 0.0371\n",
      "  Val Loss: 0.0370\n",
      "Epoch 140/250\n",
      "  Train Loss: 0.0370\n",
      "  Val Loss: 0.0369\n",
      "Epoch 141/250\n",
      "  Train Loss: 0.0369\n",
      "  Val Loss: 0.0368\n",
      "Epoch 142/250\n",
      "  Train Loss: 0.0368\n",
      "  Val Loss: 0.0367\n",
      "Epoch 143/250\n",
      "  Train Loss: 0.0367\n",
      "  Val Loss: 0.0366\n",
      "Epoch 144/250\n",
      "  Train Loss: 0.0366\n",
      "  Val Loss: 0.0365\n",
      "Epoch 145/250\n",
      "  Train Loss: 0.0365\n",
      "  Val Loss: 0.0364\n",
      "Epoch 146/250\n",
      "  Train Loss: 0.0364\n",
      "  Val Loss: 0.0363\n",
      "Epoch 147/250\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0362\n",
      "Epoch 148/250\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0362\n",
      "Epoch 149/250\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0361\n",
      "Epoch 150/250\n",
      "  Train Loss: 0.0361\n",
      "  Val Loss: 0.0360\n",
      "Epoch 151/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0359\n",
      "Epoch 152/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0358\n",
      "Epoch 153/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0358\n",
      "Epoch 154/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0357\n",
      "Epoch 155/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0356\n",
      "Epoch 156/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0355\n",
      "Epoch 157/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0355\n",
      "Epoch 158/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0354\n",
      "Epoch 159/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0353\n",
      "Epoch 160/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0353\n",
      "Epoch 161/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0352\n",
      "Epoch 162/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0351\n",
      "Epoch 163/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0351\n",
      "Epoch 164/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0350\n",
      "Epoch 165/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0349\n",
      "Epoch 166/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0349\n",
      "Epoch 167/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 168/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 169/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0347\n",
      "Epoch 170/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 171/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 172/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 173/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 174/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 175/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 176/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 177/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 178/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 179/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0340\n",
      "Epoch 180/250\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0340\n",
      "Epoch 181/250\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0339\n",
      "Epoch 182/250\n",
      "  Train Loss: 0.0339\n",
      "  Val Loss: 0.0338\n",
      "Epoch 183/250\n",
      "  Train Loss: 0.0338\n",
      "  Val Loss: 0.0338\n",
      "Epoch 184/250\n",
      "  Train Loss: 0.0338\n",
      "  Val Loss: 0.0337\n",
      "Epoch 185/250\n",
      "  Train Loss: 0.0337\n",
      "  Val Loss: 0.0336\n",
      "Epoch 186/250\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0335\n",
      "Epoch 187/250\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0335\n",
      "Epoch 188/250\n",
      "  Train Loss: 0.0335\n",
      "  Val Loss: 0.0334\n",
      "Epoch 189/250\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0333\n",
      "Epoch 190/250\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0333\n",
      "Epoch 191/250\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0332\n",
      "Epoch 192/250\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0331\n",
      "Epoch 193/250\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0330\n",
      "Epoch 194/250\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0330\n",
      "Epoch 195/250\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0329\n",
      "Epoch 196/250\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0328\n",
      "Epoch 197/250\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0327\n",
      "Epoch 198/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0327\n",
      "Epoch 199/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0326\n",
      "Epoch 200/250\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0325\n",
      "Epoch 201/250\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0324\n",
      "Epoch 202/250\n",
      "  Train Loss: 0.0324\n",
      "  Val Loss: 0.0323\n",
      "Epoch 203/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0323\n",
      "Epoch 204/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0322\n",
      "Epoch 205/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0321\n",
      "Epoch 206/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0320\n",
      "Epoch 207/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0319\n",
      "Epoch 208/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0318\n",
      "Epoch 209/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0317\n",
      "Epoch 210/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0316\n",
      "Epoch 211/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0316\n",
      "Epoch 212/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0315\n",
      "Epoch 213/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 214/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 215/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0312\n",
      "Epoch 216/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 217/250\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0310\n",
      "Epoch 218/250\n",
      "  Train Loss: 0.0310\n",
      "  Val Loss: 0.0309\n",
      "Epoch 219/250\n",
      "  Train Loss: 0.0309\n",
      "  Val Loss: 0.0308\n",
      "Epoch 220/250\n",
      "  Train Loss: 0.0308\n",
      "  Val Loss: 0.0307\n",
      "Epoch 221/250\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0306\n",
      "Epoch 222/250\n",
      "  Train Loss: 0.0306\n",
      "  Val Loss: 0.0305\n",
      "Epoch 223/250\n",
      "  Train Loss: 0.0305\n",
      "  Val Loss: 0.0304\n",
      "Epoch 224/250\n",
      "  Train Loss: 0.0304\n",
      "  Val Loss: 0.0303\n",
      "Epoch 225/250\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0302\n",
      "Epoch 226/250\n",
      "  Train Loss: 0.0302\n",
      "  Val Loss: 0.0301\n",
      "Epoch 227/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0300\n",
      "Epoch 228/250\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0299\n",
      "Epoch 229/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0298\n",
      "Epoch 230/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0297\n",
      "Epoch 231/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0296\n",
      "Epoch 232/250\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0295\n",
      "Epoch 233/250\n",
      "  Train Loss: 0.0295\n",
      "  Val Loss: 0.0294\n",
      "Epoch 234/250\n",
      "  Train Loss: 0.0294\n",
      "  Val Loss: 0.0293\n",
      "Epoch 235/250\n",
      "  Train Loss: 0.0293\n",
      "  Val Loss: 0.0292\n",
      "Epoch 236/250\n",
      "  Train Loss: 0.0292\n",
      "  Val Loss: 0.0291\n",
      "Epoch 237/250\n",
      "  Train Loss: 0.0291\n",
      "  Val Loss: 0.0290\n",
      "Epoch 238/250\n",
      "  Train Loss: 0.0290\n",
      "  Val Loss: 0.0289\n",
      "Epoch 239/250\n",
      "  Train Loss: 0.0289\n",
      "  Val Loss: 0.0288\n",
      "Epoch 240/250\n",
      "  Train Loss: 0.0288\n",
      "  Val Loss: 0.0287\n",
      "Epoch 241/250\n",
      "  Train Loss: 0.0287\n",
      "  Val Loss: 0.0286\n",
      "Epoch 242/250\n",
      "  Train Loss: 0.0286\n",
      "  Val Loss: 0.0285\n",
      "Epoch 243/250\n",
      "  Train Loss: 0.0286\n",
      "  Val Loss: 0.0285\n",
      "Epoch 244/250\n",
      "  Train Loss: 0.0285\n",
      "  Val Loss: 0.0284\n",
      "Epoch 245/250\n",
      "  Train Loss: 0.0284\n",
      "  Val Loss: 0.0283\n",
      "Epoch 246/250\n",
      "  Train Loss: 0.0283\n",
      "  Val Loss: 0.0282\n",
      "Epoch 247/250\n",
      "  Train Loss: 0.0282\n",
      "  Val Loss: 0.0281\n",
      "Epoch 248/250\n",
      "  Train Loss: 0.0281\n",
      "  Val Loss: 0.0280\n",
      "Epoch 249/250\n",
      "  Train Loss: 0.0280\n",
      "  Val Loss: 0.0279\n",
      "Epoch 250/250\n",
      "  Train Loss: 0.0280\n",
      "  Val Loss: 0.0279\n"
     ]
    }
   ],
   "source": [
    "X_seed, y_seed = make_classification(n_samples=1000, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42)\n",
    "conformity_score = APSConformityScore()\n",
    "generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "generator.fit(X_seed, y_seed)\n",
    "X_cal, y_cal = generator.generate(n=100)\n",
    "mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "# create mapie classifier for conformity scores\n",
    "mapie_clf.fit(X_cal, y_cal)\n",
    "# create \n",
    "oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "\n",
    "# generate all possible pairs for a couple of instances\n",
    "n_instances = 10\n",
    "n_classes = len(generator.classes_)\n",
    "n_obs = n_instances * n_classes\n",
    "X_train = generator.generate_instances(n_instances).repeat(n_classes, axis=0)\n",
    "y_train = np.tile(generator.classes_, n_instances)\n",
    "conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "X_sorted = X_train[sort_idx]\n",
    "y_sorted = y_train[sort_idx]\n",
    "conformities_sorted = conformities[sort_idx]\n",
    "\n",
    "X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "y_pairs = np.expand_dims(y_pairs, axis=-1)\n",
    "\n",
    "\n",
    "ds = LabelPairDataset()\n",
    "ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "for x,y in ds:\n",
    "    print(x,y)\n",
    "print(len(ds))\n",
    "model = LabelRankingModel(input_dim=generator.n_features_, hidden_dims=3*[generator.n_features_], activations=[torch.nn.Sigmoid(), SortLayer(),torch.nn.Identity()], output_dim=len(generator.classes_))\n",
    "\n",
    "pair_loader = DataLoader(ds, batch_size=32)\n",
    "model.num_classes = generator.n_classes_\n",
    "model._fit(pair_loader, val_loader=pair_loader, num_epochs=250, learning_rate=0.001, verbose=True)\n",
    "\n",
    "\n",
    "# # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "# X_test, y_test = X_train, y_train\n",
    "# conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "# skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "# tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "# print(\"in-sample: \", tau_corr)\n",
    "# X_test, y_test = generator.generate(n=10)\n",
    "# conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "# skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "# tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "# print(\"out-of-sample: \", tau_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[0.6766, 0.6402, 0.8921],\n",
      "        [0.6766, 0.6402, 0.8921]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[0.6766, 0.6402, 0.8921],\n",
      "        [0.6766, 0.6402, 0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.3553,  1.3900, -2.2718]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[0.6766, 0.6402, 0.8921],\n",
      "        [0.6766, 0.6402, 0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2696, -1.9312, -1.6093]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [2]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[2],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2663,  2.1617, -0.6311]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.6758,  0.1966,  0.4712]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]], device='cuda:0') tensor([[1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]], device='cuda:0') tensor([[1],\n",
      "        [1]], device='cuda:0')\n",
      "14\n",
      "Epoch 1/250\n",
      "  Train Loss: 0.0514\n",
      "  Val Loss: 0.0510\n",
      "Epoch 2/250\n",
      "  Train Loss: 0.0504\n",
      "  Val Loss: 0.0501\n",
      "Epoch 3/250\n",
      "  Train Loss: 0.0496\n",
      "  Val Loss: 0.0493\n",
      "Epoch 4/250\n",
      "  Train Loss: 0.0489\n",
      "  Val Loss: 0.0486\n",
      "Epoch 5/250\n",
      "  Train Loss: 0.0482\n",
      "  Val Loss: 0.0480\n",
      "Epoch 6/250\n",
      "  Train Loss: 0.0477\n",
      "  Val Loss: 0.0475\n",
      "Epoch 7/250\n",
      "  Train Loss: 0.0472\n",
      "  Val Loss: 0.0470\n",
      "Epoch 8/250\n",
      "  Train Loss: 0.0468\n",
      "  Val Loss: 0.0466\n",
      "Epoch 9/250\n",
      "  Train Loss: 0.0464\n",
      "  Val Loss: 0.0463\n",
      "Epoch 10/250\n",
      "  Train Loss: 0.0461\n",
      "  Val Loss: 0.0460\n",
      "Epoch 11/250\n",
      "  Train Loss: 0.0459\n",
      "  Val Loss: 0.0458\n",
      "Epoch 12/250\n",
      "  Train Loss: 0.0457\n",
      "  Val Loss: 0.0456\n",
      "Epoch 13/250\n",
      "  Train Loss: 0.0455\n",
      "  Val Loss: 0.0454\n",
      "Epoch 14/250\n",
      "  Train Loss: 0.0453\n",
      "  Val Loss: 0.0453\n",
      "Epoch 15/250\n",
      "  Train Loss: 0.0452\n",
      "  Val Loss: 0.0452\n",
      "Epoch 16/250\n",
      "  Train Loss: 0.0451\n",
      "  Val Loss: 0.0451\n",
      "Epoch 17/250\n",
      "  Train Loss: 0.0450\n",
      "  Val Loss: 0.0450\n",
      "Epoch 18/250\n",
      "  Train Loss: 0.0449\n",
      "  Val Loss: 0.0449\n",
      "Epoch 19/250\n",
      "  Train Loss: 0.0448\n",
      "  Val Loss: 0.0448\n",
      "Epoch 20/250\n",
      "  Train Loss: 0.0448\n",
      "  Val Loss: 0.0447\n",
      "Epoch 21/250\n",
      "  Train Loss: 0.0447\n",
      "  Val Loss: 0.0446\n",
      "Epoch 22/250\n",
      "  Train Loss: 0.0446\n",
      "  Val Loss: 0.0446\n",
      "Epoch 23/250\n",
      "  Train Loss: 0.0446\n",
      "  Val Loss: 0.0445\n",
      "Epoch 24/250\n",
      "  Train Loss: 0.0445\n",
      "  Val Loss: 0.0444\n",
      "Epoch 25/250\n",
      "  Train Loss: 0.0445\n",
      "  Val Loss: 0.0444\n",
      "Epoch 26/250\n",
      "  Train Loss: 0.0444\n",
      "  Val Loss: 0.0443\n",
      "Epoch 27/250\n",
      "  Train Loss: 0.0443\n",
      "  Val Loss: 0.0443\n",
      "Epoch 28/250\n",
      "  Train Loss: 0.0443\n",
      "  Val Loss: 0.0442\n",
      "Epoch 29/250\n",
      "  Train Loss: 0.0442\n",
      "  Val Loss: 0.0442\n",
      "Epoch 30/250\n",
      "  Train Loss: 0.0442\n",
      "  Val Loss: 0.0441\n",
      "Epoch 31/250\n",
      "  Train Loss: 0.0441\n",
      "  Val Loss: 0.0441\n",
      "Epoch 32/250\n",
      "  Train Loss: 0.0441\n",
      "  Val Loss: 0.0440\n",
      "Epoch 33/250\n",
      "  Train Loss: 0.0440\n",
      "  Val Loss: 0.0440\n",
      "Epoch 34/250\n",
      "  Train Loss: 0.0440\n",
      "  Val Loss: 0.0439\n",
      "Epoch 35/250\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.0439\n",
      "Epoch 36/250\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.0438\n",
      "Epoch 37/250\n",
      "  Train Loss: 0.0438\n",
      "  Val Loss: 0.0437\n",
      "Epoch 38/250\n",
      "  Train Loss: 0.0438\n",
      "  Val Loss: 0.0437\n",
      "Epoch 39/250\n",
      "  Train Loss: 0.0437\n",
      "  Val Loss: 0.0436\n",
      "Epoch 40/250\n",
      "  Train Loss: 0.0437\n",
      "  Val Loss: 0.0436\n",
      "Epoch 41/250\n",
      "  Train Loss: 0.0436\n",
      "  Val Loss: 0.0435\n",
      "Epoch 42/250\n",
      "  Train Loss: 0.0435\n",
      "  Val Loss: 0.0435\n",
      "Epoch 43/250\n",
      "  Train Loss: 0.0435\n",
      "  Val Loss: 0.0434\n",
      "Epoch 44/250\n",
      "  Train Loss: 0.0434\n",
      "  Val Loss: 0.0434\n",
      "Epoch 45/250\n",
      "  Train Loss: 0.0434\n",
      "  Val Loss: 0.0433\n",
      "Epoch 46/250\n",
      "  Train Loss: 0.0433\n",
      "  Val Loss: 0.0433\n",
      "Epoch 47/250\n",
      "  Train Loss: 0.0433\n",
      "  Val Loss: 0.0432\n",
      "Epoch 48/250\n",
      "  Train Loss: 0.0432\n",
      "  Val Loss: 0.0431\n",
      "Epoch 49/250\n",
      "  Train Loss: 0.0431\n",
      "  Val Loss: 0.0431\n",
      "Epoch 50/250\n",
      "  Train Loss: 0.0431\n",
      "  Val Loss: 0.0430\n",
      "Epoch 51/250\n",
      "  Train Loss: 0.0430\n",
      "  Val Loss: 0.0430\n",
      "Epoch 52/250\n",
      "  Train Loss: 0.0430\n",
      "  Val Loss: 0.0429\n",
      "Epoch 53/250\n",
      "  Train Loss: 0.0429\n",
      "  Val Loss: 0.0428\n",
      "Epoch 54/250\n",
      "  Train Loss: 0.0428\n",
      "  Val Loss: 0.0428\n",
      "Epoch 55/250\n",
      "  Train Loss: 0.0428\n",
      "  Val Loss: 0.0427\n",
      "Epoch 56/250\n",
      "  Train Loss: 0.0427\n",
      "  Val Loss: 0.0426\n",
      "Epoch 57/250\n",
      "  Train Loss: 0.0426\n",
      "  Val Loss: 0.0426\n",
      "Epoch 58/250\n",
      "  Train Loss: 0.0426\n",
      "  Val Loss: 0.0425\n",
      "Epoch 59/250\n",
      "  Train Loss: 0.0425\n",
      "  Val Loss: 0.0424\n",
      "Epoch 60/250\n",
      "  Train Loss: 0.0424\n",
      "  Val Loss: 0.0424\n",
      "Epoch 61/250\n",
      "  Train Loss: 0.0424\n",
      "  Val Loss: 0.0423\n",
      "Epoch 62/250\n",
      "  Train Loss: 0.0423\n",
      "  Val Loss: 0.0422\n",
      "Epoch 63/250\n",
      "  Train Loss: 0.0422\n",
      "  Val Loss: 0.0422\n",
      "Epoch 64/250\n",
      "  Train Loss: 0.0422\n",
      "  Val Loss: 0.0421\n",
      "Epoch 65/250\n",
      "  Train Loss: 0.0421\n",
      "  Val Loss: 0.0420\n",
      "Epoch 66/250\n",
      "  Train Loss: 0.0420\n",
      "  Val Loss: 0.0419\n",
      "Epoch 67/250\n",
      "  Train Loss: 0.0419\n",
      "  Val Loss: 0.0419\n",
      "Epoch 68/250\n",
      "  Train Loss: 0.0419\n",
      "  Val Loss: 0.0418\n",
      "Epoch 69/250\n",
      "  Train Loss: 0.0418\n",
      "  Val Loss: 0.0417\n",
      "Epoch 70/250\n",
      "  Train Loss: 0.0417\n",
      "  Val Loss: 0.0416\n",
      "Epoch 71/250\n",
      "  Train Loss: 0.0416\n",
      "  Val Loss: 0.0415\n",
      "Epoch 72/250\n",
      "  Train Loss: 0.0415\n",
      "  Val Loss: 0.0415\n",
      "Epoch 73/250\n",
      "  Train Loss: 0.0415\n",
      "  Val Loss: 0.0414\n",
      "Epoch 74/250\n",
      "  Train Loss: 0.0414\n",
      "  Val Loss: 0.0413\n",
      "Epoch 75/250\n",
      "  Train Loss: 0.0413\n",
      "  Val Loss: 0.0412\n",
      "Epoch 76/250\n",
      "  Train Loss: 0.0412\n",
      "  Val Loss: 0.0411\n",
      "Epoch 77/250\n",
      "  Train Loss: 0.0411\n",
      "  Val Loss: 0.0410\n",
      "Epoch 78/250\n",
      "  Train Loss: 0.0410\n",
      "  Val Loss: 0.0409\n",
      "Epoch 79/250\n",
      "  Train Loss: 0.0409\n",
      "  Val Loss: 0.0409\n",
      "Epoch 80/250\n",
      "  Train Loss: 0.0409\n",
      "  Val Loss: 0.0408\n",
      "Epoch 81/250\n",
      "  Train Loss: 0.0408\n",
      "  Val Loss: 0.0407\n",
      "Epoch 82/250\n",
      "  Train Loss: 0.0407\n",
      "  Val Loss: 0.0406\n",
      "Epoch 83/250\n",
      "  Train Loss: 0.0406\n",
      "  Val Loss: 0.0405\n",
      "Epoch 84/250\n",
      "  Train Loss: 0.0405\n",
      "  Val Loss: 0.0404\n",
      "Epoch 85/250\n",
      "  Train Loss: 0.0404\n",
      "  Val Loss: 0.0403\n",
      "Epoch 86/250\n",
      "  Train Loss: 0.0403\n",
      "  Val Loss: 0.0402\n",
      "Epoch 87/250\n",
      "  Train Loss: 0.0402\n",
      "  Val Loss: 0.0401\n",
      "Epoch 88/250\n",
      "  Train Loss: 0.0401\n",
      "  Val Loss: 0.0400\n",
      "Epoch 89/250\n",
      "  Train Loss: 0.0400\n",
      "  Val Loss: 0.0399\n",
      "Epoch 90/250\n",
      "  Train Loss: 0.0399\n",
      "  Val Loss: 0.0398\n",
      "Epoch 91/250\n",
      "  Train Loss: 0.0398\n",
      "  Val Loss: 0.0397\n",
      "Epoch 92/250\n",
      "  Train Loss: 0.0397\n",
      "  Val Loss: 0.0396\n",
      "Epoch 93/250\n",
      "  Train Loss: 0.0396\n",
      "  Val Loss: 0.0395\n",
      "Epoch 94/250\n",
      "  Train Loss: 0.0395\n",
      "  Val Loss: 0.0394\n",
      "Epoch 95/250\n",
      "  Train Loss: 0.0394\n",
      "  Val Loss: 0.0393\n",
      "Epoch 96/250\n",
      "  Train Loss: 0.0393\n",
      "  Val Loss: 0.0392\n",
      "Epoch 97/250\n",
      "  Train Loss: 0.0392\n",
      "  Val Loss: 0.0391\n",
      "Epoch 98/250\n",
      "  Train Loss: 0.0391\n",
      "  Val Loss: 0.0390\n",
      "Epoch 99/250\n",
      "  Train Loss: 0.0390\n",
      "  Val Loss: 0.0389\n",
      "Epoch 100/250\n",
      "  Train Loss: 0.0389\n",
      "  Val Loss: 0.0388\n",
      "Epoch 101/250\n",
      "  Train Loss: 0.0387\n",
      "  Val Loss: 0.0386\n",
      "Epoch 102/250\n",
      "  Train Loss: 0.0386\n",
      "  Val Loss: 0.0385\n",
      "Epoch 103/250\n",
      "  Train Loss: 0.0385\n",
      "  Val Loss: 0.0384\n",
      "Epoch 104/250\n",
      "  Train Loss: 0.0384\n",
      "  Val Loss: 0.0383\n",
      "Epoch 105/250\n",
      "  Train Loss: 0.0383\n",
      "  Val Loss: 0.0382\n",
      "Epoch 106/250\n",
      "  Train Loss: 0.0382\n",
      "  Val Loss: 0.0381\n",
      "Epoch 107/250\n",
      "  Train Loss: 0.0381\n",
      "  Val Loss: 0.0380\n",
      "Epoch 108/250\n",
      "  Train Loss: 0.0380\n",
      "  Val Loss: 0.0378\n",
      "Epoch 109/250\n",
      "  Train Loss: 0.0378\n",
      "  Val Loss: 0.0377\n",
      "Epoch 110/250\n",
      "  Train Loss: 0.0377\n",
      "  Val Loss: 0.0376\n",
      "Epoch 111/250\n",
      "  Train Loss: 0.0376\n",
      "  Val Loss: 0.0375\n",
      "Epoch 112/250\n",
      "  Train Loss: 0.0375\n",
      "  Val Loss: 0.0374\n",
      "Epoch 113/250\n",
      "  Train Loss: 0.0374\n",
      "  Val Loss: 0.0373\n",
      "Epoch 114/250\n",
      "  Train Loss: 0.0373\n",
      "  Val Loss: 0.0371\n",
      "Epoch 115/250\n",
      "  Train Loss: 0.0371\n",
      "  Val Loss: 0.0370\n",
      "Epoch 116/250\n",
      "  Train Loss: 0.0370\n",
      "  Val Loss: 0.0369\n",
      "Epoch 117/250\n",
      "  Train Loss: 0.0369\n",
      "  Val Loss: 0.0368\n",
      "Epoch 118/250\n",
      "  Train Loss: 0.0368\n",
      "  Val Loss: 0.0367\n",
      "Epoch 119/250\n",
      "  Train Loss: 0.0367\n",
      "  Val Loss: 0.0366\n",
      "Epoch 120/250\n",
      "  Train Loss: 0.0365\n",
      "  Val Loss: 0.0364\n",
      "Epoch 121/250\n",
      "  Train Loss: 0.0364\n",
      "  Val Loss: 0.0363\n",
      "Epoch 122/250\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0362\n",
      "Epoch 123/250\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0361\n",
      "Epoch 124/250\n",
      "  Train Loss: 0.0361\n",
      "  Val Loss: 0.0360\n",
      "Epoch 125/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0358\n",
      "Epoch 126/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0357\n",
      "Epoch 127/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0356\n",
      "Epoch 128/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0355\n",
      "Epoch 129/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0354\n",
      "Epoch 130/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0353\n",
      "Epoch 131/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0351\n",
      "Epoch 132/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0350\n",
      "Epoch 133/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0349\n",
      "Epoch 134/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 135/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 136/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 137/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 138/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 139/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 140/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 141/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0340\n",
      "Epoch 142/250\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0339\n",
      "Epoch 143/250\n",
      "  Train Loss: 0.0339\n",
      "  Val Loss: 0.0338\n",
      "Epoch 144/250\n",
      "  Train Loss: 0.0338\n",
      "  Val Loss: 0.0337\n",
      "Epoch 145/250\n",
      "  Train Loss: 0.0337\n",
      "  Val Loss: 0.0336\n",
      "Epoch 146/250\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0335\n",
      "Epoch 147/250\n",
      "  Train Loss: 0.0335\n",
      "  Val Loss: 0.0334\n",
      "Epoch 148/250\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0333\n",
      "Epoch 149/250\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0333\n",
      "Epoch 150/250\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0332\n",
      "Epoch 151/250\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0331\n",
      "Epoch 152/250\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0330\n",
      "Epoch 153/250\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0329\n",
      "Epoch 154/250\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0328\n",
      "Epoch 155/250\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0327\n",
      "Epoch 156/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0326\n",
      "Epoch 157/250\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0325\n",
      "Epoch 158/250\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0325\n",
      "Epoch 159/250\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0324\n",
      "Epoch 160/250\n",
      "  Train Loss: 0.0324\n",
      "  Val Loss: 0.0323\n",
      "Epoch 161/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0322\n",
      "Epoch 162/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0322\n",
      "Epoch 163/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0321\n",
      "Epoch 164/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0320\n",
      "Epoch 165/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0319\n",
      "Epoch 166/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0319\n",
      "Epoch 167/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0318\n",
      "Epoch 168/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0318\n",
      "Epoch 169/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0317\n",
      "Epoch 170/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0316\n",
      "Epoch 171/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0316\n",
      "Epoch 172/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0315\n",
      "Epoch 173/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 174/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 175/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 176/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 177/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0312\n",
      "Epoch 178/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0312\n",
      "Epoch 179/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 180/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 181/250\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0310\n",
      "Epoch 182/250\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0310\n",
      "Epoch 183/250\n",
      "  Train Loss: 0.0310\n",
      "  Val Loss: 0.0310\n",
      "Epoch 184/250\n",
      "  Train Loss: 0.0310\n",
      "  Val Loss: 0.0309\n",
      "Epoch 185/250\n",
      "  Train Loss: 0.0309\n",
      "  Val Loss: 0.0309\n",
      "Epoch 186/250\n",
      "  Train Loss: 0.0309\n",
      "  Val Loss: 0.0308\n",
      "Epoch 187/250\n",
      "  Train Loss: 0.0308\n",
      "  Val Loss: 0.0308\n",
      "Epoch 188/250\n",
      "  Train Loss: 0.0308\n",
      "  Val Loss: 0.0307\n",
      "Epoch 189/250\n",
      "  Train Loss: 0.0308\n",
      "  Val Loss: 0.0307\n",
      "Epoch 190/250\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0307\n",
      "Epoch 191/250\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0306\n",
      "Epoch 192/250\n",
      "  Train Loss: 0.0307\n",
      "  Val Loss: 0.0306\n",
      "Epoch 193/250\n",
      "  Train Loss: 0.0306\n",
      "  Val Loss: 0.0306\n",
      "Epoch 194/250\n",
      "  Train Loss: 0.0306\n",
      "  Val Loss: 0.0305\n",
      "Epoch 195/250\n",
      "  Train Loss: 0.0306\n",
      "  Val Loss: 0.0305\n",
      "Epoch 196/250\n",
      "  Train Loss: 0.0305\n",
      "  Val Loss: 0.0305\n",
      "Epoch 197/250\n",
      "  Train Loss: 0.0305\n",
      "  Val Loss: 0.0304\n",
      "Epoch 198/250\n",
      "  Train Loss: 0.0305\n",
      "  Val Loss: 0.0304\n",
      "Epoch 199/250\n",
      "  Train Loss: 0.0304\n",
      "  Val Loss: 0.0304\n",
      "Epoch 200/250\n",
      "  Train Loss: 0.0304\n",
      "  Val Loss: 0.0304\n",
      "Epoch 201/250\n",
      "  Train Loss: 0.0304\n",
      "  Val Loss: 0.0303\n",
      "Epoch 202/250\n",
      "  Train Loss: 0.0304\n",
      "  Val Loss: 0.0303\n",
      "Epoch 203/250\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0303\n",
      "Epoch 204/250\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0303\n",
      "Epoch 205/250\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0302\n",
      "Epoch 206/250\n",
      "  Train Loss: 0.0303\n",
      "  Val Loss: 0.0302\n",
      "Epoch 207/250\n",
      "  Train Loss: 0.0302\n",
      "  Val Loss: 0.0302\n",
      "Epoch 208/250\n",
      "  Train Loss: 0.0302\n",
      "  Val Loss: 0.0302\n",
      "Epoch 209/250\n",
      "  Train Loss: 0.0302\n",
      "  Val Loss: 0.0301\n",
      "Epoch 210/250\n",
      "  Train Loss: 0.0302\n",
      "  Val Loss: 0.0301\n",
      "Epoch 211/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0301\n",
      "Epoch 212/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0301\n",
      "Epoch 213/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0301\n",
      "Epoch 214/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0300\n",
      "Epoch 215/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0300\n",
      "Epoch 216/250\n",
      "  Train Loss: 0.0301\n",
      "  Val Loss: 0.0300\n",
      "Epoch 217/250\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0300\n",
      "Epoch 218/250\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0300\n",
      "Epoch 219/250\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0300\n",
      "Epoch 220/250\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0299\n",
      "Epoch 221/250\n",
      "  Train Loss: 0.0300\n",
      "  Val Loss: 0.0299\n",
      "Epoch 222/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0299\n",
      "Epoch 223/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0299\n",
      "Epoch 224/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0299\n",
      "Epoch 225/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0299\n",
      "Epoch 226/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0298\n",
      "Epoch 227/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0298\n",
      "Epoch 228/250\n",
      "  Train Loss: 0.0299\n",
      "  Val Loss: 0.0298\n",
      "Epoch 229/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0298\n",
      "Epoch 230/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0298\n",
      "Epoch 231/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0298\n",
      "Epoch 232/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0298\n",
      "Epoch 233/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0297\n",
      "Epoch 234/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0297\n",
      "Epoch 235/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0297\n",
      "Epoch 236/250\n",
      "  Train Loss: 0.0298\n",
      "  Val Loss: 0.0297\n",
      "Epoch 237/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0297\n",
      "Epoch 238/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0297\n",
      "Epoch 239/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0297\n",
      "Epoch 240/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0297\n",
      "Epoch 241/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0297\n",
      "Epoch 242/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0296\n",
      "Epoch 243/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0296\n",
      "Epoch 244/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0296\n",
      "Epoch 245/250\n",
      "  Train Loss: 0.0297\n",
      "  Val Loss: 0.0296\n",
      "Epoch 246/250\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0296\n",
      "Epoch 247/250\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0296\n",
      "Epoch 248/250\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0296\n",
      "Epoch 249/250\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0296\n",
      "Epoch 250/250\n",
      "  Train Loss: 0.0296\n",
      "  Val Loss: 0.0296\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_instances = 10\n",
    "n_classes = len(generator.classes_)\n",
    "n_obs = n_instances * n_classes\n",
    "X_train = generator.generate_instances(n_instances).repeat(n_classes, axis=0)\n",
    "y_train = np.tile(generator.classes_, n_instances)\n",
    "conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "X_sorted = X_train[sort_idx]\n",
    "y_sorted = y_train[sort_idx]\n",
    "conformities_sorted = conformities[sort_idx]\n",
    "\n",
    "X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "y_pairs = np.expand_dims(y_pairs, axis=-1)\n",
    "ds = LabelPairDataset()\n",
    "ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "for x,y in ds:\n",
    "    print(x,y)\n",
    "pair_loader = DataLoader(ds, batch_size=32)\n",
    "# ds_val = LabelPairDataset()\n",
    "# ds_val.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "# val_loader = DataLoader(ds_val, batch_size=32, num_workers=6)\n",
    "# print(len(ds))\n",
    "model = LabelRankingModel(input_dim=generator.n_features_, hidden_dims=3*[generator.n_features_], activations=[torch.nn.Sigmoid(), SortLayer(),torch.nn.Identity()], output_dim=len(generator.classes_))\n",
    "model.num_classes = generator.n_classes_\n",
    "print(len(pair_loader))\n",
    "# device = next(model.parameters()).device\n",
    "# print(f\"Model is on: {device}\")\n",
    "model._fit(pair_loader, val_loader=pair_loader, num_epochs=250, learning_rate=0.001, verbose=True)\n",
    "\n",
    "\n",
    "# # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "# X_test, y_test = generator.generate(n=100)\n",
    "# skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "# conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "# tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_rank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

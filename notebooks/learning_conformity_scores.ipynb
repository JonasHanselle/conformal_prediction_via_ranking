{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import torch\n",
    "\n",
    "class MultinomialSyntheticDataGenerator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, random_state=None):\n",
    "        \"\"\"\n",
    "        A custom estimator for generating synthetic data using multinomial logistic regression,\n",
    "        with the feature distribution inferred from the training data.\n",
    "        \n",
    "        Parameters:\n",
    "        - n_samples (int): Number of synthetic samples to generate.\n",
    "        - random_state (int): Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits a multinomial logistic regression model to the data and estimates the feature distribution.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        - y (ndarray): Target labels of shape (n_samples,).\n",
    "        \n",
    "        Returns:\n",
    "        - self: The fitted instance.\n",
    "        \"\"\"\n",
    "        # Store mean and covariance of features\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.feature_mean_ = np.mean(X, axis=0)\n",
    "        self.feature_cov_ = np.cov(X, rowvar=False)\n",
    "        \n",
    "        # Fit a logistic regression model\n",
    "        self.model_ = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=self.random_state)\n",
    "        self.model_.fit(X, y)\n",
    "        \n",
    "        # Store the number of classes and features\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for the given feature matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - probabilities (ndarray): Predicted probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, \"model_\")\n",
    "        return self.model_.predict_proba(X)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for the given feature matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - probabilities (ndarray): Predicted probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, \"model_\")\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def generate(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, [\"model_\", \"feature_mean_\", \"feature_cov_\"])\n",
    "        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        X_synthetic = np.random.multivariate_normal(self.feature_mean_, self.feature_cov_, n)\n",
    "        \n",
    "        # Compute class probabilities\n",
    "        P_Y_given_X = self.predict_proba(X_synthetic)\n",
    "        \n",
    "        # Sample synthetic labels\n",
    "        y_synthetic = np.array([np.random.choice(self.n_classes_, p=probs) for probs in P_Y_given_X])\n",
    "        \n",
    "        return X_synthetic, y_synthetic\n",
    "\n",
    "\n",
    "    def generate_instances(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, [\"model_\", \"feature_mean_\", \"feature_cov_\"])\n",
    "        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = np.random.multivariate_normal(self.feature_mean_, self.feature_cov_, n)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleAnnotator:\n",
    "    def __init__(self,mapie_clf, generator):\n",
    "        self.mapie_clf = mapie_clf\n",
    "        self.classes_ = mapie_clf.classes_\n",
    "        self.generator = generator\n",
    "\n",
    "    def generate_pairs_in_instance(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        X = self.generator.generate_instances(n)\n",
    "        X = np.repeat(X, repeats=2, axis=0)\n",
    "\n",
    "        y = np.hstack([np.random.choice(self.classes_, size=2, replace=False) for _ in range(n)])\n",
    "\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "        return X_pairs, y_pairs\n",
    "\n",
    "\n",
    "    def generate_pairs_cross_instance(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = self.generator.generate_instances(2*n)\n",
    "        y = np.random.choice(self.classes_, size=2*n, replace=True)\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "\n",
    "        return X_pairs, y_pairs\n",
    "    \n",
    "    # def create_pairs_for_classification_data(self, X):\n",
    "    #     \"\"\"\n",
    "    #     Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "    #     Returns:\n",
    "    #     - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "    #     - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "    #     \"\"\"\n",
    "    #     # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "    #     X = self.generator.generate_instances(2*n)\n",
    "    #     y = np.random.choice(self.classes_, size=2*n, replace=True)\n",
    "    #     conformities = self.get_conformity(X,y)\n",
    "\n",
    "    #     X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "    #     y_rs = y.reshape(n,2)\n",
    "    #     conformities_n_rs = - conformities.reshape(n,2)\n",
    "    #     sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "    #     X_rs[sort_idx]\n",
    "    #     y_rs[sort_idx,:]\n",
    "    #     X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "    #     y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "\n",
    "        return X_pairs, y_pairs\n",
    "\n",
    "    # we assume y is already label encoded\n",
    "    def get_conformity(self, X, y):\n",
    "        y_pred_proba = self.mapie_clf.estimator.predict_proba(X)\n",
    "        scores = self.mapie_clf.conformity_score_function_.get_conformity_scores(\n",
    "                        y, y_pred_proba, y_enc=y\n",
    "                    )\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.classification import MapieClassifier\n",
    "from mapie.conformity_scores.sets import APSConformityScore, LACConformityScore, NaiveConformityScore, TopKConformityScore\n",
    "from util.ranking_datasets import LabelPairDataset\n",
    "from models.ranking_models import LabelRankingModel\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "from models.ranking_models import SortLayer\n",
    "import torch\n",
    "\n",
    "def conduct_oracle_experiment(conformity_score, num_instances_to_check, generator, X_cal, y_cal):\n",
    "    tau_corrs = []\n",
    "    # Generate a small dataset\n",
    "\n",
    "    mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "    # create mapie classifier for conformity scores\n",
    "    mapie_clf.fit(X_cal, y_cal)\n",
    "    # create \n",
    "    oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "    models = []\n",
    "\n",
    "    for num_instances in num_instances_to_check:\n",
    "        X_train = generator.generate_instances(num_instances).repeat(3, axis=0)\n",
    "        y_train = np.tile(generator.classes_, num_instances)\n",
    "        conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "        sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "        X_sorted = X_train[sort_idx]\n",
    "        y_sorted = y_train[sort_idx]\n",
    "\n",
    "        X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "        y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "        y_pairs = np.expand_dims(y_pairs,axis=-1)\n",
    "\n",
    "\n",
    "        ds = LabelPairDataset()\n",
    "        ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "        pair_loader = DataLoader(ds, batch_size=64)\n",
    "        ds_val = LabelPairDataset()\n",
    "        ds_val.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "        val_loader = DataLoader(ds_val, batch_size=64)\n",
    "        print(len(ds))\n",
    "        model = LabelRankingModel(input_dim=generator.n_features_, hidden_dims=3*[generator.n_features_], activations=[torch.nn.Sigmoid(), torch.nn.Sigmoid(), torch.nn.Sigmoid()], output_dim=len(generator.classes_))\n",
    "        model.num_classes = generator.n_classes_\n",
    "        device = next(model.parameters()).device\n",
    "        print(f\"Model is on: {device}\")\n",
    "        model._fit(pair_loader, val_loader=pair_loader, num_epochs=300, learning_rate=0.01, patience=100, verbose=True)\n",
    "\n",
    "        # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "        X_test = generator.generate_instances(100).repeat(3, axis=0)\n",
    "        y_test = np.tile(generator.classes_, 100)      \n",
    "        skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "        conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "        tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "        tau_corrs.append(tau_corr)\n",
    "        models.append(models)\n",
    "    return tau_corrs, skills_from_model, conformity_scores, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0990\n",
      "  Val Loss: 0.0982\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0982\n",
      "  Val Loss: 0.0978\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0977\n",
      "  Val Loss: 0.0974\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0975\n",
      "  Val Loss: 0.0972\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0972\n",
      "  Val Loss: 0.0970\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0971\n",
      "  Val Loss: 0.0969\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0969\n",
      "  Val Loss: 0.0967\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0967\n",
      "  Val Loss: 0.0965\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0965\n",
      "  Val Loss: 0.0963\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0963\n",
      "  Val Loss: 0.0961\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0961\n",
      "  Val Loss: 0.0958\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0958\n",
      "  Val Loss: 0.0955\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0955\n",
      "  Val Loss: 0.0952\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0952\n",
      "  Val Loss: 0.0948\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0948\n",
      "  Val Loss: 0.0944\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0943\n",
      "  Val Loss: 0.0939\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0938\n",
      "  Val Loss: 0.0934\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0932\n",
      "  Val Loss: 0.0927\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0926\n",
      "  Val Loss: 0.0921\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0919\n",
      "  Val Loss: 0.0913\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0912\n",
      "  Val Loss: 0.0906\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0904\n",
      "  Val Loss: 0.0898\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0896\n",
      "  Val Loss: 0.0889\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0887\n",
      "  Val Loss: 0.0881\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0879\n",
      "  Val Loss: 0.0872\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0871\n",
      "  Val Loss: 0.0864\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0862\n",
      "  Val Loss: 0.0856\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0854\n",
      "  Val Loss: 0.0848\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0846\n",
      "  Val Loss: 0.0840\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0838\n",
      "  Val Loss: 0.0832\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0831\n",
      "  Val Loss: 0.0825\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0823\n",
      "  Val Loss: 0.0817\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0816\n",
      "  Val Loss: 0.0810\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0809\n",
      "  Val Loss: 0.0803\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0802\n",
      "  Val Loss: 0.0796\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0795\n",
      "  Val Loss: 0.0790\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0789\n",
      "  Val Loss: 0.0784\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0783\n",
      "  Val Loss: 0.0778\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0777\n",
      "  Val Loss: 0.0772\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0772\n",
      "  Val Loss: 0.0767\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0767\n",
      "  Val Loss: 0.0762\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0762\n",
      "  Val Loss: 0.0757\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0757\n",
      "  Val Loss: 0.0753\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0753\n",
      "  Val Loss: 0.0749\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0749\n",
      "  Val Loss: 0.0745\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0746\n",
      "  Val Loss: 0.0742\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0743\n",
      "  Val Loss: 0.0739\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0740\n",
      "  Val Loss: 0.0736\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0737\n",
      "  Val Loss: 0.0734\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0734\n",
      "  Val Loss: 0.0731\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0732\n",
      "  Val Loss: 0.0729\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0730\n",
      "  Val Loss: 0.0727\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0728\n",
      "  Val Loss: 0.0725\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0726\n",
      "  Val Loss: 0.0723\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0724\n",
      "  Val Loss: 0.0721\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0723\n",
      "  Val Loss: 0.0720\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0721\n",
      "  Val Loss: 0.0718\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0719\n",
      "  Val Loss: 0.0717\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0718\n",
      "  Val Loss: 0.0715\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0716\n",
      "  Val Loss: 0.0714\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0715\n",
      "  Val Loss: 0.0713\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0714\n",
      "  Val Loss: 0.0711\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0712\n",
      "  Val Loss: 0.0710\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0710\n",
      "  Val Loss: 0.0708\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0709\n",
      "  Val Loss: 0.0706\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0707\n",
      "  Val Loss: 0.0705\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0705\n",
      "  Val Loss: 0.0703\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0702\n",
      "  Val Loss: 0.0700\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0700\n",
      "  Val Loss: 0.0698\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0697\n",
      "  Val Loss: 0.0695\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0694\n",
      "  Val Loss: 0.0692\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0692\n",
      "  Val Loss: 0.0690\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0689\n",
      "  Val Loss: 0.0687\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0687\n",
      "  Val Loss: 0.0685\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0685\n",
      "  Val Loss: 0.0682\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0683\n",
      "  Val Loss: 0.0680\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0681\n",
      "  Val Loss: 0.0678\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0676\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0677\n",
      "  Val Loss: 0.0675\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0676\n",
      "  Val Loss: 0.0673\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0671\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0672\n",
      "  Val Loss: 0.0670\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0671\n",
      "  Val Loss: 0.0668\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0667\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0668\n",
      "  Val Loss: 0.0665\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0667\n",
      "  Val Loss: 0.0664\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0665\n",
      "  Val Loss: 0.0663\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0664\n",
      "  Val Loss: 0.0662\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0663\n",
      "  Val Loss: 0.0660\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0662\n",
      "  Val Loss: 0.0659\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0661\n",
      "  Val Loss: 0.0658\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0660\n",
      "  Val Loss: 0.0657\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0659\n",
      "  Val Loss: 0.0656\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0658\n",
      "  Val Loss: 0.0655\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0657\n",
      "  Val Loss: 0.0654\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0656\n",
      "  Val Loss: 0.0653\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0655\n",
      "  Val Loss: 0.0652\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0654\n",
      "  Val Loss: 0.0652\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0653\n",
      "  Val Loss: 0.0651\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0653\n",
      "  Val Loss: 0.0650\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0652\n",
      "  Val Loss: 0.0649\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0651\n",
      "  Val Loss: 0.0649\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0650\n",
      "  Val Loss: 0.0648\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0650\n",
      "  Val Loss: 0.0647\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0649\n",
      "  Val Loss: 0.0647\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0648\n",
      "  Val Loss: 0.0646\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0648\n",
      "  Val Loss: 0.0645\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0647\n",
      "  Val Loss: 0.0645\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0646\n",
      "  Val Loss: 0.0644\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0646\n",
      "  Val Loss: 0.0644\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0645\n",
      "  Val Loss: 0.0643\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0645\n",
      "  Val Loss: 0.0642\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0644\n",
      "  Val Loss: 0.0642\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0644\n",
      "  Val Loss: 0.0641\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0643\n",
      "  Val Loss: 0.0641\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0643\n",
      "  Val Loss: 0.0640\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0642\n",
      "  Val Loss: 0.0640\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0642\n",
      "  Val Loss: 0.0640\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0641\n",
      "  Val Loss: 0.0639\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0641\n",
      "  Val Loss: 0.0639\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0641\n",
      "  Val Loss: 0.0638\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0640\n",
      "  Val Loss: 0.0638\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0640\n",
      "  Val Loss: 0.0638\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0640\n",
      "  Val Loss: 0.0637\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0639\n",
      "  Val Loss: 0.0637\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0639\n",
      "  Val Loss: 0.0636\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0638\n",
      "  Val Loss: 0.0636\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0638\n",
      "  Val Loss: 0.0636\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0638\n",
      "  Val Loss: 0.0635\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0638\n",
      "  Val Loss: 0.0635\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0637\n",
      "  Val Loss: 0.0635\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0637\n",
      "  Val Loss: 0.0635\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0637\n",
      "  Val Loss: 0.0634\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0636\n",
      "  Val Loss: 0.0634\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0636\n",
      "  Val Loss: 0.0634\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0636\n",
      "  Val Loss: 0.0634\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0636\n",
      "  Val Loss: 0.0633\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0635\n",
      "  Val Loss: 0.0633\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0635\n",
      "  Val Loss: 0.0633\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0635\n",
      "  Val Loss: 0.0633\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0635\n",
      "  Val Loss: 0.0632\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0632\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0632\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0632\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0632\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0631\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0631\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0631\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0631\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0631\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0630\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0630\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0630\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0630\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0630\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0630\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0630\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0629\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0629\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0629\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0629\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0629\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0629\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0629\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0628\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0628\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0628\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0628\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0627\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0627\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0627\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0627\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0627\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0626\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0626\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0626\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0626\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0626\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0626\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0625\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0624\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0623\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0622\n",
      "4560\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0096\n",
      "  Val Loss: 0.0093\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0094\n",
      "  Val Loss: 0.0092\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0092\n",
      "  Val Loss: 0.0090\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0088\n",
      "  Val Loss: 0.0084\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0081\n",
      "  Val Loss: 0.0076\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0074\n",
      "  Val Loss: 0.0070\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0070\n",
      "  Val Loss: 0.0067\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0056\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0056\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0056\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0056\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0055\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0055\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0055\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0054\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0054\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0053\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0053\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0052\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0051\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0050\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0049\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0048\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0045\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0044\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0041\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0040\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0039\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0037\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0037\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0036\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0036\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0036\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0035\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0035\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0035\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0034\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0034\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0034\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0033\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0033\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0033\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0032\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0032\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0032\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0032\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0031\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0030\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0029\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0029\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0029\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0029\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0027\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0022\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0021\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0020\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0020\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0020\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0019\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0019\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0019\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0019\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0019\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0017\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "13530\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0026\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0025\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0025\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0024\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0024\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0024\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0021\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0021\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0020\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0019\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0019\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0018\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "26565\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0016\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0015\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0015\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0015\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0016\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0012\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0009\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "44850\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0009\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0006\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0002\n",
      "  Val Loss: 0.0002\n",
      "435\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.1000\n",
      "  Val Loss: 0.0986\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0988\n",
      "  Val Loss: 0.0983\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0984\n",
      "  Val Loss: 0.0981\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0983\n",
      "  Val Loss: 0.0980\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0982\n",
      "  Val Loss: 0.0980\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0981\n",
      "  Val Loss: 0.0979\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0980\n",
      "  Val Loss: 0.0979\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0980\n",
      "  Val Loss: 0.0978\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0979\n",
      "  Val Loss: 0.0977\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0978\n",
      "  Val Loss: 0.0977\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0977\n",
      "  Val Loss: 0.0975\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0976\n",
      "  Val Loss: 0.0974\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0974\n",
      "  Val Loss: 0.0972\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0972\n",
      "  Val Loss: 0.0970\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0970\n",
      "  Val Loss: 0.0967\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0967\n",
      "  Val Loss: 0.0963\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0963\n",
      "  Val Loss: 0.0959\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0959\n",
      "  Val Loss: 0.0954\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0954\n",
      "  Val Loss: 0.0949\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0949\n",
      "  Val Loss: 0.0943\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0943\n",
      "  Val Loss: 0.0937\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0937\n",
      "  Val Loss: 0.0930\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0930\n",
      "  Val Loss: 0.0923\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0923\n",
      "  Val Loss: 0.0916\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0916\n",
      "  Val Loss: 0.0908\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0908\n",
      "  Val Loss: 0.0901\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0900\n",
      "  Val Loss: 0.0893\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0893\n",
      "  Val Loss: 0.0885\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0885\n",
      "  Val Loss: 0.0877\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0878\n",
      "  Val Loss: 0.0870\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0870\n",
      "  Val Loss: 0.0863\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0863\n",
      "  Val Loss: 0.0856\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0856\n",
      "  Val Loss: 0.0849\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0850\n",
      "  Val Loss: 0.0843\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0844\n",
      "  Val Loss: 0.0837\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0838\n",
      "  Val Loss: 0.0832\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0833\n",
      "  Val Loss: 0.0827\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0829\n",
      "  Val Loss: 0.0823\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0824\n",
      "  Val Loss: 0.0819\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0820\n",
      "  Val Loss: 0.0815\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0817\n",
      "  Val Loss: 0.0812\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0814\n",
      "  Val Loss: 0.0809\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0811\n",
      "  Val Loss: 0.0806\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0808\n",
      "  Val Loss: 0.0804\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0806\n",
      "  Val Loss: 0.0801\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0803\n",
      "  Val Loss: 0.0799\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0801\n",
      "  Val Loss: 0.0797\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0799\n",
      "  Val Loss: 0.0796\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0798\n",
      "  Val Loss: 0.0794\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0796\n",
      "  Val Loss: 0.0792\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0795\n",
      "  Val Loss: 0.0791\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0793\n",
      "  Val Loss: 0.0790\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0792\n",
      "  Val Loss: 0.0789\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0791\n",
      "  Val Loss: 0.0787\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0790\n",
      "  Val Loss: 0.0786\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0789\n",
      "  Val Loss: 0.0785\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0788\n",
      "  Val Loss: 0.0784\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0787\n",
      "  Val Loss: 0.0783\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0786\n",
      "  Val Loss: 0.0782\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0785\n",
      "  Val Loss: 0.0782\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0784\n",
      "  Val Loss: 0.0781\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0783\n",
      "  Val Loss: 0.0780\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0782\n",
      "  Val Loss: 0.0779\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0781\n",
      "  Val Loss: 0.0778\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0781\n",
      "  Val Loss: 0.0778\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0780\n",
      "  Val Loss: 0.0777\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0779\n",
      "  Val Loss: 0.0776\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0779\n",
      "  Val Loss: 0.0775\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0778\n",
      "  Val Loss: 0.0775\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0777\n",
      "  Val Loss: 0.0774\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0776\n",
      "  Val Loss: 0.0773\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0776\n",
      "  Val Loss: 0.0773\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0775\n",
      "  Val Loss: 0.0772\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0774\n",
      "  Val Loss: 0.0771\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0774\n",
      "  Val Loss: 0.0771\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0773\n",
      "  Val Loss: 0.0770\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0773\n",
      "  Val Loss: 0.0770\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0772\n",
      "  Val Loss: 0.0769\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0771\n",
      "  Val Loss: 0.0768\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0771\n",
      "  Val Loss: 0.0768\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0770\n",
      "  Val Loss: 0.0767\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0769\n",
      "  Val Loss: 0.0766\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0769\n",
      "  Val Loss: 0.0766\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0768\n",
      "  Val Loss: 0.0765\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0768\n",
      "  Val Loss: 0.0765\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0767\n",
      "  Val Loss: 0.0764\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0766\n",
      "  Val Loss: 0.0763\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0766\n",
      "  Val Loss: 0.0763\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0765\n",
      "  Val Loss: 0.0762\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0764\n",
      "  Val Loss: 0.0761\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0764\n",
      "  Val Loss: 0.0761\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0763\n",
      "  Val Loss: 0.0760\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0763\n",
      "  Val Loss: 0.0760\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0762\n",
      "  Val Loss: 0.0759\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0761\n",
      "  Val Loss: 0.0758\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0761\n",
      "  Val Loss: 0.0758\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0760\n",
      "  Val Loss: 0.0757\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0759\n",
      "  Val Loss: 0.0756\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0759\n",
      "  Val Loss: 0.0756\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0758\n",
      "  Val Loss: 0.0755\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0757\n",
      "  Val Loss: 0.0754\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0757\n",
      "  Val Loss: 0.0754\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0756\n",
      "  Val Loss: 0.0753\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0755\n",
      "  Val Loss: 0.0752\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0755\n",
      "  Val Loss: 0.0751\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0754\n",
      "  Val Loss: 0.0751\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0753\n",
      "  Val Loss: 0.0750\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0752\n",
      "  Val Loss: 0.0749\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0752\n",
      "  Val Loss: 0.0749\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0751\n",
      "  Val Loss: 0.0748\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0750\n",
      "  Val Loss: 0.0747\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0749\n",
      "  Val Loss: 0.0746\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0749\n",
      "  Val Loss: 0.0746\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0748\n",
      "  Val Loss: 0.0745\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0747\n",
      "  Val Loss: 0.0744\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0746\n",
      "  Val Loss: 0.0743\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0746\n",
      "  Val Loss: 0.0743\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0745\n",
      "  Val Loss: 0.0742\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0744\n",
      "  Val Loss: 0.0741\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0743\n",
      "  Val Loss: 0.0740\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0742\n",
      "  Val Loss: 0.0739\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0742\n",
      "  Val Loss: 0.0739\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0741\n",
      "  Val Loss: 0.0738\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0740\n",
      "  Val Loss: 0.0737\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0739\n",
      "  Val Loss: 0.0736\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0738\n",
      "  Val Loss: 0.0735\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0737\n",
      "  Val Loss: 0.0734\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0737\n",
      "  Val Loss: 0.0734\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0736\n",
      "  Val Loss: 0.0733\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0735\n",
      "  Val Loss: 0.0732\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0734\n",
      "  Val Loss: 0.0731\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0733\n",
      "  Val Loss: 0.0730\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0732\n",
      "  Val Loss: 0.0729\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0731\n",
      "  Val Loss: 0.0728\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0731\n",
      "  Val Loss: 0.0727\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0730\n",
      "  Val Loss: 0.0727\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0729\n",
      "  Val Loss: 0.0726\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0728\n",
      "  Val Loss: 0.0725\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0727\n",
      "  Val Loss: 0.0724\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0726\n",
      "  Val Loss: 0.0723\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0725\n",
      "  Val Loss: 0.0722\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0724\n",
      "  Val Loss: 0.0721\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0723\n",
      "  Val Loss: 0.0720\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0723\n",
      "  Val Loss: 0.0720\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0722\n",
      "  Val Loss: 0.0719\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0721\n",
      "  Val Loss: 0.0718\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0720\n",
      "  Val Loss: 0.0717\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0719\n",
      "  Val Loss: 0.0716\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0718\n",
      "  Val Loss: 0.0715\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0717\n",
      "  Val Loss: 0.0714\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0717\n",
      "  Val Loss: 0.0714\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0716\n",
      "  Val Loss: 0.0713\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0715\n",
      "  Val Loss: 0.0712\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0714\n",
      "  Val Loss: 0.0711\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0713\n",
      "  Val Loss: 0.0710\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0712\n",
      "  Val Loss: 0.0709\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0712\n",
      "  Val Loss: 0.0709\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0711\n",
      "  Val Loss: 0.0708\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0710\n",
      "  Val Loss: 0.0707\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0709\n",
      "  Val Loss: 0.0706\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0708\n",
      "  Val Loss: 0.0706\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0708\n",
      "  Val Loss: 0.0705\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0707\n",
      "  Val Loss: 0.0704\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0706\n",
      "  Val Loss: 0.0703\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0706\n",
      "  Val Loss: 0.0703\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0705\n",
      "  Val Loss: 0.0702\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0704\n",
      "  Val Loss: 0.0701\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0703\n",
      "  Val Loss: 0.0701\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0703\n",
      "  Val Loss: 0.0700\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0702\n",
      "  Val Loss: 0.0699\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0701\n",
      "  Val Loss: 0.0699\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0701\n",
      "  Val Loss: 0.0698\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0700\n",
      "  Val Loss: 0.0697\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0700\n",
      "  Val Loss: 0.0697\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0699\n",
      "  Val Loss: 0.0696\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0698\n",
      "  Val Loss: 0.0696\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0698\n",
      "  Val Loss: 0.0695\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0697\n",
      "  Val Loss: 0.0695\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0697\n",
      "  Val Loss: 0.0694\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0696\n",
      "  Val Loss: 0.0693\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0696\n",
      "  Val Loss: 0.0693\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0695\n",
      "  Val Loss: 0.0692\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0695\n",
      "  Val Loss: 0.0692\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0694\n",
      "  Val Loss: 0.0691\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0694\n",
      "  Val Loss: 0.0691\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0693\n",
      "  Val Loss: 0.0690\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0693\n",
      "  Val Loss: 0.0690\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0692\n",
      "  Val Loss: 0.0690\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0692\n",
      "  Val Loss: 0.0689\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0691\n",
      "  Val Loss: 0.0689\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0691\n",
      "  Val Loss: 0.0688\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0690\n",
      "  Val Loss: 0.0688\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0690\n",
      "  Val Loss: 0.0687\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0689\n",
      "  Val Loss: 0.0687\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0689\n",
      "  Val Loss: 0.0687\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0689\n",
      "  Val Loss: 0.0686\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0688\n",
      "  Val Loss: 0.0686\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0688\n",
      "  Val Loss: 0.0685\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0687\n",
      "  Val Loss: 0.0685\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0687\n",
      "  Val Loss: 0.0685\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0687\n",
      "  Val Loss: 0.0684\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0686\n",
      "  Val Loss: 0.0684\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0686\n",
      "  Val Loss: 0.0683\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0686\n",
      "  Val Loss: 0.0683\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0685\n",
      "  Val Loss: 0.0683\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0685\n",
      "  Val Loss: 0.0682\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0684\n",
      "  Val Loss: 0.0682\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0684\n",
      "  Val Loss: 0.0682\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0684\n",
      "  Val Loss: 0.0681\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0683\n",
      "  Val Loss: 0.0681\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0683\n",
      "  Val Loss: 0.0680\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0683\n",
      "  Val Loss: 0.0680\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0682\n",
      "  Val Loss: 0.0680\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0682\n",
      "  Val Loss: 0.0679\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0682\n",
      "  Val Loss: 0.0679\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0681\n",
      "  Val Loss: 0.0679\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0681\n",
      "  Val Loss: 0.0678\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0680\n",
      "  Val Loss: 0.0678\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0680\n",
      "  Val Loss: 0.0677\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0680\n",
      "  Val Loss: 0.0677\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0677\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0676\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0679\n",
      "  Val Loss: 0.0676\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0678\n",
      "  Val Loss: 0.0676\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0678\n",
      "  Val Loss: 0.0675\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0677\n",
      "  Val Loss: 0.0675\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0677\n",
      "  Val Loss: 0.0674\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0677\n",
      "  Val Loss: 0.0674\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0676\n",
      "  Val Loss: 0.0673\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0676\n",
      "  Val Loss: 0.0673\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0675\n",
      "  Val Loss: 0.0673\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0675\n",
      "  Val Loss: 0.0672\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0672\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0671\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0671\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0673\n",
      "  Val Loss: 0.0670\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0673\n",
      "  Val Loss: 0.0670\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0672\n",
      "  Val Loss: 0.0669\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0672\n",
      "  Val Loss: 0.0668\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0671\n",
      "  Val Loss: 0.0668\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0670\n",
      "  Val Loss: 0.0667\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0670\n",
      "  Val Loss: 0.0667\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0666\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.0666\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0668\n",
      "  Val Loss: 0.0665\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0668\n",
      "  Val Loss: 0.0664\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0667\n",
      "  Val Loss: 0.0664\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0666\n",
      "  Val Loss: 0.0663\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0666\n",
      "  Val Loss: 0.0662\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0665\n",
      "  Val Loss: 0.0661\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0664\n",
      "  Val Loss: 0.0661\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0663\n",
      "  Val Loss: 0.0660\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0663\n",
      "  Val Loss: 0.0659\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0662\n",
      "  Val Loss: 0.0658\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0661\n",
      "  Val Loss: 0.0658\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0660\n",
      "  Val Loss: 0.0657\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0660\n",
      "  Val Loss: 0.0656\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0659\n",
      "  Val Loss: 0.0655\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0658\n",
      "  Val Loss: 0.0654\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0657\n",
      "  Val Loss: 0.0653\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0656\n",
      "  Val Loss: 0.0653\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0655\n",
      "  Val Loss: 0.0652\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0655\n",
      "  Val Loss: 0.0651\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0654\n",
      "  Val Loss: 0.0650\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0653\n",
      "  Val Loss: 0.0649\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0652\n",
      "  Val Loss: 0.0648\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0651\n",
      "  Val Loss: 0.0647\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0650\n",
      "  Val Loss: 0.0646\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0649\n",
      "  Val Loss: 0.0645\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0648\n",
      "  Val Loss: 0.0644\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0647\n",
      "  Val Loss: 0.0644\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0646\n",
      "  Val Loss: 0.0643\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0645\n",
      "  Val Loss: 0.0642\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0645\n",
      "  Val Loss: 0.0641\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0644\n",
      "  Val Loss: 0.0640\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0643\n",
      "  Val Loss: 0.0639\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0642\n",
      "  Val Loss: 0.0638\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0641\n",
      "  Val Loss: 0.0637\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0640\n",
      "  Val Loss: 0.0636\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0639\n",
      "  Val Loss: 0.0635\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0638\n",
      "  Val Loss: 0.0634\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0637\n",
      "  Val Loss: 0.0634\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0636\n",
      "  Val Loss: 0.0633\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0635\n",
      "  Val Loss: 0.0632\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0631\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0634\n",
      "  Val Loss: 0.0630\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0633\n",
      "  Val Loss: 0.0629\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0632\n",
      "  Val Loss: 0.0628\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.0627\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0627\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0629\n",
      "  Val Loss: 0.0626\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0628\n",
      "  Val Loss: 0.0625\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0627\n",
      "  Val Loss: 0.0624\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0623\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0626\n",
      "  Val Loss: 0.0622\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0625\n",
      "  Val Loss: 0.0621\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0624\n",
      "  Val Loss: 0.0621\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0623\n",
      "  Val Loss: 0.0620\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0622\n",
      "  Val Loss: 0.0619\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0621\n",
      "  Val Loss: 0.0618\n",
      "4560\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0097\n",
      "  Val Loss: 0.0095\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0096\n",
      "  Val Loss: 0.0094\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0094\n",
      "  Val Loss: 0.0090\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0089\n",
      "  Val Loss: 0.0083\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0082\n",
      "  Val Loss: 0.0077\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0076\n",
      "  Val Loss: 0.0073\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0074\n",
      "  Val Loss: 0.0071\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0072\n",
      "  Val Loss: 0.0070\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0070\n",
      "  Val Loss: 0.0069\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0068\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0068\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0067\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0067\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0067\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0067\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0067\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0067\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0066\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0065\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0064\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0063\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0062\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0061\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0061\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0060\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0060\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0061\n",
      "  Val Loss: 0.0059\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0059\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0058\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0058\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0057\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0056\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0058\n",
      "  Val Loss: 0.0056\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0056\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0055\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0055\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0054\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0054\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0054\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0053\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0053\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0053\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0052\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0052\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0052\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0052\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0051\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0051\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0050\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0050\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0050\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0050\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0049\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0049\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0049\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0048\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0048\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0047\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0047\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0047\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0047\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0046\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0045\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0045\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0044\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0044\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "13530\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0033\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0032\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0028\n",
      "  Val Loss: 0.0028\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0027\n",
      "  Val Loss: 0.0027\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0028\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0028\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0027\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0027\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0027\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0027\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0026\n",
      "  Val Loss: 0.0026\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0025\n",
      "  Val Loss: 0.0026\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0026\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0025\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0024\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0024\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0021\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0022\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0022\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0022\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0021\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0020\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0020\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0019\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0015\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "26565\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0016\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0013\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0013\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0009\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0008\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "44850\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0005\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "435\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.1028\n",
      "  Val Loss: 0.0998\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0996\n",
      "  Val Loss: 0.0979\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0979\n",
      "  Val Loss: 0.0968\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0969\n",
      "  Val Loss: 0.0961\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0963\n",
      "  Val Loss: 0.0957\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0959\n",
      "  Val Loss: 0.0954\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0956\n",
      "  Val Loss: 0.0953\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0955\n",
      "  Val Loss: 0.0952\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0954\n",
      "  Val Loss: 0.0951\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0953\n",
      "  Val Loss: 0.0950\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0952\n",
      "  Val Loss: 0.0950\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0951\n",
      "  Val Loss: 0.0949\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0950\n",
      "  Val Loss: 0.0948\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0949\n",
      "  Val Loss: 0.0947\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0948\n",
      "  Val Loss: 0.0947\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0947\n",
      "  Val Loss: 0.0946\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0947\n",
      "  Val Loss: 0.0945\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0945\n",
      "  Val Loss: 0.0944\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0944\n",
      "  Val Loss: 0.0942\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0943\n",
      "  Val Loss: 0.0941\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0942\n",
      "  Val Loss: 0.0940\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0940\n",
      "  Val Loss: 0.0938\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0939\n",
      "  Val Loss: 0.0936\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0937\n",
      "  Val Loss: 0.0934\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0935\n",
      "  Val Loss: 0.0932\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0932\n",
      "  Val Loss: 0.0930\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0930\n",
      "  Val Loss: 0.0927\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0927\n",
      "  Val Loss: 0.0924\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0924\n",
      "  Val Loss: 0.0921\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0920\n",
      "  Val Loss: 0.0917\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0917\n",
      "  Val Loss: 0.0913\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0912\n",
      "  Val Loss: 0.0908\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0907\n",
      "  Val Loss: 0.0903\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0902\n",
      "  Val Loss: 0.0897\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0896\n",
      "  Val Loss: 0.0891\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0889\n",
      "  Val Loss: 0.0884\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0882\n",
      "  Val Loss: 0.0876\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0874\n",
      "  Val Loss: 0.0868\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0865\n",
      "  Val Loss: 0.0858\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0856\n",
      "  Val Loss: 0.0849\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0846\n",
      "  Val Loss: 0.0838\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0835\n",
      "  Val Loss: 0.0827\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0824\n",
      "  Val Loss: 0.0816\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0812\n",
      "  Val Loss: 0.0803\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0800\n",
      "  Val Loss: 0.0791\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0788\n",
      "  Val Loss: 0.0779\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0775\n",
      "  Val Loss: 0.0766\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0762\n",
      "  Val Loss: 0.0753\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0750\n",
      "  Val Loss: 0.0741\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0738\n",
      "  Val Loss: 0.0729\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0726\n",
      "  Val Loss: 0.0718\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0714\n",
      "  Val Loss: 0.0707\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0704\n",
      "  Val Loss: 0.0696\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0693\n",
      "  Val Loss: 0.0686\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0683\n",
      "  Val Loss: 0.0677\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0674\n",
      "  Val Loss: 0.0668\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0665\n",
      "  Val Loss: 0.0659\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0657\n",
      "  Val Loss: 0.0652\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0650\n",
      "  Val Loss: 0.0644\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0643\n",
      "  Val Loss: 0.0638\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0636\n",
      "  Val Loss: 0.0631\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0630\n",
      "  Val Loss: 0.0626\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0624\n",
      "  Val Loss: 0.0620\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0619\n",
      "  Val Loss: 0.0615\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0614\n",
      "  Val Loss: 0.0610\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0609\n",
      "  Val Loss: 0.0606\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0605\n",
      "  Val Loss: 0.0602\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0601\n",
      "  Val Loss: 0.0598\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0597\n",
      "  Val Loss: 0.0595\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0594\n",
      "  Val Loss: 0.0591\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0590\n",
      "  Val Loss: 0.0588\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0587\n",
      "  Val Loss: 0.0585\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0585\n",
      "  Val Loss: 0.0582\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0582\n",
      "  Val Loss: 0.0580\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0579\n",
      "  Val Loss: 0.0578\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0577\n",
      "  Val Loss: 0.0575\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0575\n",
      "  Val Loss: 0.0573\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0573\n",
      "  Val Loss: 0.0571\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0571\n",
      "  Val Loss: 0.0570\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0569\n",
      "  Val Loss: 0.0568\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0568\n",
      "  Val Loss: 0.0566\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0566\n",
      "  Val Loss: 0.0565\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0565\n",
      "  Val Loss: 0.0563\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0563\n",
      "  Val Loss: 0.0562\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0562\n",
      "  Val Loss: 0.0561\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0561\n",
      "  Val Loss: 0.0559\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0559\n",
      "  Val Loss: 0.0558\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0558\n",
      "  Val Loss: 0.0557\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0557\n",
      "  Val Loss: 0.0556\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0556\n",
      "  Val Loss: 0.0555\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0555\n",
      "  Val Loss: 0.0554\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0555\n",
      "  Val Loss: 0.0554\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0554\n",
      "  Val Loss: 0.0553\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0553\n",
      "  Val Loss: 0.0552\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0552\n",
      "  Val Loss: 0.0551\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0551\n",
      "  Val Loss: 0.0551\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0551\n",
      "  Val Loss: 0.0550\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0550\n",
      "  Val Loss: 0.0549\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0550\n",
      "  Val Loss: 0.0549\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0549\n",
      "  Val Loss: 0.0548\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0548\n",
      "  Val Loss: 0.0548\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0548\n",
      "  Val Loss: 0.0547\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0547\n",
      "  Val Loss: 0.0547\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0547\n",
      "  Val Loss: 0.0546\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0547\n",
      "  Val Loss: 0.0546\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0546\n",
      "  Val Loss: 0.0545\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0546\n",
      "  Val Loss: 0.0545\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0545\n",
      "  Val Loss: 0.0545\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0545\n",
      "  Val Loss: 0.0544\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0545\n",
      "  Val Loss: 0.0544\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0544\n",
      "  Val Loss: 0.0544\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0544\n",
      "  Val Loss: 0.0543\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0544\n",
      "  Val Loss: 0.0543\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0543\n",
      "  Val Loss: 0.0543\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0543\n",
      "  Val Loss: 0.0543\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0543\n",
      "  Val Loss: 0.0542\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0543\n",
      "  Val Loss: 0.0542\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0542\n",
      "  Val Loss: 0.0542\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0542\n",
      "  Val Loss: 0.0542\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0542\n",
      "  Val Loss: 0.0541\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0542\n",
      "  Val Loss: 0.0541\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0542\n",
      "  Val Loss: 0.0541\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0541\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0541\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0540\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0540\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0540\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0541\n",
      "  Val Loss: 0.0540\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0540\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0540\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0540\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0539\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0539\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0539\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0539\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0540\n",
      "  Val Loss: 0.0539\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0539\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0539\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0539\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0538\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0538\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0538\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0538\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0538\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0538\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0538\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0538\n",
      "  Val Loss: 0.0537\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0537\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0537\n",
      "  Val Loss: 0.0536\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0536\n",
      "  Val Loss: 0.0536\n",
      "4560\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0098\n",
      "  Val Loss: 0.0091\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0092\n",
      "  Val Loss: 0.0090\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0091\n",
      "  Val Loss: 0.0090\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0091\n",
      "  Val Loss: 0.0089\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0090\n",
      "  Val Loss: 0.0088\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0089\n",
      "  Val Loss: 0.0087\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0088\n",
      "  Val Loss: 0.0085\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0086\n",
      "  Val Loss: 0.0083\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0083\n",
      "  Val Loss: 0.0080\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0081\n",
      "  Val Loss: 0.0078\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0079\n",
      "  Val Loss: 0.0076\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0077\n",
      "  Val Loss: 0.0075\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0076\n",
      "  Val Loss: 0.0074\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0075\n",
      "  Val Loss: 0.0073\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0074\n",
      "  Val Loss: 0.0072\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0073\n",
      "  Val Loss: 0.0071\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0072\n",
      "  Val Loss: 0.0070\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0071\n",
      "  Val Loss: 0.0069\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0071\n",
      "  Val Loss: 0.0069\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0070\n",
      "  Val Loss: 0.0068\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0070\n",
      "  Val Loss: 0.0068\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0070\n",
      "  Val Loss: 0.0068\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0067\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0067\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0067\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0067\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0069\n",
      "  Val Loss: 0.0066\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0066\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0065\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0065\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0068\n",
      "  Val Loss: 0.0065\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0065\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0064\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0064\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0067\n",
      "  Val Loss: 0.0064\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0064\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0063\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0066\n",
      "  Val Loss: 0.0063\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0063\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0065\n",
      "  Val Loss: 0.0062\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0062\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0064\n",
      "  Val Loss: 0.0061\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0063\n",
      "  Val Loss: 0.0060\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0062\n",
      "  Val Loss: 0.0059\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0060\n",
      "  Val Loss: 0.0057\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0059\n",
      "  Val Loss: 0.0056\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0057\n",
      "  Val Loss: 0.0055\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0056\n",
      "  Val Loss: 0.0054\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0055\n",
      "  Val Loss: 0.0053\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0052\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0054\n",
      "  Val Loss: 0.0051\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0053\n",
      "  Val Loss: 0.0051\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0050\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0052\n",
      "  Val Loss: 0.0050\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0049\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0051\n",
      "  Val Loss: 0.0048\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0050\n",
      "  Val Loss: 0.0047\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0047\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0047\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0048\n",
      "  Val Loss: 0.0046\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0046\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0045\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0047\n",
      "  Val Loss: 0.0045\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0045\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0044\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0046\n",
      "  Val Loss: 0.0044\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0044\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0045\n",
      "  Val Loss: 0.0043\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0043\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0044\n",
      "  Val Loss: 0.0042\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0042\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0043\n",
      "  Val Loss: 0.0041\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0041\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0042\n",
      "  Val Loss: 0.0040\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0040\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0041\n",
      "  Val Loss: 0.0039\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0039\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0039\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0038\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0040\n",
      "  Val Loss: 0.0038\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0038\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0039\n",
      "  Val Loss: 0.0037\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0037\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0038\n",
      "  Val Loss: 0.0036\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0036\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0036\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0037\n",
      "  Val Loss: 0.0035\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0035\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0035\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0036\n",
      "  Val Loss: 0.0034\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0034\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0034\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0034\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0034\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0035\n",
      "  Val Loss: 0.0033\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0033\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0034\n",
      "  Val Loss: 0.0032\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0031\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0031\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0030\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0030\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0030\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0030\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0032\n",
      "  Val Loss: 0.0030\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0030\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0031\n",
      "  Val Loss: 0.0029\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0029\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0030\n",
      "  Val Loss: 0.0028\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0028\n",
      "13530\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0034\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0033\n",
      "  Val Loss: 0.0032\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0029\n",
      "  Val Loss: 0.0025\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0024\n",
      "  Val Loss: 0.0023\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0023\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0023\n",
      "  Val Loss: 0.0022\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0022\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0021\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0022\n",
      "  Val Loss: 0.0021\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0021\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0020\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0021\n",
      "  Val Loss: 0.0020\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0020\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0019\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0020\n",
      "  Val Loss: 0.0019\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0019\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0019\n",
      "  Val Loss: 0.0018\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0018\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0018\n",
      "  Val Loss: 0.0017\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0017\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0017\n",
      "  Val Loss: 0.0016\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0015\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0014\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0014\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0013\n",
      "  Val Loss: 0.0012\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0012\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0011\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0011\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0010\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0010\n",
      "26565\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0015\n",
      "  Val Loss: 0.0016\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0014\n",
      "  Val Loss: 0.0013\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0012\n",
      "  Val Loss: 0.0013\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0013\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0013\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0011\n",
      "  Val Loss: 0.0014\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0013\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0013\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0013\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0013\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0012\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0012\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0011\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0010\n",
      "  Val Loss: 0.0011\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0010\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0008\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0008\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0006\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "44850\n",
      "Model is on: cpu\n",
      "Epoch 1/300\n",
      "  Train Loss: 0.0009\n",
      "  Val Loss: 0.0009\n",
      "Epoch 2/300\n",
      "  Train Loss: 0.0008\n",
      "  Val Loss: 0.0007\n",
      "Epoch 3/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 4/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 5/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 6/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 7/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 8/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 9/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 10/300\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0007\n",
      "Epoch 11/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 12/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0007\n",
      "Epoch 13/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 14/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0006\n",
      "Epoch 15/300\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0005\n",
      "Epoch 16/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 17/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 18/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 19/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 20/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 21/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 22/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 23/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 24/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 25/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 26/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 27/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 28/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0005\n",
      "Epoch 29/300\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0004\n",
      "Epoch 30/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 31/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 32/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 33/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 34/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 35/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 36/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 37/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 38/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 39/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 40/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 41/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 42/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 43/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 44/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0004\n",
      "Epoch 45/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 46/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 47/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 48/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 49/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 50/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 51/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 52/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 53/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 54/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 55/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 56/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 57/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 58/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 59/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 60/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 61/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 62/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 63/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 64/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 65/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 66/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 67/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 68/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 69/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 70/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 71/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 72/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 73/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 74/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 75/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 76/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 77/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 78/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 79/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 80/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 81/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 82/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 83/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 84/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 85/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 86/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 87/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 88/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 89/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 90/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 91/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 92/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 93/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 94/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 95/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 96/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 97/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 98/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 99/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 100/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 101/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 102/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 103/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 104/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 105/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 106/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 107/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 108/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 109/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 110/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 111/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 112/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 113/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 114/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 115/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 116/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 117/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 118/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 119/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 120/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 121/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 122/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 123/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 124/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 125/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 126/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 127/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 128/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 129/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 130/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 131/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 132/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 133/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 134/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 135/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 136/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 137/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 138/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 139/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 140/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 141/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 142/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 143/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 144/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 145/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 146/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 147/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 148/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 149/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 150/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 151/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 152/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 153/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 154/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 155/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 156/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 157/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 158/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 159/300\n",
      "  Train Loss: 0.0004\n",
      "  Val Loss: 0.0003\n",
      "Epoch 160/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 161/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 162/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 163/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 164/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 165/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 166/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 167/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 168/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 169/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 170/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 171/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 172/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 173/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 174/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 175/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 176/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 177/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 178/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 179/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 180/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 181/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 182/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 183/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 184/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 185/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 186/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 187/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 188/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 189/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 190/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 191/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 192/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 193/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 194/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 195/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 196/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 197/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 198/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 199/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 200/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 201/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 202/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 203/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 204/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 205/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 206/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 207/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 208/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 209/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 210/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 211/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 212/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 213/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 214/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 215/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 216/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 217/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 218/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 219/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 220/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 221/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 222/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 223/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 224/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 225/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 226/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 227/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 228/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 229/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 230/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 231/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 232/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 233/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 234/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 235/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 236/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 237/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 238/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 239/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 240/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 241/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 242/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 243/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 244/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 245/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 246/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 247/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 248/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 249/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 250/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 251/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 252/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 253/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 254/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 255/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 256/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 257/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 258/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 259/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 260/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 261/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 262/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 263/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 264/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 265/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 266/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 267/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 268/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 269/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 270/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 271/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 272/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 273/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 274/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 275/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 276/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 277/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 278/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 279/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 280/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 281/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 282/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 283/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 284/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 285/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 286/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 287/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 288/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 289/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 290/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 291/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 292/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 293/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 294/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 295/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 296/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 297/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 298/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 299/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n",
      "Epoch 300/300\n",
      "  Train Loss: 0.0003\n",
      "  Val Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "num_instances_to_check = np.linspace(10,100,5).astype(int)\n",
    "X_train, y_train = make_classification(\n",
    "    n_samples=100, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and fit the generator\n",
    "generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "generator.fit(X_train, y_train)\n",
    "X_cal, y_cal = generator.generate(n=100)\n",
    "tau_corrs_LAC, skills_LAC, conformities_LAC, models_LAC = conduct_oracle_experiment(LACConformityScore(), num_instances_to_check, generator, X_cal, y_cal)\n",
    "tau_corrs_APS, skills_APC, conformities_APC, models_APC = conduct_oracle_experiment(APSConformityScore(), num_instances_to_check, generator, X_cal, y_cal)\n",
    "tau_corrs_TopK, skills_TopK, conformities_TopK, models_TopK = conduct_oracle_experiment(TopKConformityScore(), num_instances_to_check, generator, X_cal, y_cal)\n",
    "# tau_corrs_Naive, skills_Naive, conformities_Naive = conduct_oracle_experiment(NaiveConformityScore(), num_pairs_to_check, generator, X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5,rc={'text.usetex' : True})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rc('font', **{'family': 'serif'})\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 3)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"\")\n",
    "ax.set_ylabel(r\"Kendalls $\\tau$\")\n",
    "ax.set_xlabel(r\"No. Instances\")\n",
    "# ax.set_ylim([0.0,1])\n",
    "sns.lineplot(x=num_instances_to_check, y=tau_corrs_LAC, ax = ax, marker=\"o\",label=\"LAC\", legend=False)\n",
    "sns.lineplot(x=num_instances_to_check, y=tau_corrs_APS, ax = ax, marker=\"o\",label=\"APS\", legend=False)\n",
    "# sns.lineplot(x=num_instances_to_check, y=tau_corrs_TopK, ax = ax, marker=\"o\", label=\"TopK\", legend=False)\n",
    "lgd = fig.legend(loc='upper center', ncol=3, bbox_to_anchor=(0.5, 0.08), frameon=False)\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.savefig(\"replicating.pdf\",bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "# axes[1].set_title(\"APS\")\n",
    "# axes[1].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "# axes[1].set_xlabel(r\"No. Pairs\")\n",
    "# sns.lineplot(x=num_pairs_to_check, y=tau_corrs_APS, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[1.5069, 0.4172, 0.2459],\n",
      "        [1.5069, 0.4172, 0.2459]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[1.5069, 0.4172, 0.2459],\n",
      "        [1.5069, 0.4172, 0.2459]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[1.5069, 0.4172, 0.2459],\n",
      "        [1.5069, 0.4172, 0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [ 1.5069,  0.4172,  0.2459]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1367, -0.4950, -1.5344]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[ 1.5069,  0.4172,  0.2459],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.1367, -0.4950, -1.5344],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-2.6466,  2.2308,  1.7689]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.8738,  0.2905, -0.1785],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.4712, -0.8476, -0.0779]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-2.6466,  2.2308,  1.7689],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1098,  1.7773,  0.4134]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.4712, -0.8476, -0.0779],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.1926,  4.2098,  0.9399]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1098,  1.7773,  0.4134],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.2317,  1.1304, -1.3616]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.1926,  4.2098,  0.9399],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.0532, -1.2685, -0.5828]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.2317,  1.1304, -1.3616],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-1.6497,  1.2148,  0.3398]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0532, -1.2685, -0.5828],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.6497,  1.2148,  0.3398],\n",
      "        [-0.8738,  0.2905, -0.1785]]) tensor([[1],\n",
      "        [2]])\n",
      "435\n",
      "Epoch 1/250\n",
      "  Train Loss: 0.0528\n",
      "  Val Loss: 0.0526\n",
      "Epoch 2/250\n",
      "  Train Loss: 0.0524\n",
      "  Val Loss: 0.0523\n",
      "Epoch 3/250\n",
      "  Train Loss: 0.0522\n",
      "  Val Loss: 0.0521\n",
      "Epoch 4/250\n",
      "  Train Loss: 0.0519\n",
      "  Val Loss: 0.0518\n",
      "Epoch 5/250\n",
      "  Train Loss: 0.0517\n",
      "  Val Loss: 0.0516\n",
      "Epoch 6/250\n",
      "  Train Loss: 0.0514\n",
      "  Val Loss: 0.0513\n",
      "Epoch 7/250\n",
      "  Train Loss: 0.0512\n",
      "  Val Loss: 0.0511\n",
      "Epoch 8/250\n",
      "  Train Loss: 0.0510\n",
      "  Val Loss: 0.0510\n",
      "Epoch 9/250\n",
      "  Train Loss: 0.0509\n",
      "  Val Loss: 0.0508\n",
      "Epoch 10/250\n",
      "  Train Loss: 0.0507\n",
      "  Val Loss: 0.0507\n",
      "Epoch 11/250\n",
      "  Train Loss: 0.0506\n",
      "  Val Loss: 0.0505\n",
      "Epoch 12/250\n",
      "  Train Loss: 0.0505\n",
      "  Val Loss: 0.0504\n",
      "Epoch 13/250\n",
      "  Train Loss: 0.0503\n",
      "  Val Loss: 0.0503\n",
      "Epoch 14/250\n",
      "  Train Loss: 0.0502\n",
      "  Val Loss: 0.0501\n",
      "Epoch 15/250\n",
      "  Train Loss: 0.0501\n",
      "  Val Loss: 0.0500\n",
      "Epoch 16/250\n",
      "  Train Loss: 0.0500\n",
      "  Val Loss: 0.0499\n",
      "Epoch 17/250\n",
      "  Train Loss: 0.0499\n",
      "  Val Loss: 0.0498\n",
      "Epoch 18/250\n",
      "  Train Loss: 0.0498\n",
      "  Val Loss: 0.0497\n",
      "Epoch 19/250\n",
      "  Train Loss: 0.0497\n",
      "  Val Loss: 0.0496\n",
      "Epoch 20/250\n",
      "  Train Loss: 0.0496\n",
      "  Val Loss: 0.0496\n",
      "Epoch 21/250\n",
      "  Train Loss: 0.0495\n",
      "  Val Loss: 0.0495\n",
      "Epoch 22/250\n",
      "  Train Loss: 0.0495\n",
      "  Val Loss: 0.0494\n",
      "Epoch 23/250\n",
      "  Train Loss: 0.0494\n",
      "  Val Loss: 0.0493\n",
      "Epoch 24/250\n",
      "  Train Loss: 0.0493\n",
      "  Val Loss: 0.0493\n",
      "Epoch 25/250\n",
      "  Train Loss: 0.0493\n",
      "  Val Loss: 0.0492\n",
      "Epoch 26/250\n",
      "  Train Loss: 0.0492\n",
      "  Val Loss: 0.0491\n",
      "Epoch 27/250\n",
      "  Train Loss: 0.0491\n",
      "  Val Loss: 0.0491\n",
      "Epoch 28/250\n",
      "  Train Loss: 0.0491\n",
      "  Val Loss: 0.0490\n",
      "Epoch 29/250\n",
      "  Train Loss: 0.0490\n",
      "  Val Loss: 0.0490\n",
      "Epoch 30/250\n",
      "  Train Loss: 0.0489\n",
      "  Val Loss: 0.0489\n",
      "Epoch 31/250\n",
      "  Train Loss: 0.0489\n",
      "  Val Loss: 0.0488\n",
      "Epoch 32/250\n",
      "  Train Loss: 0.0488\n",
      "  Val Loss: 0.0488\n",
      "Epoch 33/250\n",
      "  Train Loss: 0.0488\n",
      "  Val Loss: 0.0487\n",
      "Epoch 34/250\n",
      "  Train Loss: 0.0487\n",
      "  Val Loss: 0.0486\n",
      "Epoch 35/250\n",
      "  Train Loss: 0.0486\n",
      "  Val Loss: 0.0486\n",
      "Epoch 36/250\n",
      "  Train Loss: 0.0486\n",
      "  Val Loss: 0.0485\n",
      "Epoch 37/250\n",
      "  Train Loss: 0.0485\n",
      "  Val Loss: 0.0485\n",
      "Epoch 38/250\n",
      "  Train Loss: 0.0484\n",
      "  Val Loss: 0.0484\n",
      "Epoch 39/250\n",
      "  Train Loss: 0.0484\n",
      "  Val Loss: 0.0483\n",
      "Epoch 40/250\n",
      "  Train Loss: 0.0483\n",
      "  Val Loss: 0.0482\n",
      "Epoch 41/250\n",
      "  Train Loss: 0.0482\n",
      "  Val Loss: 0.0482\n",
      "Epoch 42/250\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0481\n",
      "Epoch 43/250\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0480\n",
      "Epoch 44/250\n",
      "  Train Loss: 0.0480\n",
      "  Val Loss: 0.0479\n",
      "Epoch 45/250\n",
      "  Train Loss: 0.0479\n",
      "  Val Loss: 0.0478\n",
      "Epoch 46/250\n",
      "  Train Loss: 0.0478\n",
      "  Val Loss: 0.0477\n",
      "Epoch 47/250\n",
      "  Train Loss: 0.0477\n",
      "  Val Loss: 0.0476\n",
      "Epoch 48/250\n",
      "  Train Loss: 0.0476\n",
      "  Val Loss: 0.0475\n",
      "Epoch 49/250\n",
      "  Train Loss: 0.0475\n",
      "  Val Loss: 0.0474\n",
      "Epoch 50/250\n",
      "  Train Loss: 0.0474\n",
      "  Val Loss: 0.0473\n",
      "Epoch 51/250\n",
      "  Train Loss: 0.0473\n",
      "  Val Loss: 0.0472\n",
      "Epoch 52/250\n",
      "  Train Loss: 0.0472\n",
      "  Val Loss: 0.0471\n",
      "Epoch 53/250\n",
      "  Train Loss: 0.0471\n",
      "  Val Loss: 0.0470\n",
      "Epoch 54/250\n",
      "  Train Loss: 0.0469\n",
      "  Val Loss: 0.0468\n",
      "Epoch 55/250\n",
      "  Train Loss: 0.0468\n",
      "  Val Loss: 0.0467\n",
      "Epoch 56/250\n",
      "  Train Loss: 0.0467\n",
      "  Val Loss: 0.0465\n",
      "Epoch 57/250\n",
      "  Train Loss: 0.0465\n",
      "  Val Loss: 0.0464\n",
      "Epoch 58/250\n",
      "  Train Loss: 0.0464\n",
      "  Val Loss: 0.0462\n",
      "Epoch 59/250\n",
      "  Train Loss: 0.0462\n",
      "  Val Loss: 0.0461\n",
      "Epoch 60/250\n",
      "  Train Loss: 0.0460\n",
      "  Val Loss: 0.0459\n",
      "Epoch 61/250\n",
      "  Train Loss: 0.0459\n",
      "  Val Loss: 0.0457\n",
      "Epoch 62/250\n",
      "  Train Loss: 0.0457\n",
      "  Val Loss: 0.0455\n",
      "Epoch 63/250\n",
      "  Train Loss: 0.0455\n",
      "  Val Loss: 0.0454\n",
      "Epoch 64/250\n",
      "  Train Loss: 0.0453\n",
      "  Val Loss: 0.0452\n",
      "Epoch 65/250\n",
      "  Train Loss: 0.0452\n",
      "  Val Loss: 0.0450\n",
      "Epoch 66/250\n",
      "  Train Loss: 0.0450\n",
      "  Val Loss: 0.0448\n",
      "Epoch 67/250\n",
      "  Train Loss: 0.0447\n",
      "  Val Loss: 0.0446\n",
      "Epoch 68/250\n",
      "  Train Loss: 0.0445\n",
      "  Val Loss: 0.0444\n",
      "Epoch 69/250\n",
      "  Train Loss: 0.0443\n",
      "  Val Loss: 0.0442\n",
      "Epoch 70/250\n",
      "  Train Loss: 0.0441\n",
      "  Val Loss: 0.0439\n",
      "Epoch 71/250\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.0437\n",
      "Epoch 72/250\n",
      "  Train Loss: 0.0437\n",
      "  Val Loss: 0.0435\n",
      "Epoch 73/250\n",
      "  Train Loss: 0.0434\n",
      "  Val Loss: 0.0432\n",
      "Epoch 74/250\n",
      "  Train Loss: 0.0432\n",
      "  Val Loss: 0.0430\n",
      "Epoch 75/250\n",
      "  Train Loss: 0.0430\n",
      "  Val Loss: 0.0428\n",
      "Epoch 76/250\n",
      "  Train Loss: 0.0427\n",
      "  Val Loss: 0.0425\n",
      "Epoch 77/250\n",
      "  Train Loss: 0.0425\n",
      "  Val Loss: 0.0423\n",
      "Epoch 78/250\n",
      "  Train Loss: 0.0423\n",
      "  Val Loss: 0.0421\n",
      "Epoch 79/250\n",
      "  Train Loss: 0.0420\n",
      "  Val Loss: 0.0418\n",
      "Epoch 80/250\n",
      "  Train Loss: 0.0418\n",
      "  Val Loss: 0.0416\n",
      "Epoch 81/250\n",
      "  Train Loss: 0.0416\n",
      "  Val Loss: 0.0414\n",
      "Epoch 82/250\n",
      "  Train Loss: 0.0413\n",
      "  Val Loss: 0.0411\n",
      "Epoch 83/250\n",
      "  Train Loss: 0.0411\n",
      "  Val Loss: 0.0409\n",
      "Epoch 84/250\n",
      "  Train Loss: 0.0409\n",
      "  Val Loss: 0.0407\n",
      "Epoch 85/250\n",
      "  Train Loss: 0.0407\n",
      "  Val Loss: 0.0405\n",
      "Epoch 86/250\n",
      "  Train Loss: 0.0405\n",
      "  Val Loss: 0.0403\n",
      "Epoch 87/250\n",
      "  Train Loss: 0.0403\n",
      "  Val Loss: 0.0401\n",
      "Epoch 88/250\n",
      "  Train Loss: 0.0401\n",
      "  Val Loss: 0.0399\n",
      "Epoch 89/250\n",
      "  Train Loss: 0.0399\n",
      "  Val Loss: 0.0397\n",
      "Epoch 90/250\n",
      "  Train Loss: 0.0397\n",
      "  Val Loss: 0.0395\n",
      "Epoch 91/250\n",
      "  Train Loss: 0.0395\n",
      "  Val Loss: 0.0393\n",
      "Epoch 92/250\n",
      "  Train Loss: 0.0393\n",
      "  Val Loss: 0.0391\n",
      "Epoch 93/250\n",
      "  Train Loss: 0.0391\n",
      "  Val Loss: 0.0390\n",
      "Epoch 94/250\n",
      "  Train Loss: 0.0390\n",
      "  Val Loss: 0.0388\n",
      "Epoch 95/250\n",
      "  Train Loss: 0.0388\n",
      "  Val Loss: 0.0387\n",
      "Epoch 96/250\n",
      "  Train Loss: 0.0387\n",
      "  Val Loss: 0.0385\n",
      "Epoch 97/250\n",
      "  Train Loss: 0.0385\n",
      "  Val Loss: 0.0384\n",
      "Epoch 98/250\n",
      "  Train Loss: 0.0384\n",
      "  Val Loss: 0.0382\n",
      "Epoch 99/250\n",
      "  Train Loss: 0.0383\n",
      "  Val Loss: 0.0381\n",
      "Epoch 100/250\n",
      "  Train Loss: 0.0381\n",
      "  Val Loss: 0.0380\n",
      "Epoch 101/250\n",
      "  Train Loss: 0.0380\n",
      "  Val Loss: 0.0379\n",
      "Epoch 102/250\n",
      "  Train Loss: 0.0379\n",
      "  Val Loss: 0.0378\n",
      "Epoch 103/250\n",
      "  Train Loss: 0.0378\n",
      "  Val Loss: 0.0377\n",
      "Epoch 104/250\n",
      "  Train Loss: 0.0377\n",
      "  Val Loss: 0.0375\n",
      "Epoch 105/250\n",
      "  Train Loss: 0.0376\n",
      "  Val Loss: 0.0375\n",
      "Epoch 106/250\n",
      "  Train Loss: 0.0375\n",
      "  Val Loss: 0.0374\n",
      "Epoch 107/250\n",
      "  Train Loss: 0.0374\n",
      "  Val Loss: 0.0373\n",
      "Epoch 108/250\n",
      "  Train Loss: 0.0373\n",
      "  Val Loss: 0.0372\n",
      "Epoch 109/250\n",
      "  Train Loss: 0.0372\n",
      "  Val Loss: 0.0371\n",
      "Epoch 110/250\n",
      "  Train Loss: 0.0372\n",
      "  Val Loss: 0.0370\n",
      "Epoch 111/250\n",
      "  Train Loss: 0.0371\n",
      "  Val Loss: 0.0370\n",
      "Epoch 112/250\n",
      "  Train Loss: 0.0370\n",
      "  Val Loss: 0.0369\n",
      "Epoch 113/250\n",
      "  Train Loss: 0.0370\n",
      "  Val Loss: 0.0368\n",
      "Epoch 114/250\n",
      "  Train Loss: 0.0369\n",
      "  Val Loss: 0.0368\n",
      "Epoch 115/250\n",
      "  Train Loss: 0.0368\n",
      "  Val Loss: 0.0367\n",
      "Epoch 116/250\n",
      "  Train Loss: 0.0368\n",
      "  Val Loss: 0.0367\n",
      "Epoch 117/250\n",
      "  Train Loss: 0.0367\n",
      "  Val Loss: 0.0366\n",
      "Epoch 118/250\n",
      "  Train Loss: 0.0367\n",
      "  Val Loss: 0.0366\n",
      "Epoch 119/250\n",
      "  Train Loss: 0.0366\n",
      "  Val Loss: 0.0365\n",
      "Epoch 120/250\n",
      "  Train Loss: 0.0366\n",
      "  Val Loss: 0.0365\n",
      "Epoch 121/250\n",
      "  Train Loss: 0.0365\n",
      "  Val Loss: 0.0364\n",
      "Epoch 122/250\n",
      "  Train Loss: 0.0365\n",
      "  Val Loss: 0.0364\n",
      "Epoch 123/250\n",
      "  Train Loss: 0.0364\n",
      "  Val Loss: 0.0364\n",
      "Epoch 124/250\n",
      "  Train Loss: 0.0364\n",
      "  Val Loss: 0.0363\n",
      "Epoch 125/250\n",
      "  Train Loss: 0.0364\n",
      "  Val Loss: 0.0363\n",
      "Epoch 126/250\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0362\n",
      "Epoch 127/250\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0362\n",
      "Epoch 128/250\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0362\n",
      "Epoch 129/250\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0361\n",
      "Epoch 130/250\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0361\n",
      "Epoch 131/250\n",
      "  Train Loss: 0.0361\n",
      "  Val Loss: 0.0361\n",
      "Epoch 132/250\n",
      "  Train Loss: 0.0361\n",
      "  Val Loss: 0.0360\n",
      "Epoch 133/250\n",
      "  Train Loss: 0.0361\n",
      "  Val Loss: 0.0360\n",
      "Epoch 134/250\n",
      "  Train Loss: 0.0361\n",
      "  Val Loss: 0.0360\n",
      "Epoch 135/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0360\n",
      "Epoch 136/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0359\n",
      "Epoch 137/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0359\n",
      "Epoch 138/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0359\n",
      "Epoch 139/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0359\n",
      "Epoch 140/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0359\n",
      "Epoch 141/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0358\n",
      "Epoch 142/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0358\n",
      "Epoch 143/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0358\n",
      "Epoch 144/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0358\n",
      "Epoch 145/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0358\n",
      "Epoch 146/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0357\n",
      "Epoch 147/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0357\n",
      "Epoch 148/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0357\n",
      "Epoch 149/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0357\n",
      "Epoch 150/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0357\n",
      "Epoch 151/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0356\n",
      "Epoch 152/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0356\n",
      "Epoch 153/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0356\n",
      "Epoch 154/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0356\n",
      "Epoch 155/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0355\n",
      "Epoch 156/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0355\n",
      "Epoch 157/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0355\n",
      "Epoch 158/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0355\n",
      "Epoch 159/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0355\n",
      "Epoch 160/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0354\n",
      "Epoch 161/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0354\n",
      "Epoch 162/250\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0354\n",
      "Epoch 163/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0354\n",
      "Epoch 164/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0354\n",
      "Epoch 165/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0353\n",
      "Epoch 166/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0353\n",
      "Epoch 167/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0353\n",
      "Epoch 168/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0353\n",
      "Epoch 169/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0353\n",
      "Epoch 170/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0352\n",
      "Epoch 171/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0352\n",
      "Epoch 172/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0352\n",
      "Epoch 173/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0352\n",
      "Epoch 174/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0352\n",
      "Epoch 175/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0351\n",
      "Epoch 176/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0351\n",
      "Epoch 177/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0351\n",
      "Epoch 178/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0351\n",
      "Epoch 179/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0351\n",
      "Epoch 180/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0350\n",
      "Epoch 181/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0350\n",
      "Epoch 182/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0350\n",
      "Epoch 183/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0350\n",
      "Epoch 184/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0350\n",
      "Epoch 185/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0350\n",
      "Epoch 186/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0349\n",
      "Epoch 187/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0349\n",
      "Epoch 188/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0349\n",
      "Epoch 189/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0349\n",
      "Epoch 190/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0349\n",
      "Epoch 191/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0349\n",
      "Epoch 192/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 193/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 194/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 195/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 196/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0348\n",
      "Epoch 197/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0348\n",
      "Epoch 198/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0348\n",
      "Epoch 199/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 200/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 201/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 202/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 203/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0347\n",
      "Epoch 204/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0347\n",
      "Epoch 205/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0347\n",
      "Epoch 206/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 207/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 208/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 209/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 210/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0346\n",
      "Epoch 211/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0346\n",
      "Epoch 212/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0346\n",
      "Epoch 213/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 214/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 215/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 216/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 217/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0345\n",
      "Epoch 218/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0345\n",
      "Epoch 219/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0345\n",
      "Epoch 220/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0345\n",
      "Epoch 221/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 222/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 223/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 224/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 225/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0344\n",
      "Epoch 226/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0344\n",
      "Epoch 227/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0344\n",
      "Epoch 228/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 229/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 230/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 231/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 232/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0343\n",
      "Epoch 233/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0343\n",
      "Epoch 234/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0343\n",
      "Epoch 235/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 236/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 237/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 238/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 239/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0342\n",
      "Epoch 240/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0342\n",
      "Epoch 241/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0342\n",
      "Epoch 242/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0342\n",
      "Epoch 243/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 244/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 245/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 246/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 247/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0341\n",
      "Epoch 248/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0341\n",
      "Epoch 249/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0341\n",
      "Epoch 250/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0340\n"
     ]
    }
   ],
   "source": [
    "X_seed, y_seed = make_classification(n_samples=1000, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42)\n",
    "conformity_score = APSConformityScore()\n",
    "generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "generator.fit(X_seed, y_seed)\n",
    "X_cal, y_cal = generator.generate(n=100)\n",
    "mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "# create mapie classifier for conformity scores\n",
    "mapie_clf.fit(X_cal, y_cal)\n",
    "# create \n",
    "oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "\n",
    "# generate all possible pairs for a couple of instances\n",
    "n_instances = 10\n",
    "n_classes = len(generator.classes_)\n",
    "n_obs = n_instances * n_classes\n",
    "X_train = generator.generate_instances(n_instances).repeat(n_classes, axis=0)\n",
    "y_train = np.tile(generator.classes_, n_instances)\n",
    "conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "X_sorted = X_train[sort_idx]\n",
    "y_sorted = y_train[sort_idx]\n",
    "conformities_sorted = conformities[sort_idx]\n",
    "\n",
    "X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "y_pairs = np.expand_dims(y_pairs, axis=-1)\n",
    "\n",
    "\n",
    "ds = LabelPairDataset()\n",
    "ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "for x,y in ds:\n",
    "    print(x,y)\n",
    "print(len(ds))\n",
    "model = LabelRankingModel(input_dim=generator.n_features_, hidden_dims=3*[generator.n_features_], activations=[torch.nn.Sigmoid(), SortLayer(),torch.nn.Identity()], output_dim=len(generator.classes_))\n",
    "\n",
    "pair_loader = DataLoader(ds, batch_size=32)\n",
    "model.num_classes = generator.n_classes_\n",
    "model._fit(pair_loader, val_loader=pair_loader, num_epochs=250, learning_rate=0.001, verbose=True)\n",
    "\n",
    "\n",
    "# # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "# X_test, y_test = X_train, y_train\n",
    "# conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "# skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "# tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "# print(\"in-sample: \", tau_corr)\n",
    "# X_test, y_test = generator.generate(n=10)\n",
    "# conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "# skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "# tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "# print(\"out-of-sample: \", tau_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[0.6766, 0.6402, 0.8921],\n",
      "        [0.6766, 0.6402, 0.8921]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[0.6766, 0.6402, 0.8921],\n",
      "        [0.6766, 0.6402, 0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.3553,  1.3900, -2.2718]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.3553,  1.3900, -2.2718],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [2]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[0.6766, 0.6402, 0.8921],\n",
      "        [0.6766, 0.6402, 0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [2]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.7794,  3.7924,  1.9101],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2696, -1.9312, -1.6093]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [2]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-0.2696, -1.9312, -1.6093],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[2],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[2],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2663,  2.1617, -0.6311]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.0614,  0.7707, -0.2419]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2663,  2.1617, -0.6311],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.6758,  0.1966,  0.4712]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[0],\n",
      "        [0]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-1.0614,  0.7707, -0.2419],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-2.0302, -0.0881,  1.1705]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.6758,  0.1966,  0.4712],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-3.1908,  2.8808,  0.8630]]) tensor([[1],\n",
      "        [0]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-2.0302, -0.0881,  1.1705],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-0.2583, -0.3482,  1.0580]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-3.1908,  2.8808,  0.8630],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[0],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [ 0.6766,  0.6402,  0.8921]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[-0.2583, -0.3482,  1.0580],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "tensor([[ 0.6766,  0.6402,  0.8921],\n",
      "        [-1.7794,  3.7924,  1.9101]]) tensor([[1],\n",
      "        [1]])\n",
      "14\n",
      "Epoch 1/250\n",
      "  Train Loss: 0.0597\n",
      "  Val Loss: 0.0589\n",
      "Epoch 2/250\n",
      "  Train Loss: 0.0584\n",
      "  Val Loss: 0.0577\n",
      "Epoch 3/250\n",
      "  Train Loss: 0.0573\n",
      "  Val Loss: 0.0568\n",
      "Epoch 4/250\n",
      "  Train Loss: 0.0563\n",
      "  Val Loss: 0.0559\n",
      "Epoch 5/250\n",
      "  Train Loss: 0.0555\n",
      "  Val Loss: 0.0550\n",
      "Epoch 6/250\n",
      "  Train Loss: 0.0547\n",
      "  Val Loss: 0.0543\n",
      "Epoch 7/250\n",
      "  Train Loss: 0.0539\n",
      "  Val Loss: 0.0535\n",
      "Epoch 8/250\n",
      "  Train Loss: 0.0532\n",
      "  Val Loss: 0.0528\n",
      "Epoch 9/250\n",
      "  Train Loss: 0.0525\n",
      "  Val Loss: 0.0522\n",
      "Epoch 10/250\n",
      "  Train Loss: 0.0519\n",
      "  Val Loss: 0.0515\n",
      "Epoch 11/250\n",
      "  Train Loss: 0.0512\n",
      "  Val Loss: 0.0509\n",
      "Epoch 12/250\n",
      "  Train Loss: 0.0506\n",
      "  Val Loss: 0.0503\n",
      "Epoch 13/250\n",
      "  Train Loss: 0.0501\n",
      "  Val Loss: 0.0498\n",
      "Epoch 14/250\n",
      "  Train Loss: 0.0495\n",
      "  Val Loss: 0.0492\n",
      "Epoch 15/250\n",
      "  Train Loss: 0.0490\n",
      "  Val Loss: 0.0488\n",
      "Epoch 16/250\n",
      "  Train Loss: 0.0485\n",
      "  Val Loss: 0.0483\n",
      "Epoch 17/250\n",
      "  Train Loss: 0.0481\n",
      "  Val Loss: 0.0479\n",
      "Epoch 18/250\n",
      "  Train Loss: 0.0477\n",
      "  Val Loss: 0.0475\n",
      "Epoch 19/250\n",
      "  Train Loss: 0.0474\n",
      "  Val Loss: 0.0472\n",
      "Epoch 20/250\n",
      "  Train Loss: 0.0471\n",
      "  Val Loss: 0.0469\n",
      "Epoch 21/250\n",
      "  Train Loss: 0.0468\n",
      "  Val Loss: 0.0466\n",
      "Epoch 22/250\n",
      "  Train Loss: 0.0465\n",
      "  Val Loss: 0.0464\n",
      "Epoch 23/250\n",
      "  Train Loss: 0.0463\n",
      "  Val Loss: 0.0462\n",
      "Epoch 24/250\n",
      "  Train Loss: 0.0461\n",
      "  Val Loss: 0.0460\n",
      "Epoch 25/250\n",
      "  Train Loss: 0.0459\n",
      "  Val Loss: 0.0458\n",
      "Epoch 26/250\n",
      "  Train Loss: 0.0457\n",
      "  Val Loss: 0.0456\n",
      "Epoch 27/250\n",
      "  Train Loss: 0.0456\n",
      "  Val Loss: 0.0455\n",
      "Epoch 28/250\n",
      "  Train Loss: 0.0454\n",
      "  Val Loss: 0.0453\n",
      "Epoch 29/250\n",
      "  Train Loss: 0.0453\n",
      "  Val Loss: 0.0452\n",
      "Epoch 30/250\n",
      "  Train Loss: 0.0452\n",
      "  Val Loss: 0.0451\n",
      "Epoch 31/250\n",
      "  Train Loss: 0.0451\n",
      "  Val Loss: 0.0450\n",
      "Epoch 32/250\n",
      "  Train Loss: 0.0450\n",
      "  Val Loss: 0.0449\n",
      "Epoch 33/250\n",
      "  Train Loss: 0.0449\n",
      "  Val Loss: 0.0448\n",
      "Epoch 34/250\n",
      "  Train Loss: 0.0448\n",
      "  Val Loss: 0.0447\n",
      "Epoch 35/250\n",
      "  Train Loss: 0.0447\n",
      "  Val Loss: 0.0446\n",
      "Epoch 36/250\n",
      "  Train Loss: 0.0446\n",
      "  Val Loss: 0.0445\n",
      "Epoch 37/250\n",
      "  Train Loss: 0.0445\n",
      "  Val Loss: 0.0444\n",
      "Epoch 38/250\n",
      "  Train Loss: 0.0444\n",
      "  Val Loss: 0.0444\n",
      "Epoch 39/250\n",
      "  Train Loss: 0.0444\n",
      "  Val Loss: 0.0443\n",
      "Epoch 40/250\n",
      "  Train Loss: 0.0443\n",
      "  Val Loss: 0.0442\n",
      "Epoch 41/250\n",
      "  Train Loss: 0.0442\n",
      "  Val Loss: 0.0441\n",
      "Epoch 42/250\n",
      "  Train Loss: 0.0441\n",
      "  Val Loss: 0.0440\n",
      "Epoch 43/250\n",
      "  Train Loss: 0.0440\n",
      "  Val Loss: 0.0440\n",
      "Epoch 44/250\n",
      "  Train Loss: 0.0440\n",
      "  Val Loss: 0.0439\n",
      "Epoch 45/250\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.0438\n",
      "Epoch 46/250\n",
      "  Train Loss: 0.0438\n",
      "  Val Loss: 0.0437\n",
      "Epoch 47/250\n",
      "  Train Loss: 0.0437\n",
      "  Val Loss: 0.0436\n",
      "Epoch 48/250\n",
      "  Train Loss: 0.0436\n",
      "  Val Loss: 0.0435\n",
      "Epoch 49/250\n",
      "  Train Loss: 0.0435\n",
      "  Val Loss: 0.0435\n",
      "Epoch 50/250\n",
      "  Train Loss: 0.0435\n",
      "  Val Loss: 0.0434\n",
      "Epoch 51/250\n",
      "  Train Loss: 0.0434\n",
      "  Val Loss: 0.0433\n",
      "Epoch 52/250\n",
      "  Train Loss: 0.0433\n",
      "  Val Loss: 0.0432\n",
      "Epoch 53/250\n",
      "  Train Loss: 0.0432\n",
      "  Val Loss: 0.0431\n",
      "Epoch 54/250\n",
      "  Train Loss: 0.0431\n",
      "  Val Loss: 0.0430\n",
      "Epoch 55/250\n",
      "  Train Loss: 0.0430\n",
      "  Val Loss: 0.0429\n",
      "Epoch 56/250\n",
      "  Train Loss: 0.0429\n",
      "  Val Loss: 0.0428\n",
      "Epoch 57/250\n",
      "  Train Loss: 0.0428\n",
      "  Val Loss: 0.0427\n",
      "Epoch 58/250\n",
      "  Train Loss: 0.0427\n",
      "  Val Loss: 0.0426\n",
      "Epoch 59/250\n",
      "  Train Loss: 0.0426\n",
      "  Val Loss: 0.0425\n",
      "Epoch 60/250\n",
      "  Train Loss: 0.0425\n",
      "  Val Loss: 0.0424\n",
      "Epoch 61/250\n",
      "  Train Loss: 0.0424\n",
      "  Val Loss: 0.0423\n",
      "Epoch 62/250\n",
      "  Train Loss: 0.0423\n",
      "  Val Loss: 0.0422\n",
      "Epoch 63/250\n",
      "  Train Loss: 0.0422\n",
      "  Val Loss: 0.0420\n",
      "Epoch 64/250\n",
      "  Train Loss: 0.0420\n",
      "  Val Loss: 0.0419\n",
      "Epoch 65/250\n",
      "  Train Loss: 0.0419\n",
      "  Val Loss: 0.0418\n",
      "Epoch 66/250\n",
      "  Train Loss: 0.0418\n",
      "  Val Loss: 0.0417\n",
      "Epoch 67/250\n",
      "  Train Loss: 0.0417\n",
      "  Val Loss: 0.0416\n",
      "Epoch 68/250\n",
      "  Train Loss: 0.0416\n",
      "  Val Loss: 0.0414\n",
      "Epoch 69/250\n",
      "  Train Loss: 0.0414\n",
      "  Val Loss: 0.0413\n",
      "Epoch 70/250\n",
      "  Train Loss: 0.0413\n",
      "  Val Loss: 0.0412\n",
      "Epoch 71/250\n",
      "  Train Loss: 0.0412\n",
      "  Val Loss: 0.0410\n",
      "Epoch 72/250\n",
      "  Train Loss: 0.0410\n",
      "  Val Loss: 0.0409\n",
      "Epoch 73/250\n",
      "  Train Loss: 0.0409\n",
      "  Val Loss: 0.0408\n",
      "Epoch 74/250\n",
      "  Train Loss: 0.0408\n",
      "  Val Loss: 0.0406\n",
      "Epoch 75/250\n",
      "  Train Loss: 0.0406\n",
      "  Val Loss: 0.0405\n",
      "Epoch 76/250\n",
      "  Train Loss: 0.0405\n",
      "  Val Loss: 0.0403\n",
      "Epoch 77/250\n",
      "  Train Loss: 0.0403\n",
      "  Val Loss: 0.0402\n",
      "Epoch 78/250\n",
      "  Train Loss: 0.0402\n",
      "  Val Loss: 0.0400\n",
      "Epoch 79/250\n",
      "  Train Loss: 0.0400\n",
      "  Val Loss: 0.0399\n",
      "Epoch 80/250\n",
      "  Train Loss: 0.0399\n",
      "  Val Loss: 0.0397\n",
      "Epoch 81/250\n",
      "  Train Loss: 0.0397\n",
      "  Val Loss: 0.0396\n",
      "Epoch 82/250\n",
      "  Train Loss: 0.0396\n",
      "  Val Loss: 0.0394\n",
      "Epoch 83/250\n",
      "  Train Loss: 0.0394\n",
      "  Val Loss: 0.0393\n",
      "Epoch 84/250\n",
      "  Train Loss: 0.0393\n",
      "  Val Loss: 0.0391\n",
      "Epoch 85/250\n",
      "  Train Loss: 0.0391\n",
      "  Val Loss: 0.0390\n",
      "Epoch 86/250\n",
      "  Train Loss: 0.0390\n",
      "  Val Loss: 0.0388\n",
      "Epoch 87/250\n",
      "  Train Loss: 0.0388\n",
      "  Val Loss: 0.0387\n",
      "Epoch 88/250\n",
      "  Train Loss: 0.0387\n",
      "  Val Loss: 0.0385\n",
      "Epoch 89/250\n",
      "  Train Loss: 0.0385\n",
      "  Val Loss: 0.0384\n",
      "Epoch 90/250\n",
      "  Train Loss: 0.0383\n",
      "  Val Loss: 0.0382\n",
      "Epoch 91/250\n",
      "  Train Loss: 0.0382\n",
      "  Val Loss: 0.0381\n",
      "Epoch 92/250\n",
      "  Train Loss: 0.0380\n",
      "  Val Loss: 0.0379\n",
      "Epoch 93/250\n",
      "  Train Loss: 0.0379\n",
      "  Val Loss: 0.0377\n",
      "Epoch 94/250\n",
      "  Train Loss: 0.0377\n",
      "  Val Loss: 0.0376\n",
      "Epoch 95/250\n",
      "  Train Loss: 0.0376\n",
      "  Val Loss: 0.0374\n",
      "Epoch 96/250\n",
      "  Train Loss: 0.0374\n",
      "  Val Loss: 0.0373\n",
      "Epoch 97/250\n",
      "  Train Loss: 0.0373\n",
      "  Val Loss: 0.0371\n",
      "Epoch 98/250\n",
      "  Train Loss: 0.0371\n",
      "  Val Loss: 0.0370\n",
      "Epoch 99/250\n",
      "  Train Loss: 0.0370\n",
      "  Val Loss: 0.0369\n",
      "Epoch 100/250\n",
      "  Train Loss: 0.0369\n",
      "  Val Loss: 0.0367\n",
      "Epoch 101/250\n",
      "  Train Loss: 0.0367\n",
      "  Val Loss: 0.0366\n",
      "Epoch 102/250\n",
      "  Train Loss: 0.0366\n",
      "  Val Loss: 0.0364\n",
      "Epoch 103/250\n",
      "  Train Loss: 0.0364\n",
      "  Val Loss: 0.0363\n",
      "Epoch 104/250\n",
      "  Train Loss: 0.0363\n",
      "  Val Loss: 0.0362\n",
      "Epoch 105/250\n",
      "  Train Loss: 0.0362\n",
      "  Val Loss: 0.0360\n",
      "Epoch 106/250\n",
      "  Train Loss: 0.0360\n",
      "  Val Loss: 0.0359\n",
      "Epoch 107/250\n",
      "  Train Loss: 0.0359\n",
      "  Val Loss: 0.0358\n",
      "Epoch 108/250\n",
      "  Train Loss: 0.0358\n",
      "  Val Loss: 0.0357\n",
      "Epoch 109/250\n",
      "  Train Loss: 0.0357\n",
      "  Val Loss: 0.0355\n",
      "Epoch 110/250\n",
      "  Train Loss: 0.0356\n",
      "  Val Loss: 0.0354\n",
      "Epoch 111/250\n",
      "  Train Loss: 0.0354\n",
      "  Val Loss: 0.0353\n",
      "Epoch 112/250\n",
      "  Train Loss: 0.0353\n",
      "  Val Loss: 0.0352\n",
      "Epoch 113/250\n",
      "  Train Loss: 0.0352\n",
      "  Val Loss: 0.0351\n",
      "Epoch 114/250\n",
      "  Train Loss: 0.0351\n",
      "  Val Loss: 0.0350\n",
      "Epoch 115/250\n",
      "  Train Loss: 0.0350\n",
      "  Val Loss: 0.0349\n",
      "Epoch 116/250\n",
      "  Train Loss: 0.0349\n",
      "  Val Loss: 0.0348\n",
      "Epoch 117/250\n",
      "  Train Loss: 0.0348\n",
      "  Val Loss: 0.0347\n",
      "Epoch 118/250\n",
      "  Train Loss: 0.0347\n",
      "  Val Loss: 0.0346\n",
      "Epoch 119/250\n",
      "  Train Loss: 0.0346\n",
      "  Val Loss: 0.0345\n",
      "Epoch 120/250\n",
      "  Train Loss: 0.0345\n",
      "  Val Loss: 0.0344\n",
      "Epoch 121/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 122/250\n",
      "  Train Loss: 0.0344\n",
      "  Val Loss: 0.0343\n",
      "Epoch 123/250\n",
      "  Train Loss: 0.0343\n",
      "  Val Loss: 0.0342\n",
      "Epoch 124/250\n",
      "  Train Loss: 0.0342\n",
      "  Val Loss: 0.0341\n",
      "Epoch 125/250\n",
      "  Train Loss: 0.0341\n",
      "  Val Loss: 0.0340\n",
      "Epoch 126/250\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0339\n",
      "Epoch 127/250\n",
      "  Train Loss: 0.0340\n",
      "  Val Loss: 0.0339\n",
      "Epoch 128/250\n",
      "  Train Loss: 0.0339\n",
      "  Val Loss: 0.0338\n",
      "Epoch 129/250\n",
      "  Train Loss: 0.0338\n",
      "  Val Loss: 0.0337\n",
      "Epoch 130/250\n",
      "  Train Loss: 0.0338\n",
      "  Val Loss: 0.0337\n",
      "Epoch 131/250\n",
      "  Train Loss: 0.0337\n",
      "  Val Loss: 0.0336\n",
      "Epoch 132/250\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0336\n",
      "Epoch 133/250\n",
      "  Train Loss: 0.0336\n",
      "  Val Loss: 0.0335\n",
      "Epoch 134/250\n",
      "  Train Loss: 0.0335\n",
      "  Val Loss: 0.0334\n",
      "Epoch 135/250\n",
      "  Train Loss: 0.0335\n",
      "  Val Loss: 0.0334\n",
      "Epoch 136/250\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0333\n",
      "Epoch 137/250\n",
      "  Train Loss: 0.0334\n",
      "  Val Loss: 0.0333\n",
      "Epoch 138/250\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0332\n",
      "Epoch 139/250\n",
      "  Train Loss: 0.0333\n",
      "  Val Loss: 0.0332\n",
      "Epoch 140/250\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0331\n",
      "Epoch 141/250\n",
      "  Train Loss: 0.0332\n",
      "  Val Loss: 0.0331\n",
      "Epoch 142/250\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0331\n",
      "Epoch 143/250\n",
      "  Train Loss: 0.0331\n",
      "  Val Loss: 0.0330\n",
      "Epoch 144/250\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0330\n",
      "Epoch 145/250\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0329\n",
      "Epoch 146/250\n",
      "  Train Loss: 0.0330\n",
      "  Val Loss: 0.0329\n",
      "Epoch 147/250\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0329\n",
      "Epoch 148/250\n",
      "  Train Loss: 0.0329\n",
      "  Val Loss: 0.0328\n",
      "Epoch 149/250\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0328\n",
      "Epoch 150/250\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0327\n",
      "Epoch 151/250\n",
      "  Train Loss: 0.0328\n",
      "  Val Loss: 0.0327\n",
      "Epoch 152/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0327\n",
      "Epoch 153/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0327\n",
      "Epoch 154/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0326\n",
      "Epoch 155/250\n",
      "  Train Loss: 0.0327\n",
      "  Val Loss: 0.0326\n",
      "Epoch 156/250\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0326\n",
      "Epoch 157/250\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0325\n",
      "Epoch 158/250\n",
      "  Train Loss: 0.0326\n",
      "  Val Loss: 0.0325\n",
      "Epoch 159/250\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0325\n",
      "Epoch 160/250\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0325\n",
      "Epoch 161/250\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0324\n",
      "Epoch 162/250\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0324\n",
      "Epoch 163/250\n",
      "  Train Loss: 0.0324\n",
      "  Val Loss: 0.0324\n",
      "Epoch 164/250\n",
      "  Train Loss: 0.0324\n",
      "  Val Loss: 0.0324\n",
      "Epoch 165/250\n",
      "  Train Loss: 0.0324\n",
      "  Val Loss: 0.0323\n",
      "Epoch 166/250\n",
      "  Train Loss: 0.0324\n",
      "  Val Loss: 0.0323\n",
      "Epoch 167/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0323\n",
      "Epoch 168/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0323\n",
      "Epoch 169/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0322\n",
      "Epoch 170/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0322\n",
      "Epoch 171/250\n",
      "  Train Loss: 0.0323\n",
      "  Val Loss: 0.0322\n",
      "Epoch 172/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0322\n",
      "Epoch 173/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0322\n",
      "Epoch 174/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0321\n",
      "Epoch 175/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0321\n",
      "Epoch 176/250\n",
      "  Train Loss: 0.0322\n",
      "  Val Loss: 0.0321\n",
      "Epoch 177/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0321\n",
      "Epoch 178/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0321\n",
      "Epoch 179/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0320\n",
      "Epoch 180/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0320\n",
      "Epoch 181/250\n",
      "  Train Loss: 0.0321\n",
      "  Val Loss: 0.0320\n",
      "Epoch 182/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0320\n",
      "Epoch 183/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0320\n",
      "Epoch 184/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0320\n",
      "Epoch 185/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0319\n",
      "Epoch 186/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0319\n",
      "Epoch 187/250\n",
      "  Train Loss: 0.0320\n",
      "  Val Loss: 0.0319\n",
      "Epoch 188/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0319\n",
      "Epoch 189/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0319\n",
      "Epoch 190/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0319\n",
      "Epoch 191/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0318\n",
      "Epoch 192/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0318\n",
      "Epoch 193/250\n",
      "  Train Loss: 0.0319\n",
      "  Val Loss: 0.0318\n",
      "Epoch 194/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0318\n",
      "Epoch 195/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0318\n",
      "Epoch 196/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0318\n",
      "Epoch 197/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0318\n",
      "Epoch 198/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0317\n",
      "Epoch 199/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0317\n",
      "Epoch 200/250\n",
      "  Train Loss: 0.0318\n",
      "  Val Loss: 0.0317\n",
      "Epoch 201/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0317\n",
      "Epoch 202/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0317\n",
      "Epoch 203/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0317\n",
      "Epoch 204/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0317\n",
      "Epoch 205/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0316\n",
      "Epoch 206/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0316\n",
      "Epoch 207/250\n",
      "  Train Loss: 0.0317\n",
      "  Val Loss: 0.0316\n",
      "Epoch 208/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0316\n",
      "Epoch 209/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0316\n",
      "Epoch 210/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0316\n",
      "Epoch 211/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0316\n",
      "Epoch 212/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0315\n",
      "Epoch 213/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0315\n",
      "Epoch 214/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0315\n",
      "Epoch 215/250\n",
      "  Train Loss: 0.0316\n",
      "  Val Loss: 0.0315\n",
      "Epoch 216/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0315\n",
      "Epoch 217/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0315\n",
      "Epoch 218/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0315\n",
      "Epoch 219/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0315\n",
      "Epoch 220/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 221/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 222/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 223/250\n",
      "  Train Loss: 0.0315\n",
      "  Val Loss: 0.0314\n",
      "Epoch 224/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0314\n",
      "Epoch 225/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0314\n",
      "Epoch 226/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0314\n",
      "Epoch 227/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0314\n",
      "Epoch 228/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 229/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 230/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 231/250\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0313\n",
      "Epoch 232/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0313\n",
      "Epoch 233/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0313\n",
      "Epoch 234/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0313\n",
      "Epoch 235/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0313\n",
      "Epoch 236/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0313\n",
      "Epoch 237/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0312\n",
      "Epoch 238/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0312\n",
      "Epoch 239/250\n",
      "  Train Loss: 0.0313\n",
      "  Val Loss: 0.0312\n",
      "Epoch 240/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0312\n",
      "Epoch 241/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0312\n",
      "Epoch 242/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0312\n",
      "Epoch 243/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0312\n",
      "Epoch 244/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0312\n",
      "Epoch 245/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 246/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 247/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 248/250\n",
      "  Train Loss: 0.0312\n",
      "  Val Loss: 0.0311\n",
      "Epoch 249/250\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0311\n",
      "Epoch 250/250\n",
      "  Train Loss: 0.0311\n",
      "  Val Loss: 0.0311\n"
     ]
    }
   ],
   "source": [
    "n_instances = 10\n",
    "n_classes = len(generator.classes_)\n",
    "n_obs = n_instances * n_classes\n",
    "X_train = generator.generate_instances(n_instances).repeat(n_classes, axis=0)\n",
    "y_train = np.tile(generator.classes_, n_instances)\n",
    "conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "X_sorted = X_train[sort_idx]\n",
    "y_sorted = y_train[sort_idx]\n",
    "conformities_sorted = conformities[sort_idx]\n",
    "\n",
    "X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "y_pairs = np.expand_dims(y_pairs, axis=-1)\n",
    "ds = LabelPairDataset()\n",
    "ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "for x,y in ds:\n",
    "    print(x,y)\n",
    "pair_loader = DataLoader(ds, batch_size=32)\n",
    "# ds_val = LabelPairDataset()\n",
    "# ds_val.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "# val_loader = DataLoader(ds_val, batch_size=32, num_workers=6)\n",
    "# print(len(ds))\n",
    "model = LabelRankingModel(input_dim=generator.n_features_, hidden_dims=3*[generator.n_features_], activations=[torch.nn.Sigmoid(), SortLayer(),torch.nn.Identity()], output_dim=len(generator.classes_))\n",
    "model.num_classes = generator.n_classes_\n",
    "print(len(pair_loader))\n",
    "# device = next(model.parameters()).device\n",
    "# print(f\"Model is on: {device}\")\n",
    "model._fit(pair_loader, val_loader=pair_loader, num_epochs=250, learning_rate=0.001, verbose=True)\n",
    "\n",
    "\n",
    "# # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "# X_test, y_test = generator.generate(n=100)\n",
    "# skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "# conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "# tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.classification import MapieClassifier\n",
    "mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=TopKConformityScore())\n",
    "# create mapie classifier for conformity scores\n",
    "mapie_clf.fit(X_train, y_train)\n",
    "# create \n",
    "oracle_annotator = OracleAnnotator(mapie_clf, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

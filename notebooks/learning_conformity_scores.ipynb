{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class MultinomialSyntheticDataGenerator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, random_state=None):\n",
    "        \"\"\"\n",
    "        A custom estimator for generating synthetic data using multinomial logistic regression,\n",
    "        with the feature distribution inferred from the training data.\n",
    "        \n",
    "        Parameters:\n",
    "        - n_samples (int): Number of synthetic samples to generate.\n",
    "        - random_state (int): Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits a multinomial logistic regression model to the data and estimates the feature distribution.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        - y (ndarray): Target labels of shape (n_samples,).\n",
    "        \n",
    "        Returns:\n",
    "        - self: The fitted instance.\n",
    "        \"\"\"\n",
    "        # Store mean and covariance of features\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.feature_mean_ = np.mean(X, axis=0)\n",
    "        self.feature_cov_ = np.cov(X, rowvar=False)\n",
    "        \n",
    "        # Fit a logistic regression model\n",
    "        self.model_ = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=self.random_state)\n",
    "        self.model_.fit(X, y)\n",
    "        \n",
    "        # Store the number of classes and features\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for the given feature matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - probabilities (ndarray): Predicted probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, \"model_\")\n",
    "        return self.model_.predict_proba(X)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for the given feature matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - probabilities (ndarray): Predicted probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, \"model_\")\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def generate(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, [\"model_\", \"feature_mean_\", \"feature_cov_\"])\n",
    "        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        X_synthetic = np.random.multivariate_normal(self.feature_mean_, self.feature_cov_, n)\n",
    "        \n",
    "        # Compute class probabilities\n",
    "        P_Y_given_X = self.predict_proba(X_synthetic)\n",
    "        \n",
    "        # Sample synthetic labels\n",
    "        y_synthetic = np.array([np.random.choice(self.n_classes_, p=probs) for probs in P_Y_given_X])\n",
    "        \n",
    "        return X_synthetic, y_synthetic\n",
    "\n",
    "\n",
    "    def generate_instances(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, [\"model_\", \"feature_mean_\", \"feature_cov_\"])\n",
    "        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = np.random.multivariate_normal(self.feature_mean_, self.feature_cov_, n)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleAnnotator:\n",
    "    def __init__(self,mapie_clf, generator):\n",
    "        self.mapie_clf = mapie_clf\n",
    "        self.classes_ = mapie_clf.classes_\n",
    "        self.generator = generator\n",
    "\n",
    "    def generate_pairs_in_instance(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        X = self.generator.generate_instances(n)\n",
    "        X = np.repeat(X, repeats=2, axis=0)\n",
    "\n",
    "        y = np.hstack([np.random.choice(self.classes_, size=2, replace=False) for _ in range(n)])\n",
    "\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "        return X_pairs, y_pairs\n",
    "\n",
    "\n",
    "    def generate_pairs_cross_instance(self, n):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"        \n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = self.generator.generate_instances(2*n)\n",
    "        y = np.random.choice(self.classes_, size=2*n, replace=True)\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "\n",
    "        return X_pairs, y_pairs\n",
    "    \n",
    "    def create_pairs_for_classification_data(self, X):\n",
    "        \"\"\"\n",
    "        Generates synthetic data and labels based on the learned model and feature distribution.\n",
    "        \n",
    "        Returns:\n",
    "        - X_synthetic (ndarray): Generated feature matrix of shape (n_samples, n_features).\n",
    "        - y_synthetic (ndarray): Generated labels of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        # Generate synthetic features based on the inferred distribution\n",
    "        \n",
    "        X = self.generator.generate_instances(2*n)\n",
    "        y = np.random.choice(self.classes_, size=2*n, replace=True)\n",
    "        conformities = self.get_conformity(X,y)\n",
    "\n",
    "        X_rs = X.reshape(n,2,self.generator.n_features_)\n",
    "        y_rs = y.reshape(n,2)\n",
    "        conformities_n_rs = - conformities.reshape(n,2)\n",
    "        sort_idx = conformities_n_rs.argsort(axis=1)\n",
    "        X_rs[sort_idx]\n",
    "        y_rs[sort_idx,:]\n",
    "        X_pairs = np.take_along_axis(X_rs, sort_idx[:, :, np.newaxis], axis=1)\n",
    "        y_pairs = np.expand_dims(np.take_along_axis(y_rs, sort_idx, axis=1),axis=-1)\n",
    "\n",
    "        return X_pairs, y_pairs\n",
    "\n",
    "    # we assume y is already label encoded\n",
    "    def get_conformity(self, X, y):\n",
    "        y_pred_proba = self.mapie_clf.estimator.predict_proba(X)\n",
    "        scores = self.mapie_clf.conformity_score_function_.get_conformity_scores(\n",
    "                        y, y_pred_proba, y_enc=y\n",
    "                    )\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.classification import MapieClassifier\n",
    "from mapie.conformity_scores.sets import APSConformityScore, LACConformityScore, NaiveConformityScore, TopKConformityScore\n",
    "from util.ranking_datasets import LabelPairDataset\n",
    "from models.ranking_models import LabelRankingModel\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conduct_oracle_experiment(conformity_score, num_pairs_to_check):\n",
    "    tau_corrs = []\n",
    "    # Generate a small dataset\n",
    "    X_train, y_train = make_classification(\n",
    "        n_samples=10000, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialize and fit the generator\n",
    "    generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "    generator.fit(X_train, y_train)\n",
    "    X_cal, y_cal = generator.generate(n=100)\n",
    "    mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "    # create mapie classifier for conformity scores\n",
    "    mapie_clf.fit(X_cal, y_cal)\n",
    "    # create \n",
    "    oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "\n",
    "    for num_pairs in num_pairs_to_check:\n",
    "        X_pairs, y_pairs = oracle_annotator.generate_pairs_cross_instance(num_pairs)\n",
    "        ds = LabelPairDataset()\n",
    "        ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "        model = LabelRankingModel(input_dim=X_train.shape[1], hidden_dims=[2*X_train.shape[1]], output_dim=len(generator.classes_))\n",
    "        pair_loader = DataLoader(ds, batch_size=64)\n",
    "        model.num_classes = generator.n_classes_\n",
    "        model._fit(pair_loader, val_loader=None, num_epochs=50, learning_rate=0.01)\n",
    "\n",
    "\n",
    "        # generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "        X_test, y_test = generator.generate(n=100)\n",
    "        skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "        print(\"skills:\", skills_from_model)\n",
    "        conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "        print(\"conformities:\", conformity_scores)\n",
    "        tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "        tau_corrs.append(tau_corr)\n",
    "    return tau_corrs, skills_from_model, conformity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills: [[-19.153324 ]\n",
      " [-12.934612 ]\n",
      " [  1.1542577]\n",
      " [ -9.6023   ]\n",
      " [-14.905732 ]\n",
      " [ -9.756613 ]\n",
      " [ -8.632145 ]\n",
      " [ -7.4441285]\n",
      " [-23.539108 ]\n",
      " [-16.806414 ]\n",
      " [-12.278173 ]\n",
      " [-13.211951 ]\n",
      " [ -8.811878 ]\n",
      " [-11.31379  ]\n",
      " [-16.53355  ]\n",
      " [-14.501238 ]\n",
      " [ -6.551092 ]\n",
      " [  3.0348835]\n",
      " [-21.299435 ]\n",
      " [-24.244816 ]\n",
      " [-13.386758 ]\n",
      " [ -8.696529 ]\n",
      " [ -6.036506 ]\n",
      " [-11.899676 ]\n",
      " [-12.796584 ]\n",
      " [-11.178515 ]\n",
      " [-16.47266  ]\n",
      " [ -6.388368 ]\n",
      " [ -8.690697 ]\n",
      " [ -4.6613946]\n",
      " [-23.678616 ]\n",
      " [-25.897171 ]\n",
      " [ -3.523168 ]\n",
      " [-23.96627  ]\n",
      " [-26.252382 ]\n",
      " [-21.588379 ]\n",
      " [-25.944077 ]\n",
      " [-14.0361395]\n",
      " [-13.26723  ]\n",
      " [-25.529593 ]\n",
      " [-17.090778 ]\n",
      " [ -6.014439 ]\n",
      " [-18.668762 ]\n",
      " [ -6.795526 ]\n",
      " [-19.919128 ]\n",
      " [-14.990327 ]\n",
      " [-14.440622 ]\n",
      " [-12.896277 ]\n",
      " [-11.445201 ]\n",
      " [ -6.5049267]\n",
      " [-11.043254 ]\n",
      " [ -4.9488835]\n",
      " [-20.92752  ]\n",
      " [ -3.6201577]\n",
      " [-26.247162 ]\n",
      " [-14.976879 ]\n",
      " [-10.628969 ]\n",
      " [-11.38787  ]\n",
      " [ -7.338004 ]\n",
      " [ -5.021169 ]\n",
      " [-15.750061 ]\n",
      " [-12.2982435]\n",
      " [-15.810864 ]\n",
      " [-11.453443 ]\n",
      " [-20.905535 ]\n",
      " [-19.584656 ]\n",
      " [-16.607632 ]\n",
      " [ -5.620824 ]\n",
      " [ -7.7618423]\n",
      " [ -5.8081427]\n",
      " [ -4.182551 ]\n",
      " [-15.47387  ]\n",
      " [ -2.7584934]\n",
      " [-20.371128 ]\n",
      " [-18.763817 ]\n",
      " [-17.28539  ]\n",
      " [-21.470142 ]\n",
      " [-15.07141  ]\n",
      " [-10.128532 ]\n",
      " [ -7.1842437]\n",
      " [-15.331906 ]\n",
      " [-14.390556 ]\n",
      " [-19.38536  ]\n",
      " [-22.597225 ]\n",
      " [-23.501705 ]\n",
      " [-22.767082 ]\n",
      " [-24.124454 ]\n",
      " [-11.960629 ]\n",
      " [-13.297207 ]\n",
      " [-20.54132  ]\n",
      " [-14.141564 ]\n",
      " [-21.414562 ]\n",
      " [-19.924416 ]\n",
      " [-17.032705 ]\n",
      " [-11.090026 ]\n",
      " [ -8.750078 ]\n",
      " [ -9.95493  ]\n",
      " [-17.828905 ]\n",
      " [-13.4450445]\n",
      " [ -7.726244 ]]\n",
      "conformities: [[1.45749298e-02]\n",
      " [1.13548943e-01]\n",
      " [9.64684765e-01]\n",
      " [3.30246086e-01]\n",
      " [6.29523885e-02]\n",
      " [3.09435787e-01]\n",
      " [4.46173194e-01]\n",
      " [5.71026970e-01]\n",
      " [4.38925849e-04]\n",
      " [3.17705192e-02]\n",
      " [1.90484752e-01]\n",
      " [1.64872790e-01]\n",
      " [3.77646833e-01]\n",
      " [2.27583600e-01]\n",
      " [4.17786099e-02]\n",
      " [9.20816006e-02]\n",
      " [5.56683930e-01]\n",
      " [9.85272435e-01]\n",
      " [4.56740825e-03]\n",
      " [2.40589622e-04]\n",
      " [1.02391968e-01]\n",
      " [4.59969133e-01]\n",
      " [6.14121046e-01]\n",
      " [2.03687415e-01]\n",
      " [1.38797028e-01]\n",
      " [2.43896886e-01]\n",
      " [3.27754650e-02]\n",
      " [5.65657448e-01]\n",
      " [4.80236175e-01]\n",
      " [6.94387867e-01]\n",
      " [8.76616215e-04]\n",
      " [1.71407590e-06]\n",
      " [8.31404471e-01]\n",
      " [5.26059516e-04]\n",
      " [8.63315471e-06]\n",
      " [3.68392636e-03]\n",
      " [9.54540430e-06]\n",
      " [1.13681886e-01]\n",
      " [1.53500763e-01]\n",
      " [7.04458905e-05]\n",
      " [3.80316797e-02]\n",
      " [5.94645096e-01]\n",
      " [1.58822191e-02]\n",
      " [6.26907857e-01]\n",
      " [9.96096643e-03]\n",
      " [6.41255319e-02]\n",
      " [1.06100541e-01]\n",
      " [1.40106490e-01]\n",
      " [1.65249543e-01]\n",
      " [5.58368452e-01]\n",
      " [2.32329008e-01]\n",
      " [6.99399941e-01]\n",
      " [5.08497679e-03]\n",
      " [8.24115187e-01]\n",
      " [1.83589984e-07]\n",
      " [5.05515087e-02]\n",
      " [2.65172498e-01]\n",
      " [2.44794186e-01]\n",
      " [4.98118621e-01]\n",
      " [6.69073138e-01]\n",
      " [5.90042486e-02]\n",
      " [1.30470018e-01]\n",
      " [4.36329757e-02]\n",
      " [2.48097460e-01]\n",
      " [4.31855055e-03]\n",
      " [8.86181623e-03]\n",
      " [3.88627065e-02]\n",
      " [6.49344471e-01]\n",
      " [4.95010339e-01]\n",
      " [6.49073235e-01]\n",
      " [7.95578650e-01]\n",
      " [5.44440772e-02]\n",
      " [8.64805709e-01]\n",
      " [2.61700461e-03]\n",
      " [1.59440169e-02]\n",
      " [2.13912491e-02]\n",
      " [4.30222632e-03]\n",
      " [8.38414582e-02]\n",
      " [2.97604890e-01]\n",
      " [5.28082244e-01]\n",
      " [5.44884439e-02]\n",
      " [6.37634045e-02]\n",
      " [1.06129353e-02]\n",
      " [3.92413140e-04]\n",
      " [6.05858894e-04]\n",
      " [1.23251648e-03]\n",
      " [1.75530835e-05]\n",
      " [1.77098145e-01]\n",
      " [1.35954376e-01]\n",
      " [2.20225286e-03]\n",
      " [1.20082773e-01]\n",
      " [3.79282701e-03]\n",
      " [8.85027890e-03]\n",
      " [3.89890287e-02]\n",
      " [2.55167475e-01]\n",
      " [4.39706789e-01]\n",
      " [3.63323080e-01]\n",
      " [2.60453823e-02]\n",
      " [1.06933049e-01]\n",
      " [5.10789562e-01]]\n",
      "skills: [[-1.9261557e+01]\n",
      " [ 4.7274351e-01]\n",
      " [-2.8379971e+01]\n",
      " [-9.5350361e+00]\n",
      " [-2.1301210e+01]\n",
      " [-1.9670994e+01]\n",
      " [-2.8227554e+01]\n",
      " [-2.1210632e+01]\n",
      " [-3.0231617e+01]\n",
      " [-2.5240408e+01]\n",
      " [-2.0990074e+00]\n",
      " [-1.0938473e+01]\n",
      " [ 1.2357302e+00]\n",
      " [-6.0957985e+00]\n",
      " [ 2.1492004e-02]\n",
      " [-7.3280787e+00]\n",
      " [-1.6950680e+01]\n",
      " [-3.0180172e+01]\n",
      " [-9.3021021e+00]\n",
      " [-3.8076680e+00]\n",
      " [-9.9488916e+00]\n",
      " [-9.4871454e+00]\n",
      " [-1.7288437e+01]\n",
      " [-2.1548910e+01]\n",
      " [-1.8790125e+01]\n",
      " [-2.0586903e+01]\n",
      " [-2.5169975e+01]\n",
      " [-8.8864632e+00]\n",
      " [-6.2809191e+00]\n",
      " [-1.2243903e+01]\n",
      " [-1.9721966e+00]\n",
      " [-1.3189540e+01]\n",
      " [-1.4157565e+01]\n",
      " [-7.9421291e+00]\n",
      " [-8.9178715e+00]\n",
      " [-9.2531223e+00]\n",
      " [-6.7215028e+00]\n",
      " [-1.2864175e+01]\n",
      " [-2.7986279e+01]\n",
      " [-1.3532162e+01]\n",
      " [-5.4120321e+00]\n",
      " [-1.9498865e+01]\n",
      " [-3.2135503e+00]\n",
      " [-1.8135561e+01]\n",
      " [-2.5774120e+01]\n",
      " [-1.6498280e+01]\n",
      " [-3.7817557e+00]\n",
      " [-5.7755837e+00]\n",
      " [-9.0147400e+00]\n",
      " [-2.6387102e+01]\n",
      " [-7.8141546e+00]\n",
      " [-2.5856262e+01]\n",
      " [-9.1332264e+00]\n",
      " [-7.6319675e+00]\n",
      " [-1.4430029e+01]\n",
      " [-2.6704861e+01]\n",
      " [-1.6041176e+01]\n",
      " [-1.7082626e+01]\n",
      " [-1.0870633e+01]\n",
      " [-1.1584951e+01]\n",
      " [-7.8043346e+00]\n",
      " [-1.0473347e+01]\n",
      " [-2.1064692e+01]\n",
      " [-4.2490883e+00]\n",
      " [-1.3008472e+01]\n",
      " [-2.5115166e+01]\n",
      " [-1.6890207e+01]\n",
      " [-2.1870600e+01]\n",
      " [-3.4661055e+00]\n",
      " [-2.2535881e+01]\n",
      " [-2.1114529e+01]\n",
      " [-1.1493895e+01]\n",
      " [-1.8310324e+01]\n",
      " [-1.5082620e+01]\n",
      " [-1.5831312e+01]\n",
      " [ 3.0595636e+00]\n",
      " [-1.5576308e+01]\n",
      " [-2.0185160e+01]\n",
      " [-3.9418137e+00]\n",
      " [-6.6067638e+00]\n",
      " [-1.6561148e+01]\n",
      " [-1.8074261e+01]\n",
      " [-1.8066828e+01]\n",
      " [-5.2147384e+00]\n",
      " [-1.4535104e+01]\n",
      " [-1.1467493e+01]\n",
      " [-1.5483269e+01]\n",
      " [-1.9462017e+01]\n",
      " [-2.8903935e+00]\n",
      " [-1.5726168e+01]\n",
      " [-3.1211877e+00]\n",
      " [-8.5831566e+00]\n",
      " [-2.8640789e+01]\n",
      " [-1.8652542e+01]\n",
      " [-1.8095800e+01]\n",
      " [-1.4154285e+01]\n",
      " [-1.6718983e+01]\n",
      " [-6.3304090e+00]\n",
      " [-9.3861694e+00]\n",
      " [-1.7917753e+01]]\n",
      "conformities: [[1.81202945e-02]\n",
      " [8.86018223e-01]\n",
      " [2.65550420e-04]\n",
      " [2.15844354e-01]\n",
      " [6.77711541e-03]\n",
      " [1.35110967e-02]\n",
      " [4.74306854e-05]\n",
      " [8.47132566e-03]\n",
      " [2.12629691e-06]\n",
      " [2.30098652e-04]\n",
      " [7.52057901e-01]\n",
      " [2.34489751e-01]\n",
      " [8.95024096e-01]\n",
      " [5.01263526e-01]\n",
      " [8.34585114e-01]\n",
      " [3.73446702e-01]\n",
      " [3.90021890e-02]\n",
      " [9.65211788e-09]\n",
      " [2.74734042e-01]\n",
      " [6.76945545e-01]\n",
      " [2.63244603e-01]\n",
      " [3.41024821e-01]\n",
      " [3.60626464e-02]\n",
      " [6.02942544e-03]\n",
      " [1.85232057e-02]\n",
      " [5.78724694e-03]\n",
      " [1.53025873e-03]\n",
      " [3.14204834e-01]\n",
      " [4.52024372e-01]\n",
      " [1.71305768e-01]\n",
      " [7.29602929e-01]\n",
      " [1.24454733e-01]\n",
      " [9.48479478e-02]\n",
      " [4.12112920e-01]\n",
      " [2.78984602e-01]\n",
      " [2.72535490e-01]\n",
      " [4.07493241e-01]\n",
      " [1.51576674e-01]\n",
      " [3.85420614e-04]\n",
      " [5.55784222e-02]\n",
      " [5.17645382e-01]\n",
      " [1.26249079e-02]\n",
      " [7.08113158e-01]\n",
      " [2.55440819e-02]\n",
      " [4.36023728e-04]\n",
      " [3.32876885e-02]\n",
      " [6.85806799e-01]\n",
      " [5.16125966e-01]\n",
      " [3.58885797e-01]\n",
      " [3.97806536e-04]\n",
      " [3.84967676e-01]\n",
      " [6.04514829e-04]\n",
      " [2.50867050e-01]\n",
      " [4.08506234e-01]\n",
      " [7.16963593e-02]\n",
      " [6.17901108e-04]\n",
      " [4.12285722e-02]\n",
      " [3.57342719e-02]\n",
      " [2.32526502e-01]\n",
      " [1.70755345e-01]\n",
      " [3.74986629e-01]\n",
      " [1.89372267e-01]\n",
      " [6.82207149e-03]\n",
      " [6.13698582e-01]\n",
      " [1.48802505e-01]\n",
      " [1.48560263e-03]\n",
      " [3.92163871e-02]\n",
      " [6.03260219e-03]\n",
      " [6.86394893e-01]\n",
      " [4.84266075e-03]\n",
      " [5.36028163e-03]\n",
      " [1.75442351e-01]\n",
      " [1.28854591e-02]\n",
      " [6.65794155e-02]\n",
      " [3.98482466e-02]\n",
      " [9.44828396e-01]\n",
      " [4.32534696e-02]\n",
      " [1.02921140e-02]\n",
      " [6.76549463e-01]\n",
      " [4.22073341e-01]\n",
      " [3.73274905e-02]\n",
      " [2.91647237e-02]\n",
      " [1.65339598e-02]\n",
      " [5.73852735e-01]\n",
      " [9.38247935e-02]\n",
      " [1.61737753e-01]\n",
      " [4.90424994e-02]\n",
      " [1.46364315e-02]\n",
      " [7.92542379e-01]\n",
      " [5.12556693e-02]\n",
      " [6.95300540e-01]\n",
      " [2.85479822e-01]\n",
      " [1.65588041e-04]\n",
      " [2.21263690e-02]\n",
      " [2.32505061e-02]\n",
      " [1.02491805e-01]\n",
      " [4.18260660e-02]\n",
      " [5.09627986e-01]\n",
      " [2.33295525e-01]\n",
      " [2.94518972e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills: [[-6.7000785]\n",
      " [-7.2294917]\n",
      " [-8.191509 ]\n",
      " [-6.9089894]\n",
      " [-8.060402 ]\n",
      " [-8.2044735]\n",
      " [-6.8360224]\n",
      " [-7.2826614]\n",
      " [-7.5123863]\n",
      " [-7.7758226]\n",
      " [-4.896255 ]\n",
      " [-7.36979  ]\n",
      " [-7.8222904]\n",
      " [-7.409658 ]\n",
      " [-8.202436 ]\n",
      " [-7.7782383]\n",
      " [-7.807068 ]\n",
      " [-7.8750386]\n",
      " [-6.5204988]\n",
      " [-8.098837 ]\n",
      " [-7.615181 ]\n",
      " [-7.4924273]\n",
      " [-7.483013 ]\n",
      " [-7.797166 ]\n",
      " [-8.682217 ]\n",
      " [-8.334339 ]\n",
      " [-8.607777 ]\n",
      " [-6.835816 ]\n",
      " [-8.219767 ]\n",
      " [-7.4229445]\n",
      " [-8.425169 ]\n",
      " [-8.118172 ]\n",
      " [-7.6660438]\n",
      " [-7.2320995]\n",
      " [-7.7420454]\n",
      " [-7.5234966]\n",
      " [-8.378881 ]\n",
      " [-6.6769037]\n",
      " [-8.217753 ]\n",
      " [-7.5230603]\n",
      " [-7.0801454]\n",
      " [-7.511279 ]\n",
      " [-6.7591295]\n",
      " [-6.9578786]\n",
      " [-7.561361 ]\n",
      " [-7.8949876]\n",
      " [-8.595985 ]\n",
      " [-6.549483 ]\n",
      " [-7.4157853]\n",
      " [-7.6749344]\n",
      " [-7.438617 ]\n",
      " [-7.264129 ]\n",
      " [-8.505885 ]\n",
      " [-7.478392 ]\n",
      " [-7.96281  ]\n",
      " [-7.8562174]\n",
      " [-7.695559 ]\n",
      " [-7.608661 ]\n",
      " [-7.0810647]\n",
      " [-8.1153755]\n",
      " [-8.052863 ]\n",
      " [-7.5721474]\n",
      " [-7.539004 ]\n",
      " [-7.7651258]\n",
      " [-7.6441636]\n",
      " [-7.703836 ]\n",
      " [-6.186619 ]\n",
      " [-7.8711147]\n",
      " [-6.923726 ]\n",
      " [-8.039503 ]\n",
      " [-7.269987 ]\n",
      " [-7.8124824]\n",
      " [-7.117686 ]\n",
      " [-7.4298816]\n",
      " [-6.8033223]\n",
      " [-7.5506253]\n",
      " [-7.0172644]\n",
      " [-6.839012 ]\n",
      " [-3.8916276]\n",
      " [-7.463123 ]\n",
      " [-7.723472 ]\n",
      " [-7.9250965]\n",
      " [-7.306717 ]\n",
      " [-7.9494853]\n",
      " [-8.360554 ]\n",
      " [-7.607824 ]\n",
      " [-8.163324 ]\n",
      " [-7.9939823]\n",
      " [-5.626522 ]\n",
      " [-7.0983467]\n",
      " [-7.294857 ]\n",
      " [-7.5996056]\n",
      " [-7.956046 ]\n",
      " [-7.3912587]\n",
      " [-7.22849  ]\n",
      " [-8.449315 ]\n",
      " [-7.500632 ]\n",
      " [-7.008468 ]\n",
      " [-8.542918 ]\n",
      " [-6.955003 ]]\n",
      "conformities: [[0.67005647]\n",
      " [0.80970155]\n",
      " [0.11984445]\n",
      " [0.61008825]\n",
      " [0.85499861]\n",
      " [0.84231388]\n",
      " [0.70810519]\n",
      " [0.40869582]\n",
      " [0.34657291]\n",
      " [0.33228848]\n",
      " [0.97309599]\n",
      " [0.15181686]\n",
      " [0.33975725]\n",
      " [0.59820502]\n",
      " [0.59611304]\n",
      " [0.38418445]\n",
      " [0.46540279]\n",
      " [0.28959521]\n",
      " [0.79791506]\n",
      " [0.27315213]\n",
      " [0.46324489]\n",
      " [0.48309479]\n",
      " [0.23910198]\n",
      " [0.34778308]\n",
      " [0.52287407]\n",
      " [0.2802538 ]\n",
      " [0.50676521]\n",
      " [0.5998336 ]\n",
      " [0.25065042]\n",
      " [0.80103316]\n",
      " [0.20250279]\n",
      " [0.24058402]\n",
      " [0.49685188]\n",
      " [0.05053792]\n",
      " [0.62317762]\n",
      " [0.98903129]\n",
      " [0.68365543]\n",
      " [0.4515949 ]\n",
      " [0.26876966]\n",
      " [0.64516506]\n",
      " [0.88521389]\n",
      " [0.23130868]\n",
      " [0.30233221]\n",
      " [0.55980173]\n",
      " [0.20205703]\n",
      " [0.79009189]\n",
      " [0.33535506]\n",
      " [0.24233459]\n",
      " [0.51307752]\n",
      " [0.41872614]\n",
      " [0.90188766]\n",
      " [0.41741334]\n",
      " [0.42246228]\n",
      " [0.58511166]\n",
      " [0.597042  ]\n",
      " [0.6918895 ]\n",
      " [0.51896606]\n",
      " [0.51594811]\n",
      " [0.16474868]\n",
      " [0.32426764]\n",
      " [0.56228717]\n",
      " [0.71961788]\n",
      " [0.83208895]\n",
      " [0.62897336]\n",
      " [0.40061621]\n",
      " [0.60302754]\n",
      " [0.41359138]\n",
      " [0.0956785 ]\n",
      " [0.00465613]\n",
      " [0.41153887]\n",
      " [0.39435073]\n",
      " [0.38817263]\n",
      " [0.25460847]\n",
      " [0.93609914]\n",
      " [0.28381929]\n",
      " [0.00367689]\n",
      " [0.71384952]\n",
      " [0.9262547 ]\n",
      " [0.96375561]\n",
      " [0.58406545]\n",
      " [0.27372201]\n",
      " [0.0498742 ]\n",
      " [0.20760043]\n",
      " [0.45795829]\n",
      " [0.08768272]\n",
      " [0.43102938]\n",
      " [0.15506656]\n",
      " [0.13325832]\n",
      " [0.97313283]\n",
      " [0.8324555 ]\n",
      " [0.693141  ]\n",
      " [0.77097697]\n",
      " [0.0711465 ]\n",
      " [0.21703368]\n",
      " [0.88456104]\n",
      " [0.08602275]\n",
      " [0.75037258]\n",
      " [0.64455707]\n",
      " [0.88418085]\n",
      " [0.58588184]]\n",
      "skills: [[-7.934533 ]\n",
      " [-7.739052 ]\n",
      " [-7.4786305]\n",
      " [-8.630823 ]\n",
      " [-7.6571856]\n",
      " [-7.725923 ]\n",
      " [-8.001307 ]\n",
      " [-7.9045353]\n",
      " [-7.6742954]\n",
      " [-7.917135 ]\n",
      " [-7.8465137]\n",
      " [-7.829919 ]\n",
      " [-7.665349 ]\n",
      " [-8.43434  ]\n",
      " [-8.044794 ]\n",
      " [-8.071872 ]\n",
      " [-8.242833 ]\n",
      " [-7.9373236]\n",
      " [-7.4254727]\n",
      " [-7.598797 ]\n",
      " [-3.9974062]\n",
      " [-7.935013 ]\n",
      " [-2.9990056]\n",
      " [-7.6127396]\n",
      " [-5.9708138]\n",
      " [-7.7453265]\n",
      " [-8.021839 ]\n",
      " [-8.115306 ]\n",
      " [-8.02916  ]\n",
      " [-8.156879 ]\n",
      " [-8.090772 ]\n",
      " [-6.896379 ]\n",
      " [-4.576458 ]\n",
      " [-8.0456085]\n",
      " [-7.2022686]\n",
      " [-8.234831 ]\n",
      " [-7.362507 ]\n",
      " [-7.6875   ]\n",
      " [-7.029381 ]\n",
      " [-7.7203345]\n",
      " [-8.017387 ]\n",
      " [-7.433853 ]\n",
      " [-8.159239 ]\n",
      " [-7.1711965]\n",
      " [-7.756179 ]\n",
      " [-8.281825 ]\n",
      " [-6.0766354]\n",
      " [-8.129212 ]\n",
      " [-7.8430986]\n",
      " [-8.038002 ]\n",
      " [-8.490758 ]\n",
      " [-5.9166746]\n",
      " [-6.6509523]\n",
      " [-8.129909 ]\n",
      " [-8.407744 ]\n",
      " [-7.6712003]\n",
      " [-7.7807417]\n",
      " [-5.0319676]\n",
      " [-8.059345 ]\n",
      " [-8.303045 ]\n",
      " [-8.123639 ]\n",
      " [-8.699809 ]\n",
      " [-7.671836 ]\n",
      " [-1.2945704]\n",
      " [-7.5480876]\n",
      " [-7.0437555]\n",
      " [-7.11889  ]\n",
      " [-8.30591  ]\n",
      " [-7.757656 ]\n",
      " [-8.271212 ]\n",
      " [-6.687223 ]\n",
      " [-7.3405743]\n",
      " [-7.7877846]\n",
      " [-7.9838037]\n",
      " [-8.08711  ]\n",
      " [-8.286988 ]\n",
      " [-7.244204 ]\n",
      " [-8.689113 ]\n",
      " [-7.5750427]\n",
      " [-7.776238 ]\n",
      " [-8.111622 ]\n",
      " [-7.3893776]\n",
      " [-7.798096 ]\n",
      " [-8.199844 ]\n",
      " [-8.110503 ]\n",
      " [-7.4618435]\n",
      " [-8.084882 ]\n",
      " [-8.201357 ]\n",
      " [-7.7635036]\n",
      " [-7.996583 ]\n",
      " [-8.087311 ]\n",
      " [-4.4823847]\n",
      " [-7.8124604]\n",
      " [-6.3004174]\n",
      " [-8.073378 ]\n",
      " [-8.102943 ]\n",
      " [-7.999089 ]\n",
      " [-8.12587  ]\n",
      " [-5.529533 ]\n",
      " [-7.729224 ]]\n",
      "conformities: [[0.41775598]\n",
      " [0.17887126]\n",
      " [0.29693633]\n",
      " [0.77558032]\n",
      " [0.65486724]\n",
      " [0.58936943]\n",
      " [0.43972011]\n",
      " [0.67008915]\n",
      " [0.26197936]\n",
      " [0.3684434 ]\n",
      " [0.8971923 ]\n",
      " [0.61016195]\n",
      " [0.36727847]\n",
      " [0.79989941]\n",
      " [0.86258434]\n",
      " [0.7839025 ]\n",
      " [0.21209857]\n",
      " [0.45856021]\n",
      " [0.44125971]\n",
      " [0.49356574]\n",
      " [0.98910721]\n",
      " [0.50600355]\n",
      " [0.9909334 ]\n",
      " [0.38797758]\n",
      " [0.75070117]\n",
      " [0.51223856]\n",
      " [0.59682209]\n",
      " [0.01927048]\n",
      " [0.88787051]\n",
      " [0.69891895]\n",
      " [0.62465477]\n",
      " [0.79100791]\n",
      " [0.93910529]\n",
      " [0.89985775]\n",
      " [0.09077002]\n",
      " [0.43435671]\n",
      " [0.51002655]\n",
      " [0.77799554]\n",
      " [0.03623379]\n",
      " [0.22290539]\n",
      " [0.50949786]\n",
      " [0.24394509]\n",
      " [0.6946866 ]\n",
      " [0.76471817]\n",
      " [0.13301928]\n",
      " [0.55049072]\n",
      " [0.89493426]\n",
      " [0.35513476]\n",
      " [0.04494421]\n",
      " [0.59473609]\n",
      " [0.45689071]\n",
      " [0.92925317]\n",
      " [0.56347599]\n",
      " [0.25991356]\n",
      " [0.57046079]\n",
      " [0.36801983]\n",
      " [0.51464602]\n",
      " [0.83976959]\n",
      " [0.15239122]\n",
      " [0.10992789]\n",
      " [0.85589297]\n",
      " [0.59304055]\n",
      " [0.86843935]\n",
      " [0.99695484]\n",
      " [0.35642794]\n",
      " [0.67216871]\n",
      " [0.91383474]\n",
      " [0.87403405]\n",
      " [0.51529666]\n",
      " [0.12900021]\n",
      " [0.92430491]\n",
      " [0.60278172]\n",
      " [0.15741368]\n",
      " [0.64759636]\n",
      " [0.20717911]\n",
      " [0.85429264]\n",
      " [0.35463786]\n",
      " [0.56329184]\n",
      " [0.21148939]\n",
      " [0.39088805]\n",
      " [0.46732405]\n",
      " [0.26120543]\n",
      " [0.74428772]\n",
      " [0.65614826]\n",
      " [0.43716259]\n",
      " [0.32435956]\n",
      " [0.70402402]\n",
      " [0.30769819]\n",
      " [0.42776867]\n",
      " [0.35091716]\n",
      " [0.16491779]\n",
      " [0.97393304]\n",
      " [0.53435338]\n",
      " [0.695126  ]\n",
      " [0.26317763]\n",
      " [0.32090319]\n",
      " [0.45493009]\n",
      " [0.59514094]\n",
      " [0.9407776 ]\n",
      " [0.26298879]]\n"
     ]
    }
   ],
   "source": [
    "num_pairs_to_check = np.linspace(2**14,2**15,2).astype(int)\n",
    "tau_corrs_LAC, skills_LAC, conformities_LAC = conduct_oracle_experiment(LACConformityScore(), num_pairs_to_check)\n",
    "tau_corrs_APS, skills_APC, conformities_APC = conduct_oracle_experiment(APSConformityScore(), num_pairs_to_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'APS'}, xlabel='No. Pairs', ylabel='Kendalls $\\\\tau$'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from turtle import title\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5,rc={'text.usetex' : True})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rc('font', **{'family': 'serif'})\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 3)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].set_title(\"LAC\")\n",
    "axes[0].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "axes[0].set_xlabel(r\"No. Pairs\")\n",
    "sns.lineplot(x=num_pairs_to_check, y=tau_corrs_LAC, ax = axes[0])\n",
    "axes[1].set_title(\"APS\")\n",
    "axes[1].set_ylabel(r\"Kendalls $\\tau$\")\n",
    "axes[1].set_xlabel(r\"No. Pairs\")\n",
    "sns.lineplot(x=num_pairs_to_check, y=tau_corrs_APS, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills: [[-14.133024  ]\n",
      " [-19.606674  ]\n",
      " [-10.656549  ]\n",
      " [-28.796978  ]\n",
      " [-18.99741   ]\n",
      " [-15.061966  ]\n",
      " [-21.086607  ]\n",
      " [-21.921268  ]\n",
      " [ -8.417094  ]\n",
      " [ -0.33185673]\n",
      " [-22.451635  ]\n",
      " [ -7.8956347 ]\n",
      " [-15.791954  ]\n",
      " [-15.229649  ]\n",
      " [-19.396345  ]\n",
      " [-26.281425  ]\n",
      " [ -4.5637436 ]\n",
      " [-17.165798  ]\n",
      " [-15.96188   ]\n",
      " [-16.141487  ]\n",
      " [-25.067814  ]\n",
      " [ -9.236451  ]\n",
      " [ -9.4575615 ]\n",
      " [-11.332676  ]\n",
      " [-10.842269  ]\n",
      " [-20.978548  ]\n",
      " [-23.532444  ]\n",
      " [ -5.161045  ]\n",
      " [-13.619881  ]\n",
      " [-25.597403  ]\n",
      " [-14.225886  ]\n",
      " [-31.327055  ]\n",
      " [  2.9475336 ]\n",
      " [-25.9706    ]\n",
      " [-12.266063  ]\n",
      " [-15.40323   ]\n",
      " [ -4.1816044 ]\n",
      " [-11.91349   ]\n",
      " [-17.971714  ]\n",
      " [-20.520954  ]\n",
      " [-11.275637  ]\n",
      " [-23.597319  ]\n",
      " [  8.907391  ]\n",
      " [-21.499056  ]\n",
      " [ -9.278126  ]\n",
      " [  2.7754946 ]\n",
      " [ -7.45321   ]\n",
      " [-17.056564  ]\n",
      " [-25.367226  ]\n",
      " [-13.708603  ]\n",
      " [-13.917294  ]\n",
      " [-28.956379  ]\n",
      " [-11.1911335 ]\n",
      " [-25.557121  ]\n",
      " [ -0.45508432]\n",
      " [-24.09023   ]\n",
      " [-18.617332  ]\n",
      " [-15.007083  ]\n",
      " [-25.055843  ]\n",
      " [-31.051191  ]\n",
      " [-22.684422  ]\n",
      " [-10.174865  ]\n",
      " [-13.080367  ]\n",
      " [-18.946835  ]\n",
      " [-18.838985  ]\n",
      " [ -2.0797176 ]\n",
      " [-28.838217  ]\n",
      " [-23.044651  ]\n",
      " [-20.588873  ]\n",
      " [-14.576997  ]\n",
      " [-10.645278  ]\n",
      " [ -7.69644   ]\n",
      " [-19.939394  ]\n",
      " [ -8.989283  ]\n",
      " [-14.745051  ]\n",
      " [-22.513615  ]\n",
      " [ -8.299699  ]\n",
      " [-11.759551  ]\n",
      " [-13.535665  ]\n",
      " [-10.542707  ]\n",
      " [-13.988036  ]\n",
      " [-13.021298  ]\n",
      " [ -6.4671144 ]\n",
      " [-23.60379   ]\n",
      " [ -2.4782007 ]\n",
      " [-10.080919  ]\n",
      " [-14.688011  ]\n",
      " [-15.102384  ]\n",
      " [ -8.333611  ]\n",
      " [-27.81054   ]\n",
      " [-14.066819  ]\n",
      " [-13.345787  ]\n",
      " [-17.81697   ]\n",
      " [ -6.1294756 ]\n",
      " [-16.441385  ]\n",
      " [-16.384747  ]\n",
      " [-23.943298  ]\n",
      " [-17.813026  ]\n",
      " [-21.901478  ]\n",
      " [ -9.388885  ]]\n",
      "conformities: [[1.27823725e-01]\n",
      " [8.12462658e-03]\n",
      " [2.78234584e-01]\n",
      " [5.40565498e-04]\n",
      " [2.20153500e-02]\n",
      " [8.18733809e-02]\n",
      " [1.09916148e-02]\n",
      " [7.43191029e-03]\n",
      " [4.34076721e-01]\n",
      " [9.34238064e-01]\n",
      " [4.96393965e-03]\n",
      " [5.09862998e-01]\n",
      " [3.35643695e-02]\n",
      " [7.47990817e-02]\n",
      " [1.45408306e-02]\n",
      " [7.07671781e-04]\n",
      " [7.37392836e-01]\n",
      " [4.63870589e-02]\n",
      " [7.07263085e-02]\n",
      " [5.65823045e-02]\n",
      " [1.22212153e-03]\n",
      " [3.18319839e-01]\n",
      " [4.46597802e-01]\n",
      " [2.30256971e-01]\n",
      " [2.95439456e-01]\n",
      " [7.71957612e-03]\n",
      " [3.20656504e-03]\n",
      " [6.80185518e-01]\n",
      " [1.08962975e-01]\n",
      " [4.60107375e-04]\n",
      " [1.15332467e-01]\n",
      " [3.57166297e-10]\n",
      " [9.63270645e-01]\n",
      " [4.75339376e-04]\n",
      " [2.08832921e-01]\n",
      " [8.05039423e-02]\n",
      " [7.17380282e-01]\n",
      " [2.13543040e-01]\n",
      " [3.73170327e-02]\n",
      " [8.26656018e-03]\n",
      " [2.21118236e-01]\n",
      " [2.33294138e-03]\n",
      " [9.98145450e-01]\n",
      " [7.88219372e-03]\n",
      " [3.91181411e-01]\n",
      " [9.76328855e-01]\n",
      " [5.04967404e-01]\n",
      " [4.32076196e-02]\n",
      " [7.52351096e-03]\n",
      " [1.04773414e-01]\n",
      " [1.33502445e-01]\n",
      " [1.08158213e-05]\n",
      " [2.24512610e-01]\n",
      " [5.34841718e-04]\n",
      " [9.03255763e-01]\n",
      " [2.38518508e-03]\n",
      " [2.94439966e-02]\n",
      " [8.33095009e-02]\n",
      " [1.12414092e-03]\n",
      " [6.23108844e-07]\n",
      " [9.44104023e-03]\n",
      " [3.43435546e-01]\n",
      " [1.31920120e-01]\n",
      " [2.04484275e-02]\n",
      " [1.89546348e-02]\n",
      " [8.65582300e-01]\n",
      " [8.14851626e-05]\n",
      " [2.22582314e-03]\n",
      " [9.08175463e-03]\n",
      " [9.24201244e-02]\n",
      " [2.87734587e-01]\n",
      " [4.57553005e-01]\n",
      " [1.54231223e-02]\n",
      " [3.88060561e-01]\n",
      " [1.05634644e-01]\n",
      " [5.10056627e-03]\n",
      " [4.75365972e-01]\n",
      " [1.39573232e-01]\n",
      " [1.66891617e-01]\n",
      " [2.49768972e-01]\n",
      " [1.33397517e-01]\n",
      " [1.55926361e-01]\n",
      " [5.76688335e-01]\n",
      " [3.02656951e-03]\n",
      " [8.58652276e-01]\n",
      " [2.76850051e-01]\n",
      " [9.92481217e-02]\n",
      " [9.33639710e-02]\n",
      " [4.43156791e-01]\n",
      " [1.14267511e-03]\n",
      " [1.30147214e-01]\n",
      " [1.63794608e-01]\n",
      " [6.12236654e-02]\n",
      " [6.10804702e-01]\n",
      " [5.75370521e-02]\n",
      " [5.91447453e-02]\n",
      " [3.73684452e-03]\n",
      " [3.18114672e-02]\n",
      " [6.80492997e-03]\n",
      " [3.96843689e-01]]\n"
     ]
    }
   ],
   "source": [
    "a = conduct_oracle_experiment(LACConformityScore(), [2**15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample:  0.7682051282051283\n",
      "out-of-sample:  0.5111111111111111\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X_seed, y_seed = make_classification(n_samples=1000, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42)\n",
    "conformity_score = APSConformityScore()\n",
    "generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "generator.fit(X_seed, y_seed)\n",
    "X_cal, y_cal = generator.generate(n=100)\n",
    "mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "# create mapie classifier for conformity scores\n",
    "mapie_clf.fit(X_cal, y_cal)\n",
    "# create \n",
    "oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "\n",
    "# generate all possible pairs for a couple of instances\n",
    "n_instances = 100\n",
    "n_classes = len(generator.classes_)\n",
    "n_obs = n_instances * n_classes\n",
    "X_train = generator.generate_instances(n_instances).repeat(n_classes, axis=0)\n",
    "y_train = np.tile(generator.classes_, n_instances)\n",
    "conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "X_sorted = X_train[sort_idx]\n",
    "y_sorted = y_train[sort_idx]\n",
    "conformities_sorted = conformities[sort_idx]\n",
    "\n",
    "X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "y_pairs = np.expand_dims(y_pairs, axis=-1)\n",
    "\n",
    "\n",
    "ds = LabelPairDataset()\n",
    "ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "model = LabelRankingModel(input_dim=X_train.shape[1], hidden_dims=2*[2*X_train.shape[1]], activations=[torch.nn.Sigmoid(), torch.nn.ReLU()],output_dim=len(generator.classes_))\n",
    "pair_loader = DataLoader(ds, batch_size=64)\n",
    "model.num_classes = generator.n_classes_\n",
    "model._fit(pair_loader, val_loader=None, num_epochs=2500, learning_rate=0.01)\n",
    "\n",
    "\n",
    "# generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "X_test, y_test = X_train, y_train\n",
    "conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "print(\"in-sample: \", tau_corr)\n",
    "X_test, y_test = generator.generate(n=10)\n",
    "conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "print(\"out-of-sample: \", tau_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m pair_loader \u001b[38;5;241m=\u001b[39m DataLoader(ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\u001b[39;00m\n\u001b[1;32m     39\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m X_train, y_train\n",
      "File \u001b[0;32m~/Documents/Research/torch_plnet/models/ranking_models.py:84\u001b[0m, in \u001b[0;36mLabelRankingModel._fit\u001b[0;34m(self, train_loader, val_loader, learning_rate, num_epochs, random_state, patience, delta)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     83\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 84\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     outputs_for_labels \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mgather(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     86\u001b[0m     loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m         torch\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m     88\u001b[0m             torch\u001b[38;5;241m.\u001b[39mexp(outputs_for_labels[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;241m-\u001b[39m outputs_for_labels[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     92\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Research/torch_plnet/models/ranking_models.py:52\u001b[0m, in \u001b[0;36mLabelRankingModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_seed, y_seed = make_classification(n_samples=1000, n_features=3, n_classes=3, n_informative=3, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42)\n",
    "conformity_score = LACConformityScore()\n",
    "generator = MultinomialSyntheticDataGenerator(random_state=42)\n",
    "generator.fit(X_seed, y_seed)\n",
    "X_cal, y_cal = generator.generate(n=100)\n",
    "mapie_clf = MapieClassifier(estimator=generator, cv=\"prefit\", conformity_score=conformity_score)\n",
    "# create mapie classifier for conformity scores\n",
    "mapie_clf.fit(X_cal, y_cal)\n",
    "# create \n",
    "oracle_annotator = OracleAnnotator(mapie_clf, generator)\n",
    "\n",
    "# generate all possible pairs for a couple of instances\n",
    "n_instances = 50\n",
    "n_classes = len(generator.classes_)\n",
    "n_obs = n_instances * n_classes\n",
    "X_train = generator.generate_instances(n_instances).repeat(n_classes, axis=0)\n",
    "y_train = np.tile(generator.classes_, n_instances)\n",
    "conformities = oracle_annotator.get_conformity(X_train,y_train)\n",
    "sort_idx = (-conformities).argsort(axis=0).flatten()\n",
    "\n",
    "X_sorted = X_train[sort_idx]\n",
    "y_sorted = y_train[sort_idx]\n",
    "conformities_sorted = conformities[sort_idx]\n",
    "\n",
    "X_pairs = np.array([(X_sorted[i], X_sorted[j]) for i in range(len(X_sorted)) for j in range(i + 1, len(X_sorted))])\n",
    "y_pairs = np.array([(y_sorted[i], y_sorted[j]) for i in range(len(y_sorted)) for j in range(i + 1, len(y_sorted))])\n",
    "y_pairs = np.expand_dims(y_pairs, axis=-1)\n",
    "\n",
    "\n",
    "ds = LabelPairDataset()\n",
    "ds.create_from_numpy_pairs(X_pairs, y_pairs)\n",
    "model = LabelRankingModel(input_dim=X_train.shape[1], hidden_dims=[2*X_train.shape[1]], output_dim=len(generator.classes_))\n",
    "pair_loader = DataLoader(ds, batch_size=64)\n",
    "model.num_classes = generator.n_classes_\n",
    "model._fit(pair_loader, val_loader=None, num_epochs=1000, learning_rate=0.01)\n",
    "\n",
    "\n",
    "# generate data from data generating process and check whether the learned non-conformity relation sorts them correctly\n",
    "X_test, y_test = X_train, y_train\n",
    "conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "print(\"in-sample: \", tau_corr)\n",
    "X_test, y_test = generator.generate(n=10)\n",
    "conformity_scores = oracle_annotator.get_conformity(X_test, y_test)\n",
    "skills_from_model = np.take_along_axis(model.predict_class_skills(X_test), y_test[:,np.newaxis], axis=1)\n",
    "tau_corr, p_value = kendalltau(skills_from_model, conformity_scores)\n",
    "print(\"out-of-sample: \", tau_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_rank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

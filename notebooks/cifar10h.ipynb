{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jonas/anaconda3/envs/plnet/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "features must be 2D tensor, got shape torch.Size([100, 3, 224, 224])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 132\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Compute evaluation metrics\u001b[39;00m\n\u001b[1;32m    105\u001b[0m metric \u001b[38;5;241m=\u001b[39m Metrics()\n\u001b[1;32m    107\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoverage_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoverage_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    109\u001b[0m         prediction_sets\u001b[38;5;241m=\u001b[39mval_prediction_sets, labels\u001b[38;5;241m=\u001b[39mval_labels\n\u001b[1;32m    110\u001b[0m     ),\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    112\u001b[0m         prediction_sets\u001b[38;5;241m=\u001b[39mval_prediction_sets, labels\u001b[38;5;241m=\u001b[39mval_labels\n\u001b[1;32m    113\u001b[0m     ),\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcov_gap\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCovGap\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    115\u001b[0m         prediction_sets\u001b[38;5;241m=\u001b[39mval_prediction_sets,\n\u001b[1;32m    116\u001b[0m         labels\u001b[38;5;241m=\u001b[39mval_labels,\n\u001b[1;32m    117\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    118\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m    119\u001b[0m     ),\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvio_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVioClasses\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    121\u001b[0m         prediction_sets\u001b[38;5;241m=\u001b[39mval_prediction_sets,\n\u001b[1;32m    122\u001b[0m         labels\u001b[38;5;241m=\u001b[39mval_labels,\n\u001b[1;32m    123\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    124\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m    125\u001b[0m     ),\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msscv\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSCV\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    128\u001b[0m         prediction_sets\u001b[38;5;241m=\u001b[39mval_prediction_sets,\n\u001b[1;32m    129\u001b[0m         labels\u001b[38;5;241m=\u001b[39mval_labels,\n\u001b[1;32m    130\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    131\u001b[0m     ),\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwsc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWSC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_prediction_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(y_true, y_pred),\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbacc\u001b[39m\u001b[38;5;124m\"\u001b[39m: balanced_accuracy_score(y_true, y_pred),\n\u001b[1;32m    139\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/plnet/lib/python3.11/site-packages/torchcp/classification/utils/metrics.py:298\u001b[0m, in \u001b[0;36mWSC\u001b[0;34m(features, prediction_sets, labels, delta, M, test_fraction, random_state, verbose)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM must be positive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures must be 2D tensor, got shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prediction_sets\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_sets must be 2D tensor, got shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_sets\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: features must be 2D tensor, got shape torch.Size([100, 3, 224, 224])"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from transformers import set_seed\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchcp.classification import Metrics\n",
    "from torchcp.classification.predictor import SplitPredictor\n",
    "from torchcp.classification.score import THR, APS, SAPS, RAPS, Margin, TOPK\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model.load_state_dict(torch.load(\"finetuned_models/clf_cifar10h_dbg.pth\",map_location=torch.device('cpu')))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "    \n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "cal_data, test_data = torch.utils.data.random_split(dataset, [10000, 40000])\n",
    "\n",
    "cal_data = Subset(cal_data, range(0,100))\n",
    "test_data = Subset(test_data, range(500,600))\n",
    "\n",
    "cal_data_loader = DataLoader(cal_data,batch_size=64)\n",
    "test_data_loader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "# Extract logits and labels\n",
    "cal_logits = torch.stack([sample[0] for sample in cal_data])\n",
    "cal_labels = torch.stack([torch.tensor(sample[1]) for sample in cal_data])\n",
    "test_logits = torch.stack([sample[0] for sample in test_data])\n",
    "test_labels = torch.stack([torch.tensor(sample[1]) for sample in test_data])\n",
    "\n",
    "#######################################\n",
    "# A standard process of conformal prediction\n",
    "#######################################\n",
    "scoring_methods = [THR(), APS(), RAPS(penalty=0)]\n",
    "alphas = [0.05,0.1,0.2]\n",
    "for score_function, alpha in product(scoring_methods, alphas):\n",
    "    predictor = SplitPredictor(score_function,model)\n",
    "    predictor.calibrate(cal_data_loader, alpha)\n",
    "\n",
    "    predictions_sets_list = []\n",
    "    predictions_list = []\n",
    "    labels_list = []\n",
    "    logits_list = []\n",
    "    feature_list = []\n",
    "\n",
    "    # Evaluate in inference mode\n",
    "    predictor._model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            # Move batch to device and get predictions\n",
    "            inputs = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            # Get predictions as bool tensor (N x C)\n",
    "            batch_predictions = predictor.predict(inputs)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            predicted_label = logits.argmax(axis=1)\n",
    "            # Accumulate predictions and labels\n",
    "            predictions_sets_list.append(batch_predictions)\n",
    "            predictions_list.append(predicted_label)\n",
    "            labels_list.append(labels)\n",
    "            logits_list.append(logits)\n",
    "            feature_list.append(inputs)\n",
    "\n",
    "        # Concatenate all batches\n",
    "        val_prediction_sets = torch.cat(predictions_sets_list, dim=0)  # (N_val x C)\n",
    "        val_predictions = torch.cat(predictions_list, dim=0)\n",
    "        val_labels = torch.cat(labels_list, dim=0)  # (N_val,)\n",
    "        val_logits = torch.cat(logits_list, dim=0)\n",
    "        val_features = torch.cat(feature_list, dim=0)\n",
    "\n",
    "        y_pred = val_predictions.detach().cpu().numpy()\n",
    "        y_true = val_labels.detach().cpu().numpy()\n",
    "        # Compute evaluation metrics\n",
    "        metric = Metrics()\n",
    "\n",
    "        metrics = {\n",
    "            \"coverage_rate\": metric(\"coverage_rate\")(\n",
    "                prediction_sets=val_prediction_sets, labels=val_labels\n",
    "            ),\n",
    "            \"average_size\": metric(\"average_size\")(\n",
    "                prediction_sets=val_prediction_sets, labels=val_labels\n",
    "            ),\n",
    "            \"cov_gap\": metric(\"CovGap\")(\n",
    "                prediction_sets=val_prediction_sets,\n",
    "                labels=val_labels,\n",
    "                alpha=alpha,\n",
    "                num_classes=num_classes,\n",
    "            ),\n",
    "            \"vio_classes\": metric(\"VioClasses\")(\n",
    "                prediction_sets=val_prediction_sets,\n",
    "                labels=val_labels,\n",
    "                alpha=alpha,\n",
    "                num_classes=num_classes,\n",
    "            ),\n",
    "\n",
    "            \"sscv\": metric(\"SSCV\")(\n",
    "                prediction_sets=val_prediction_sets,\n",
    "                labels=val_labels,\n",
    "                alpha=alpha,\n",
    "            ),\n",
    "            # \"wsc\": metric(\"WSC\")(\n",
    "            #     val_features,\n",
    "            #     prediction_sets=val_prediction_sets,\n",
    "            #     labels=val_labels,\n",
    "            # ),\n",
    "            \"acc\": accuracy_score(y_true, y_pred),\n",
    "            \"bacc\": balanced_accuracy_score(y_true, y_pred),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

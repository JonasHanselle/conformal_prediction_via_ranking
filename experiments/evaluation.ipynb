{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from py_experimenter.experimenter import PyExperimenter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import mysql.connector\n",
    "import openml\n",
    "\n",
    "\n",
    "from py_experimenter.database_connector_mysql import DatabaseConnectorMYSQL\n",
    "\n",
    "def connect(self):\n",
    "\n",
    "    db = mysql.connector.connect(\n",
    "        host=\"db01-kiml.kiml.ifi.lmu.de\",\n",
    "        user=\"jonas_h\",\n",
    "        password=\"thiswillnotactuallybevalidforverylongsodontcountonit\",\n",
    "        database=\"jonas_test\",\n",
    "        ssl_disabled=False,\n",
    "    )\n",
    "    return db\n",
    "\n",
    "\n",
    "def _start_transaction(self, connection, readonly=False):\n",
    "    if not readonly:\n",
    "        connection.start_transaction()\n",
    "\n",
    "\n",
    "DatabaseConnectorMYSQL.connect = connect\n",
    "DatabaseConnectorMYSQL._start_transaction = _start_transaction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:06:31,235  | py-experimenter - INFO     | Found 5 keyfields\n",
      "2024-08-22 16:06:31,241  | py-experimenter - INFO     | Found 9 resultfields\n",
      "2024-08-22 16:06:31,248  | py-experimenter - WARNING  | No logtables given\n",
      "2024-08-22 16:06:31,252  | py-experimenter - WARNING  | No custom section defined in config\n",
      "2024-08-22 16:06:31,257  | py-experimenter - WARNING  | No codecarbon section defined in config\n",
      "2024-08-22 16:06:31,286  | py-experimenter - INFO     | Initialized and connected to database\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_225595/3367923869.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mexperiment_configuration_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./experiments/config/config.yml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mexp_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperimenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexp_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction_cal_samples\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.19999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexp_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m39\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "experimenter = PyExperimenter(\n",
    "    experiment_configuration_file_path=\"./experiments/config/config.yml\",\n",
    ")\n",
    "exp_frame = experimenter.get_table()\n",
    "exp_frame = exp_frame[exp_frame.fraction_cal_samples >= 0.19999]\n",
    "exp_frame = exp_frame[exp_frame.dataset != 39]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "datasets = {}\n",
    "num_classes = {}\n",
    "dataset_renamer = {}\n",
    "for id in exp_frame.openml_id.unique():\n",
    "    dataset = openml.datasets.get_dataset(id.item())\n",
    "    target_attribute = dataset.default_target_attribute\n",
    "    X, y, _, _ = dataset.get_data(target=target_attribute)\n",
    "    datasets[id] = dataset\n",
    "    dataset_renamer[id] = dataset.name\n",
    "    num_classes[id] = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>model</th>\n",
       "      <th>openml_id</th>\n",
       "      <th>master_seed</th>\n",
       "      <th>alpha</th>\n",
       "      <th>fraction_cal_samples</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>status</th>\n",
       "      <th>start_date</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>score_bacc</th>\n",
       "      <th>coverage_mean</th>\n",
       "      <th>coverage_std</th>\n",
       "      <th>efficiency_mean</th>\n",
       "      <th>efficiency_std</th>\n",
       "      <th>clf_seed</th>\n",
       "      <th>mccv_seed</th>\n",
       "      <th>end_date</th>\n",
       "      <th>error</th>\n",
       "      <th>rn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:16:53</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.185577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 17:17:19</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:41:12</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.257539</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 17:41:46</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>917</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:42:03</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.363935</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.349927</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 17:42:37</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>581</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:17:37</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.202535</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.084213</td>\n",
       "      <td>364522461</td>\n",
       "      <td>242886303</td>\n",
       "      <td>2024-08-14 17:18:04</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>759</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:41:15</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.166599</td>\n",
       "      <td>364522461</td>\n",
       "      <td>242886303</td>\n",
       "      <td>2024-08-14 17:41:49</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>893</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:41:54</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973508</td>\n",
       "      <td>0.906829</td>\n",
       "      <td>0.290671</td>\n",
       "      <td>0.914066</td>\n",
       "      <td>0.280267</td>\n",
       "      <td>595022250</td>\n",
       "      <td>1603362544</td>\n",
       "      <td>2024-08-14 17:42:07</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>1061</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:43:40</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973508</td>\n",
       "      <td>0.801900</td>\n",
       "      <td>0.398568</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.396150</td>\n",
       "      <td>595022250</td>\n",
       "      <td>1603362544</td>\n",
       "      <td>2024-08-14 17:43:54</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>731</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:41:11</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.951606</td>\n",
       "      <td>0.214598</td>\n",
       "      <td>0.971054</td>\n",
       "      <td>0.167655</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:41:26</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>911</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:42:00</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.893713</td>\n",
       "      <td>0.308204</td>\n",
       "      <td>0.902759</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:42:13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1079</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:43:56</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.797829</td>\n",
       "      <td>0.401619</td>\n",
       "      <td>0.802352</td>\n",
       "      <td>0.398225</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:44:10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>870 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID          model  openml_id  master_seed  alpha  \\\n",
       "1      569  classifier_nn         15            1   0.05   \n",
       "3      741  classifier_nn         15            1   0.10   \n",
       "5      917  classifier_nn         15            1   0.20   \n",
       "7      581  classifier_nn         15            2   0.05   \n",
       "9      759  classifier_nn         15            2   0.10   \n",
       "...    ...            ...        ...          ...    ...   \n",
       "1731   893  random_forest       4534            9   0.10   \n",
       "1733  1061  random_forest       4534            9   0.20   \n",
       "1735   731  random_forest       4534           10   0.05   \n",
       "1737   911  random_forest       4534           10   0.10   \n",
       "1739  1079  random_forest       4534           10   0.20   \n",
       "\n",
       "      fraction_cal_samples       creation_date status          start_date  \\\n",
       "1                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:16:53   \n",
       "3                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:41:12   \n",
       "5                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:42:03   \n",
       "7                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:17:37   \n",
       "9                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:41:15   \n",
       "...                    ...                 ...    ...                 ...   \n",
       "1731                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:41:54   \n",
       "1733                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:43:40   \n",
       "1735                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:41:11   \n",
       "1737                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:42:00   \n",
       "1739                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:43:56   \n",
       "\n",
       "                name  ... score_bacc  coverage_mean  coverage_std  \\\n",
       "1     PyExperimenter  ...   0.973118       0.964286      0.185577   \n",
       "3     PyExperimenter  ...   0.973118       0.928571      0.257539   \n",
       "5     PyExperimenter  ...   0.973118       0.842857      0.363935   \n",
       "7     PyExperimenter  ...   0.962594       0.957143      0.202535   \n",
       "9     PyExperimenter  ...   0.962594       0.950000      0.217945   \n",
       "...              ...  ...        ...            ...           ...   \n",
       "1731  PyExperimenter  ...   0.973508       0.906829      0.290671   \n",
       "1733  PyExperimenter  ...   0.973508       0.801900      0.398568   \n",
       "1735  PyExperimenter  ...   0.967596       0.951606      0.214598   \n",
       "1737  PyExperimenter  ...   0.967596       0.893713      0.308204   \n",
       "1739  PyExperimenter  ...   0.967596       0.797829      0.401619   \n",
       "\n",
       "      efficiency_mean  efficiency_std    clf_seed   mccv_seed  \\\n",
       "1            1.000000        0.000000  1095513148  3280387012   \n",
       "3            0.950000        0.217945  1095513148  3280387012   \n",
       "5            0.857143        0.349927  1095513148  3280387012   \n",
       "7            0.992857        0.084213   364522461   242886303   \n",
       "9            0.971429        0.166599   364522461   242886303   \n",
       "...               ...             ...         ...         ...   \n",
       "1731         0.914066        0.280267   595022250  1603362544   \n",
       "1733         0.805066        0.396150   595022250  1603362544   \n",
       "1735         0.971054        0.167655  1842064464  2454155475   \n",
       "1737         0.902759        0.296286  1842064464  2454155475   \n",
       "1739         0.802352        0.398225  1842064464  2454155475   \n",
       "\n",
       "                end_date error rn  \n",
       "1    2024-08-14 17:17:19  None  1  \n",
       "3    2024-08-14 17:41:46  None  1  \n",
       "5    2024-08-14 17:42:37  None  1  \n",
       "7    2024-08-14 17:18:04  None  1  \n",
       "9    2024-08-14 17:41:49  None  1  \n",
       "...                  ...   ... ..  \n",
       "1731 2024-08-14 17:42:07  None  1  \n",
       "1733 2024-08-14 17:43:54  None  1  \n",
       "1735 2024-08-14 17:41:26  None  1  \n",
       "1737 2024-08-14 17:42:13  None  1  \n",
       "1739 2024-08-14 17:44:10  None  1  \n",
       "\n",
       "[870 rows x 23 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exp_frame\n",
    "\n",
    "exp_frame[\"dataset\"] =  exp_frame[\"openml_id\"].replace(dataset_renamer)\n",
    "exp_frame[\"num_classes\"] = exp_frame[\"openml_id\"].replace(num_classes)\n",
    "\n",
    "exp_frame[\"dataset\"] = exp_frame[\"dataset\"] + \" (\" + exp_frame[\"num_classes\"].astype(str) + \")\" \n",
    "\n",
    "# group_cols = ['dataset', 'alpha', 'fraction_cal_samples', 'model']\n",
    "group_cols = ['dataset', 'alpha', 'model']\n",
    "metrics_max = ['score_acc', 'coverage_mean']\n",
    "metrics_min = ['efficiency_mean']\n",
    "metrics = metrics_max + metrics_min\n",
    "\n",
    "grouped_df = df.groupby(group_cols).agg({metric: 'mean' for metric in metrics}).reset_index()\n",
    "agg_dict = {metric: 'max' for metric in metrics_max}\n",
    "agg_dict.update({metric: 'min' for metric in metrics_min})\n",
    "best_values = grouped_df.groupby(['dataset', 'alpha']).agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "dataset & alpha & model & score\\_acc & coverage\\_mean & efficiency\\_mean \\\\\n",
      "\\midrule\n",
      " \\multirow{9}{*}{PhishingWebsites (2)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.9607 & 0.9536 & 0.9883 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9607 & 0.9510 & 1.2198 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9709} & \\textbf{0.9552} & \\textbf{0.9734} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9607 & \\textbf{0.9056} & 0.9180 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9607 & 0.9039 & 1.0748 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9709} & 0.9031 & \\textbf{0.9106} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9607 & 0.8008 & \\textbf{0.8032} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9607 & \\textbf{0.8066} & 0.8929 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9709} & 0.8025 & 0.8058 \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{bank-marketing (2)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9046} & 0.9485 & \\textbf{1.1030} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.8835 & 0.9484 & 1.3721 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9021 & \\textbf{0.9503} & 1.1140 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9046} & 0.8975 & \\textbf{0.9864} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.8835 & \\textbf{0.8993} & 1.2356 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9021 & 0.8989 & 0.9943 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9046} & 0.8007 & \\textbf{0.8329} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.8835 & 0.7977 & 1.0275 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9021 & \\textbf{0.8018} & 0.8356 \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{breast-w (2)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9700} & 0.9550 & \\textbf{0.9800} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9693 & 0.9579 & 1.0743 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9671 & \\textbf{0.9614} & 0.9979 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9700} & 0.9093 & 0.9221 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9693 & \\textbf{0.9114} & 1.0007 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9671 & 0.8943 & \\textbf{0.9071} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9700} & 0.7979 & 0.8029 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9693 & \\textbf{0.8093} & 0.8764 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9671 & 0.7893 & \\textbf{0.7950} \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{credit-g (2)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.7270 & 0.9520 & \\textbf{1.5980} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.7275 & 0.9505 & 1.7080 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7410} & \\textbf{0.9535} & 1.6315 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.7270 & 0.9000 & \\textbf{1.4040} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.7275 & \\textbf{0.9115} & 1.5715 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7410} & 0.9020 & 1.4250 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.7270 & 0.8010 & \\textbf{1.1465} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.7275 & \\textbf{0.8215} & 1.3365 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7410} & 0.8080 & 1.1485 \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{dermatology (6)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.9716 & 0.9527 & \\textbf{0.9703} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9676 & 0.9554 & 3.5338 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9757} & \\textbf{0.9622} & 0.9797 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9716 & 0.9176 & 0.9230 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9676 & \\textbf{0.9297} & 3.1662 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9757} & 0.9149 & \\textbf{0.9189} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9716 & \\textbf{0.8365} & 0.8378 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9676 & 0.8230 & 2.4905 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9757} & 0.8351 & \\textbf{0.8351} \\\\\n",
      "\\cline{1-6} \\multirow{6}{*}{ecoli (8)} &  \\multirow{2}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.8647} & 0.9706 & \\textbf{2.4265} \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.8611 & \\textbf{0.9722} & 2.8775 \\\\\n",
      "\\cline{2-6} &  \\multirow{2}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.8647} & \\textbf{0.9279} & 1.4294 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.8611 & 0.9167 & \\textbf{1.2925} \\\\\n",
      "\\cline{2-6} &  \\multirow{2}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.8647} & \\textbf{0.8074} & 0.9206 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.8611 & 0.7958 & \\textbf{0.8987} \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{glass (6)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.6140 & 0.9581 & 2.9767 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.6186 & 0.9581 & 4.9349 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7233} & \\textbf{0.9674} & \\textbf{2.6093} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.6140 & 0.8791 & 2.0488 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.6186 & \\textbf{0.9070} & 3.8233 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7233} & 0.8651 & \\textbf{1.5930} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.6140 & 0.7698 & 1.5395 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.6186 & \\textbf{0.7977} & 2.7140 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7233} & 0.7860 & \\textbf{1.1488} \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{iris (3)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9600} & 0.9200 & \\textbf{0.9567} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9600 & 0.9367 & 1.4233 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9467 & \\textbf{0.9567} & 1.0533 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9600} & 0.8600 & \\textbf{0.8700} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9600 & \\textbf{0.9100} & 1.3633 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9467 & 0.9067 & 0.9367 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9600} & 0.7533 & \\textbf{0.7533} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9600 & \\textbf{0.8033} & 1.2033 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9467 & 0.7900 & 0.7967 \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{vehicle (4)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.5594 & 0.9676 & \\textbf{2.6741} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.5894 & 0.9635 & 3.3965 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.5912} & \\textbf{0.9753} & 2.6771 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5594 & \\textbf{0.9182} & 2.3018 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.5894 & 0.8971 & 3.1247 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.5912} & \\textbf{0.9182} & \\textbf{2.2241} \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5594 & \\textbf{0.8106} & 1.7094 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.5894 & 0.7947 & 2.6782 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.5912} & 0.8094 & \\textbf{1.6971} \\\\\n",
      "\\cline{1-6} \\multirow{9}{*}{wine (3)} &  \\multirow{3}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9778} & 0.9528 & \\textbf{0.9778} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9778} & 0.9528 & 1.6944 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9778 & \\textbf{0.9694} & 0.9944 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9778} & 0.8861 & \\textbf{0.8861} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9778} & \\textbf{0.9083} & 1.4250 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9778 & 0.8944 & 0.9000 \\\\\n",
      "\\cline{2-6} &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9778} & 0.7806 & 0.7806 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9778} & \\textbf{0.8028} & 1.2028 \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9778 & 0.7750 & \\textbf{0.7750} \\\\\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_with_lines(df, group_cols, value_cols, best_values):\n",
    "    \"\"\"Generate a LaTeX table with multirow entries, bold the best values, and add lines between consecutive multirows.\"\"\"\n",
    "    \n",
    "    def format_value(value, group, metric, max=True):\n",
    "        \"\"\"Format the value, making the highest value bold.\"\"\"\n",
    "        max_value = best_values.loc[\n",
    "            (best_values['dataset'] == group['dataset']) & \n",
    "            (best_values['alpha'] == group['alpha']), metric].values[0]\n",
    "            # (best_values['fraction_cal_samples'] == group['fraction_cal_samples']), metric].values[0]\n",
    "        if value == max_value:\n",
    "            return f\"\\\\textbf{{{value:.4f}}}\"\n",
    "        else:\n",
    "            return f\"{value:.4f}\"\n",
    "    \n",
    "    def recursive_build(df, group_cols):\n",
    "        # if len(group_cols) == 1:\n",
    "            # Base case: only one group left, print it directly\n",
    "            latex_str = \"\"\n",
    "            prev_row = None\n",
    "            for row_id, row in df.iterrows():\n",
    "                latex_str_tmp = \"\"\n",
    "                col_id_list = []\n",
    "                for col_id, col in enumerate(group_cols):\n",
    "                    if prev_row is None or row[col] != prev_row[col]:\n",
    "                        col_id_list.append(col_id)\n",
    "                        filter_cols = group_cols[:col_id+1]\n",
    "                        indices = []\n",
    "                        values = []\n",
    "                        for fcol in filter_cols:\n",
    "                            indices.append(fcol)\n",
    "                            values.append(row[fcol])\n",
    "                        criteria = dict(zip(indices, values))\n",
    "                        # Filter the DataFrame using query\n",
    "                        mask = pd.Series([True] * len(df))\n",
    "\n",
    "                        # Iterate over criteria to apply conditions\n",
    "                        for key, value in criteria.items():\n",
    "                            mask = mask & (df[key] == value)\n",
    "\n",
    "                        # Filter the DataFrame\n",
    "                        filtered_df = df[mask]\n",
    "\n",
    "                        length = len(filtered_df)\n",
    "\n",
    "\n",
    "                        latex_str_tmp += f\" \\\\multirow{{{length}}}{{*}}{{{row[col]}}} & \"\n",
    "                        if col_id == len(group_cols) - 1:\n",
    "                            latex_str_tmp += \" & \".join([format_value(row[col], row, col) for col in value_cols]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "                        # if prev_row is not None and col_id < len(group_cols) - 1:\n",
    "                        # latex_str_tmp += \" \\\\\\\\ \\cline{%d-%d} \\\\\\\\\" % (col_id + 1, len(group_cols) + len(value_cols))\n",
    "\n",
    "                    else:\n",
    "                        latex_str_tmp += \" & \"\n",
    "                        if col_id == len(group_cols) - 1:\n",
    "                            latex_str_tmp += \" & \".join([format_value(row[col], row, col) for col in value_cols]) + \" \\\\\\\\\\n\"\n",
    "                if row_id > 0 and group_cols[min(col_id_list)] != \"model\":\n",
    "                    latex_str += \"\\\\cline{%d-%d}\" % (min(col_id_list)+1, len(group_cols) + len(value_cols))\n",
    "                latex_str += latex_str_tmp\n",
    "                indices = []\n",
    "                values = []\n",
    "                prev_row = row\n",
    "            return latex_str\n",
    "        \n",
    "    # Start recursive building\n",
    "    latex_body = recursive_build(df, group_cols)\n",
    "\n",
    "    # Complete LaTeX table\n",
    "    num_columns = len(group_cols) + len(value_cols)\n",
    "    col_format = 'l' * len(group_cols) + 'r' * len(value_cols)\n",
    "    latex_table = f\"\"\"\n",
    "\\\\begin{{tabular}}{{{col_format}}}\n",
    "\\\\toprule\n",
    "{' & '.join(group_cols)} & {' & '.join(value_cols)} \\\\\\\\\n",
    "\\\\midrule\n",
    "{latex_body}\n",
    "\\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "\"\"\"\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table with bold formatting and lines\n",
    "latex_table = generate_latex_table_with_lines(grouped_df, group_cols, metrics, best_values)\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "print(latex_table.replace(\"_\", \"\\_\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>alpha</th>\n",
       "      <th>model</th>\n",
       "      <th>score_acc</th>\n",
       "      <th>coverage_mean</th>\n",
       "      <th>efficiency_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.960742</td>\n",
       "      <td>0.953596</td>\n",
       "      <td>0.988331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.960651</td>\n",
       "      <td>0.951018</td>\n",
       "      <td>1.219766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.970873</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.973360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.960742</td>\n",
       "      <td>0.905563</td>\n",
       "      <td>0.918001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.960651</td>\n",
       "      <td>0.903935</td>\n",
       "      <td>1.074763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>1.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.780556</td>\n",
       "      <td>0.780556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.802778</td>\n",
       "      <td>1.202778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset  alpha          model  score_acc  coverage_mean  \\\n",
       "0   PhishingWebsites (2)   0.05  classifier_nn   0.960742       0.953596   \n",
       "1   PhishingWebsites (2)   0.05          plnet   0.960651       0.951018   \n",
       "2   PhishingWebsites (2)   0.05  random_forest   0.970873       0.955224   \n",
       "3   PhishingWebsites (2)   0.10  classifier_nn   0.960742       0.905563   \n",
       "4   PhishingWebsites (2)   0.10          plnet   0.960651       0.903935   \n",
       "..                   ...    ...            ...        ...            ...   \n",
       "82              wine (3)   0.10          plnet   0.977778       0.908333   \n",
       "83              wine (3)   0.10  random_forest   0.977778       0.894444   \n",
       "84              wine (3)   0.20  classifier_nn   0.977778       0.780556   \n",
       "85              wine (3)   0.20          plnet   0.977778       0.802778   \n",
       "86              wine (3)   0.20  random_forest   0.977778       0.775000   \n",
       "\n",
       "    efficiency_mean  \n",
       "0          0.988331  \n",
       "1          1.219766  \n",
       "2          0.973360  \n",
       "3          0.918001  \n",
       "4          1.074763  \n",
       "..              ...  \n",
       "82         1.425000  \n",
       "83         0.900000  \n",
       "84         0.780556  \n",
       "85         1.202778  \n",
       "86         0.775000  \n",
       "\n",
       "[87 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

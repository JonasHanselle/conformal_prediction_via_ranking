{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from py_experimenter.experimenter import PyExperimenter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import mysql.connector\n",
    "import openml\n",
    "\n",
    "\n",
    "from py_experimenter.database_connector_mysql import DatabaseConnectorMYSQL\n",
    "\n",
    "def connect(self):\n",
    "\n",
    "    db = mysql.connector.connect(\n",
    "        host=\"xxx\",\n",
    "        user=\"xxx\",\n",
    "        password=\"xxx\",\n",
    "        database=\"xxx\",\n",
    "        ssl_disabled=False,\n",
    "    )\n",
    "    return db\n",
    "\n",
    "\n",
    "def _start_transaction(self, connection, readonly=False):\n",
    "    if not readonly:\n",
    "        connection.start_transaction()\n",
    "\n",
    "\n",
    "DatabaseConnectorMYSQL.connect = connect\n",
    "DatabaseConnectorMYSQL._start_transaction = _start_transaction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 16:56:50,196  | py-experimenter - INFO     | Found 5 keyfields\n",
      "2024-08-19 16:56:50,197  | py-experimenter - INFO     | Found 9 resultfields\n",
      "2024-08-19 16:56:50,198  | py-experimenter - WARNING  | No logtables given\n",
      "2024-08-19 16:56:50,198  | py-experimenter - WARNING  | No custom section defined in config\n",
      "2024-08-19 16:56:50,198  | py-experimenter - WARNING  | No codecarbon section defined in config\n",
      "2024-08-19 16:56:50,208  | py-experimenter - INFO     | Initialized and connected to database\n"
     ]
    }
   ],
   "source": [
    "experimenter = PyExperimenter(\n",
    "    experiment_configuration_file_path=\"./experiments/config/config.yml\",\n",
    ")\n",
    "exp_frame = experimenter.get_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>model</th>\n",
       "      <th>openml_id</th>\n",
       "      <th>master_seed</th>\n",
       "      <th>alpha</th>\n",
       "      <th>fraction_cal_samples</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>status</th>\n",
       "      <th>start_date</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>score_bacc</th>\n",
       "      <th>coverage_mean</th>\n",
       "      <th>coverage_std</th>\n",
       "      <th>efficiency_mean</th>\n",
       "      <th>efficiency_std</th>\n",
       "      <th>clf_seed</th>\n",
       "      <th>mccv_seed</th>\n",
       "      <th>end_date</th>\n",
       "      <th>error</th>\n",
       "      <th>rn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 16:50:39</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.202535</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.084213</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 16:51:17</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:16:53</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.185577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 17:17:19</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 16:58:28</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.269069</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 16:58:55</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:41:12</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.257539</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 17:41:46</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:07:43</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.382993</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.370535</td>\n",
       "      <td>1095513148</td>\n",
       "      <td>3280387012</td>\n",
       "      <td>2024-08-14 17:08:10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>731</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:41:11</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.951606</td>\n",
       "      <td>0.214598</td>\n",
       "      <td>0.971054</td>\n",
       "      <td>0.167655</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:41:26</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>395</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:07:19</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967915</td>\n",
       "      <td>0.869742</td>\n",
       "      <td>0.336587</td>\n",
       "      <td>0.876526</td>\n",
       "      <td>0.328980</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:07:32</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>911</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:42:00</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.893713</td>\n",
       "      <td>0.308204</td>\n",
       "      <td>0.902759</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:42:13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>563</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:16:30</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967915</td>\n",
       "      <td>0.803256</td>\n",
       "      <td>0.397537</td>\n",
       "      <td>0.807327</td>\n",
       "      <td>0.394398</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:16:44</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>1079</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>4534</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2024-08-14 16:50:38</td>\n",
       "      <td>done</td>\n",
       "      <td>2024-08-14 17:43:56</td>\n",
       "      <td>PyExperimenter</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.797829</td>\n",
       "      <td>0.401619</td>\n",
       "      <td>0.802352</td>\n",
       "      <td>0.398225</td>\n",
       "      <td>1842064464</td>\n",
       "      <td>2454155475</td>\n",
       "      <td>2024-08-14 17:44:10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID          model  openml_id  master_seed  alpha  \\\n",
       "0       62  classifier_nn         15            1   0.05   \n",
       "1      569  classifier_nn         15            1   0.05   \n",
       "2      225  classifier_nn         15            1   0.10   \n",
       "3      741  classifier_nn         15            1   0.10   \n",
       "4      401  classifier_nn         15            1   0.20   \n",
       "...    ...            ...        ...          ...    ...   \n",
       "1795   731  random_forest       4534           10   0.05   \n",
       "1796   395  random_forest       4534           10   0.10   \n",
       "1797   911  random_forest       4534           10   0.10   \n",
       "1798   563  random_forest       4534           10   0.20   \n",
       "1799  1079  random_forest       4534           10   0.20   \n",
       "\n",
       "      fraction_cal_samples       creation_date status          start_date  \\\n",
       "0                      0.1 2024-08-14 16:50:38   done 2024-08-14 16:50:39   \n",
       "1                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:16:53   \n",
       "2                      0.1 2024-08-14 16:50:38   done 2024-08-14 16:58:28   \n",
       "3                      0.2 2024-08-14 16:50:38   done 2024-08-14 17:41:12   \n",
       "4                      0.1 2024-08-14 16:50:38   done 2024-08-14 17:07:43   \n",
       "...                    ...                 ...    ...                 ...   \n",
       "1795                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:41:11   \n",
       "1796                   0.1 2024-08-14 16:50:38   done 2024-08-14 17:07:19   \n",
       "1797                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:42:00   \n",
       "1798                   0.1 2024-08-14 16:50:38   done 2024-08-14 17:16:30   \n",
       "1799                   0.2 2024-08-14 16:50:38   done 2024-08-14 17:43:56   \n",
       "\n",
       "                name  ... score_bacc  coverage_mean  coverage_std  \\\n",
       "0     PyExperimenter  ...   0.973118       0.957143      0.202535   \n",
       "1     PyExperimenter  ...   0.973118       0.964286      0.185577   \n",
       "2     PyExperimenter  ...   0.973118       0.921429      0.269069   \n",
       "3     PyExperimenter  ...   0.973118       0.928571      0.257539   \n",
       "4     PyExperimenter  ...   0.973118       0.821429      0.382993   \n",
       "...              ...  ...        ...            ...           ...   \n",
       "1795  PyExperimenter  ...   0.967596       0.951606      0.214598   \n",
       "1796  PyExperimenter  ...   0.967915       0.869742      0.336587   \n",
       "1797  PyExperimenter  ...   0.967596       0.893713      0.308204   \n",
       "1798  PyExperimenter  ...   0.967915       0.803256      0.397537   \n",
       "1799  PyExperimenter  ...   0.967596       0.797829      0.401619   \n",
       "\n",
       "      efficiency_mean  efficiency_std    clf_seed   mccv_seed  \\\n",
       "0            0.992857        0.084213  1095513148  3280387012   \n",
       "1            1.000000        0.000000  1095513148  3280387012   \n",
       "2            0.950000        0.217945  1095513148  3280387012   \n",
       "3            0.950000        0.217945  1095513148  3280387012   \n",
       "4            0.835714        0.370535  1095513148  3280387012   \n",
       "...               ...             ...         ...         ...   \n",
       "1795         0.971054        0.167655  1842064464  2454155475   \n",
       "1796         0.876526        0.328980  1842064464  2454155475   \n",
       "1797         0.902759        0.296286  1842064464  2454155475   \n",
       "1798         0.807327        0.394398  1842064464  2454155475   \n",
       "1799         0.802352        0.398225  1842064464  2454155475   \n",
       "\n",
       "                end_date error rn  \n",
       "0    2024-08-14 16:51:17  None  1  \n",
       "1    2024-08-14 17:17:19  None  1  \n",
       "2    2024-08-14 16:58:55  None  1  \n",
       "3    2024-08-14 17:41:46  None  1  \n",
       "4    2024-08-14 17:08:10  None  1  \n",
       "...                  ...   ... ..  \n",
       "1795 2024-08-14 17:41:26  None  1  \n",
       "1796 2024-08-14 17:07:32  None  1  \n",
       "1797 2024-08-14 17:42:13  None  1  \n",
       "1798 2024-08-14 17:16:44  None  1  \n",
       "1799 2024-08-14 17:44:10  None  1  \n",
       "\n",
       "[1800 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "datasets = {}\n",
    "num_classes = {}\n",
    "dataset_renamer = {}\n",
    "for id in exp_frame.openml_id.unique():\n",
    "    dataset = openml.datasets.get_dataset(id.item())\n",
    "    target_attribute = dataset.default_target_attribute\n",
    "    X, y, _, _ = dataset.get_data(target=target_attribute)\n",
    "    datasets[id] = dataset\n",
    "    dataset_renamer[id] = dataset.name\n",
    "    num_classes[id] = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exp_frame\n",
    "\n",
    "exp_frame[\"dataset\"] =  exp_frame[\"openml_id\"].replace(dataset_renamer)\n",
    "exp_frame[\"num_classes\"] = exp_frame[\"openml_id\"].replace(num_classes)\n",
    "\n",
    "exp_frame[\"dataset\"] = exp_frame[\"dataset\"] + \" (\" + exp_frame[\"num_classes\"].astype(str) + \")\" \n",
    "\n",
    "group_cols = ['dataset', 'alpha', 'fraction_cal_samples', 'model']\n",
    "metrics_max = ['score_bacc', 'score_acc', 'coverage_mean']\n",
    "metrics_min = ['efficiency_mean']\n",
    "metrics = metrics_max + metrics_min\n",
    "\n",
    "grouped_df = df.groupby(group_cols).agg({metric: 'mean' for metric in metrics}).reset_index()\n",
    "agg_dict = {metric: 'max' for metric in metrics_max}\n",
    "agg_dict.update({metric: 'min' for metric in metrics_min})\n",
    "best_values = grouped_df.groupby(['dataset', 'alpha', 'fraction_cal_samples']).agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{llllrrrr}\n",
      "\\toprule\n",
      "dataset & alpha & fraction\\_cal\\_samples & model & score\\_bacc & score\\_acc & coverage\\_mean & efficiency\\_mean \\\\\n",
      "\\midrule\n",
      " \\multirow{18}{*}{PhishingWebsites (2)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9624 & 0.9630 & \\textbf{0.9557} & 0.9867 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9294 & 0.9328 & 0.9510 & 1.3393 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9715} & \\textbf{0.9724} & 0.9533 & \\textbf{0.9681} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9600 & 0.9607 & 0.9536 & 0.9883 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9602 & 0.9607 & 0.9503 & 1.2176 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9701} & \\textbf{0.9709} & \\textbf{0.9552} & \\textbf{0.9734} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9624 & 0.9630 & 0.9044 & 0.9141 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9294 & 0.9328 & \\textbf{0.9510} & 1.3393 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9715} & \\textbf{0.9724} & 0.9036 & \\textbf{0.9105} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9600 & 0.9607 & 0.9056 & 0.9180 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9602 & 0.9607 & \\textbf{0.9503} & 1.2176 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9701} & \\textbf{0.9709} & 0.9031 & \\textbf{0.9106} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9624 & 0.9630 & 0.8019 & \\textbf{0.8044} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9294 & 0.9328 & \\textbf{0.9510} & 1.3393 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9715} & \\textbf{0.9724} & 0.8097 & 0.8127 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9600 & 0.9607 & 0.8008 & \\textbf{0.8032} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9602 & 0.9607 & \\textbf{0.9503} & 1.2176 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9701} & \\textbf{0.9709} & 0.8025 & 0.8058 \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{bank-marketing (2)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7209} & \\textbf{0.9042} & 0.9497 & \\textbf{1.1048} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5675 & 0.8901 & 0.9494 & 1.4184 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6874 & 0.9016 & \\textbf{0.9502} & 1.1142 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7204} & \\textbf{0.9046} & 0.9485 & \\textbf{1.1030} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5000 & 0.8835 & 0.9483 & 1.3717 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6871 & 0.9021 & \\textbf{0.9503} & 1.1140 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7209} & \\textbf{0.9042} & 0.8964 & \\textbf{0.9844} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5675 & 0.8901 & \\textbf{0.9494} & 1.4184 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6874 & 0.9016 & 0.8987 & 0.9940 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7204} & \\textbf{0.9046} & 0.8975 & \\textbf{0.9864} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5000 & 0.8835 & \\textbf{0.9483} & 1.3717 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6871 & 0.9021 & 0.8989 & 0.9943 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7209} & \\textbf{0.9042} & 0.7980 & \\textbf{0.8284} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5675 & 0.8901 & \\textbf{0.9494} & 1.4184 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6874 & 0.9016 & 0.8002 & 0.8345 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7204} & \\textbf{0.9046} & 0.8007 & \\textbf{0.8329} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5000 & 0.8835 & \\textbf{0.9483} & 1.3717 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6871 & 0.9021 & 0.8018 & 0.8356 \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{breast-w (2)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9680 & 0.9693 & \\textbf{0.9736} & 1.0271 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9698} & \\textbf{0.9700} & 0.9579 & 1.0736 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9669 & 0.9686 & 0.9664 & \\textbf{1.0221} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9697 & \\textbf{0.9700} & 0.9550 & \\textbf{0.9800} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9699} & 0.9693 & 0.9514 & 1.0614 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9649 & 0.9671 & \\textbf{0.9614} & 0.9979 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9680 & 0.9693 & 0.9043 & \\textbf{0.9193} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9698} & \\textbf{0.9700} & \\textbf{0.9579} & 1.0736 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9669 & 0.9686 & 0.9093 & 0.9264 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9697 & \\textbf{0.9700} & 0.9093 & 0.9221 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9699} & 0.9693 & \\textbf{0.9514} & 1.0614 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9649 & 0.9671 & 0.8943 & \\textbf{0.9071} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9680 & 0.9693 & 0.7579 & \\textbf{0.7629} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9698} & \\textbf{0.9700} & \\textbf{0.9579} & 1.0736 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9669 & 0.9686 & 0.7864 & 0.7929 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9697 & \\textbf{0.9700} & 0.7979 & 0.8029 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9699} & 0.9693 & \\textbf{0.9514} & 1.0614 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9649 & 0.9671 & 0.7893 & \\textbf{0.7950} \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{credit-g (2)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.6746} & \\textbf{0.7445} & 0.9425 & \\textbf{1.5730} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5790 & 0.7205 & 0.9445 & 1.6315 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6308 & 0.7385 & \\textbf{0.9500} & 1.6075 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.6551} & 0.7270 & 0.9520 & \\textbf{1.5980} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.6029 & 0.7275 & 0.9450 & 1.6900 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6368 & \\textbf{0.7410} & \\textbf{0.9535} & 1.6315 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.6746} & \\textbf{0.7445} & 0.8940 & \\textbf{1.4145} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5790 & 0.7205 & \\textbf{0.9445} & 1.6315 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6308 & 0.7385 & 0.9075 & 1.4295 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.6551} & 0.7270 & 0.9000 & \\textbf{1.4040} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.6029 & 0.7275 & \\textbf{0.9450} & 1.6900 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6368 & \\textbf{0.7410} & 0.9020 & 1.4250 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.6746} & \\textbf{0.7445} & 0.8180 & 1.1835 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5790 & 0.7205 & \\textbf{0.9445} & 1.6315 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6308 & 0.7385 & 0.8195 & \\textbf{1.1760} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.6551} & 0.7270 & 0.8010 & \\textbf{1.1465} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.6029 & 0.7275 & \\textbf{0.9450} & 1.6900 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.6368 & \\textbf{0.7410} & 0.8080 & 1.1485 \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{dermatology (6)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9790} & \\textbf{0.9797} & \\textbf{0.9838} & \\textbf{1.0284} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9637 & 0.9716 & 0.9554 & 3.2919 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9772 & 0.9784 & 0.9797 & 1.0392 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9692 & 0.9716 & 0.9527 & \\textbf{0.9703} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9570 & 0.9676 & 0.9554 & 3.5338 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9718} & \\textbf{0.9757} & \\textbf{0.9622} & 0.9797 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9790} & \\textbf{0.9797} & 0.9054 & \\textbf{0.9054} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9637 & 0.9716 & \\textbf{0.9554} & 3.2919 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9772 & 0.9784 & 0.9162 & 0.9257 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9692 & 0.9716 & 0.9176 & 0.9230 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9570 & 0.9676 & \\textbf{0.9554} & 3.5338 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9718} & \\textbf{0.9757} & 0.9149 & \\textbf{0.9189} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9790} & \\textbf{0.9797} & 0.8324 & 0.8324 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9637 & 0.9716 & \\textbf{0.9554} & 3.2919 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9772 & 0.9784 & 0.8257 & \\textbf{0.8257} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9692 & 0.9716 & 0.8365 & 0.8378 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9570 & 0.9676 & \\textbf{0.9554} & 3.5338 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9718} & \\textbf{0.9757} & 0.8351 & \\textbf{0.8351} \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{ecoli (8)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.8013} & \\textbf{0.8574} & 0.9647 & \\textbf{2.8588} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.7658 & 0.8382 & 0.9134 & 4.2794 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.7316 & 0.8562 & \\textbf{0.9788} & 3.4526 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7635} & \\textbf{0.8647} & 0.9706 & \\textbf{2.4265} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.7459 & 0.8317 & 0.9167 & 4.3938 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.7554 & 0.8611 & \\textbf{0.9722} & 2.8775 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.8013} & \\textbf{0.8574} & \\textbf{0.9588} & 2.0000 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.7658 & 0.8382 & 0.9134 & 4.2794 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.7316 & 0.8562 & 0.9379 & \\textbf{1.5703} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7635} & \\textbf{0.8647} & \\textbf{0.9279} & 1.4294 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.7459 & 0.8317 & 0.9167 & 4.3938 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.7554 & 0.8611 & 0.9167 & \\textbf{1.2925} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.8013} & \\textbf{0.8574} & 0.8485 & 1.0044 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.7658 & 0.8382 & \\textbf{0.9134} & 4.2794 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.7316 & 0.8562 & 0.8203 & \\textbf{0.9592} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.7635} & \\textbf{0.8647} & 0.8074 & 0.9206 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.7459 & 0.8317 & \\textbf{0.9167} & 4.3938 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.7554 & 0.8611 & 0.7958 & \\textbf{0.8987} \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{glass (6)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5535 & 0.6233 & 0.9349 & 2.6535 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5478 & 0.6535 & \\textbf{0.9395} & 4.4349 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6727} & \\textbf{0.7395} & 0.9116 & \\textbf{1.9837} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5369 & 0.6140 & 0.9581 & 2.9767 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5266 & 0.6186 & 0.9326 & 4.3953 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6717} & \\textbf{0.7233} & \\textbf{0.9674} & \\textbf{2.6093} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5535 & 0.6233 & 0.9349 & 2.6535 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5478 & 0.6535 & \\textbf{0.9395} & 4.4349 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6727} & \\textbf{0.7395} & 0.9116 & \\textbf{1.9837} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5369 & 0.6140 & 0.8791 & 2.0488 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5266 & 0.6186 & \\textbf{0.9326} & 4.3953 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6717} & \\textbf{0.7233} & 0.8651 & \\textbf{1.5930} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5535 & 0.6233 & 0.8023 & 1.6279 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5478 & 0.6535 & \\textbf{0.9395} & 4.4349 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6727} & \\textbf{0.7395} & 0.8000 & \\textbf{1.1791} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5369 & 0.6140 & 0.7698 & 1.5395 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5266 & 0.6186 & \\textbf{0.9326} & 4.3953 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6717} & \\textbf{0.7233} & 0.7860 & \\textbf{1.1488} \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{iris (3)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9570} & \\textbf{0.9567} & 0.8967 & \\textbf{0.9233} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9465 & 0.9433 & \\textbf{0.9400} & 1.2933 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9498 & 0.9467 & 0.9133 & 0.9667 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9617} & \\textbf{0.9600} & 0.9200 & \\textbf{0.9567} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9594 & 0.9600 & 0.9033 & 1.3567 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9478 & 0.9467 & \\textbf{0.9567} & 1.0533 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9570} & \\textbf{0.9567} & 0.8967 & \\textbf{0.9233} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9465 & 0.9433 & \\textbf{0.9400} & 1.2933 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9498 & 0.9467 & 0.9133 & 0.9667 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9617} & \\textbf{0.9600} & 0.8600 & \\textbf{0.8700} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9594 & 0.9600 & 0.9033 & 1.3567 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9478 & 0.9467 & \\textbf{0.9067} & 0.9367 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9570} & \\textbf{0.9567} & 0.7700 & \\textbf{0.7733} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9465 & 0.9433 & \\textbf{0.9400} & 1.2933 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9498 & 0.9467 & 0.8633 & 0.8833 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9617} & \\textbf{0.9600} & 0.7533 & \\textbf{0.7533} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9594 & 0.9600 & \\textbf{0.9033} & 1.3567 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9478 & 0.9467 & 0.7900 & 0.7967 \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{vehicle (4)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5683 & 0.5618 & 0.9541 & 2.6494 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5992 & 0.5953 & 0.9324 & 3.1271 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6044} & \\textbf{0.6018} & \\textbf{0.9606} & \\textbf{2.5476} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5656 & 0.5594 & 0.9676 & \\textbf{2.6741} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.5945} & 0.5894 & 0.9582 & 3.3653 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.5929 & \\textbf{0.5912} & \\textbf{0.9753} & 2.6771 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5683 & 0.5618 & 0.9259 & 2.3165 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5992 & 0.5953 & \\textbf{0.9324} & 3.1271 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6044} & \\textbf{0.6018} & 0.9224 & \\textbf{2.2206} \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5656 & 0.5594 & 0.9182 & 2.3018 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.5945} & 0.5894 & \\textbf{0.9582} & 3.3653 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.5929 & \\textbf{0.5912} & 0.9182 & \\textbf{2.2241} \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5683 & 0.5618 & 0.8129 & \\textbf{1.6818} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.5992 & 0.5953 & \\textbf{0.9324} & 3.1271 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.6044} & \\textbf{0.6018} & 0.8212 & 1.7071 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5656 & 0.5594 & 0.8106 & 1.7094 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.5945} & 0.5894 & \\textbf{0.9582} & 3.3653 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.5929 & \\textbf{0.5912} & 0.8094 & \\textbf{1.6971} \\\\\n",
      "\\cline{1-8} \\multirow{18}{*}{wine (3)} &  \\multirow{6}{*}{0.05} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9833 & 0.9833 & 0.9417 & \\textbf{0.9611} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9892} & \\textbf{0.9861} & 0.9278 & 1.4306 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9821 & 0.9778 & \\textbf{0.9528} & 0.9750 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9796 & \\textbf{0.9778} & 0.9528 & \\textbf{0.9778} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9818 & \\textbf{0.9778} & 0.9333 & 1.5667 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9821} & 0.9778 & \\textbf{0.9694} & 0.9944 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.1} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9833 & 0.9833 & 0.9417 & \\textbf{0.9611} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9892} & \\textbf{0.9861} & 0.9278 & 1.4306 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9821 & 0.9778 & \\textbf{0.9528} & 0.9750 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9796 & \\textbf{0.9778} & 0.8861 & \\textbf{0.8861} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9818 & \\textbf{0.9778} & \\textbf{0.9333} & 1.5667 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9821} & 0.9778 & 0.8944 & 0.9000 \\\\\n",
      "\\cline{2-8} &  \\multirow{6}{*}{0.2} &  \\multirow{3}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9833 & 0.9833 & 0.8028 & \\textbf{0.8028} \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9892} & \\textbf{0.9861} & \\textbf{0.9278} & 1.4306 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & 0.9821 & 0.9778 & 0.8250 & 0.8278 \\\\\n",
      "\\cline{3-8} &  &  \\multirow{3}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9796 & \\textbf{0.9778} & 0.7806 & 0.7806 \\\\\n",
      " &  &  &  \\multirow{1}{*}{plnet} & 0.9818 & \\textbf{0.9778} & \\textbf{0.9333} & 1.5667 \\\\\n",
      " &  &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9821} & 0.9778 & 0.7750 & \\textbf{0.7750} \\\\\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_with_lines(df, group_cols, value_cols, best_values):\n",
    "    \"\"\"Generate a LaTeX table with multirow entries, bold the best values, and add lines between consecutive multirows.\"\"\"\n",
    "    \n",
    "    def format_value(value, group, metric, max=True):\n",
    "        \"\"\"Format the value, making the highest value bold.\"\"\"\n",
    "        max_value = best_values.loc[\n",
    "            (best_values['dataset'] == group['dataset']) & \n",
    "            (best_values['alpha'] == group['alpha']) & \n",
    "            (best_values['fraction_cal_samples'] == group['fraction_cal_samples']), metric].values[0]\n",
    "        if value == max_value:\n",
    "            return f\"\\\\textbf{{{value:.4f}}}\"\n",
    "        else:\n",
    "            return f\"{value:.4f}\"\n",
    "    \n",
    "    def recursive_build(df, group_cols):\n",
    "        # if len(group_cols) == 1:\n",
    "            # Base case: only one group left, print it directly\n",
    "            latex_str = \"\"\n",
    "            prev_row = None\n",
    "            for row_id, row in df.iterrows():\n",
    "                latex_str_tmp = \"\"\n",
    "                col_id_list = []\n",
    "                for col_id, col in enumerate(group_cols):\n",
    "                    if prev_row is None or row[col] != prev_row[col]:\n",
    "                        col_id_list.append(col_id)\n",
    "                        filter_cols = group_cols[:col_id+1]\n",
    "                        indices = []\n",
    "                        values = []\n",
    "                        for fcol in filter_cols:\n",
    "                            indices.append(fcol)\n",
    "                            values.append(row[fcol])\n",
    "                        criteria = dict(zip(indices, values))\n",
    "                        # Filter the DataFrame using query\n",
    "                        mask = pd.Series([True] * len(df))\n",
    "\n",
    "                        # Iterate over criteria to apply conditions\n",
    "                        for key, value in criteria.items():\n",
    "                            mask = mask & (df[key] == value)\n",
    "\n",
    "                        # Filter the DataFrame\n",
    "                        filtered_df = df[mask]\n",
    "\n",
    "                        length = len(filtered_df)\n",
    "\n",
    "\n",
    "                        latex_str_tmp += f\" \\\\multirow{{{length}}}{{*}}{{{row[col]}}} & \"\n",
    "                        if col_id == len(group_cols) - 1:\n",
    "                            latex_str_tmp += \" & \".join([format_value(row[col], row, col) for col in value_cols]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "                        # if prev_row is not None and col_id < len(group_cols) - 1:\n",
    "                        # latex_str_tmp += \" \\\\\\\\ \\cline{%d-%d} \\\\\\\\\" % (col_id + 1, len(group_cols) + len(value_cols))\n",
    "\n",
    "                    else:\n",
    "                        latex_str_tmp += \" & \"\n",
    "                        if col_id == len(group_cols) - 1:\n",
    "                            latex_str_tmp += \" & \".join([format_value(row[col], row, col) for col in value_cols]) + \" \\\\\\\\\\n\"\n",
    "                if row_id > 0 and group_cols[min(col_id_list)] != \"model\":\n",
    "                    latex_str += \"\\\\cline{%d-%d}\" % (min(col_id_list)+1, len(group_cols) + len(value_cols))\n",
    "                latex_str += latex_str_tmp\n",
    "                indices = []\n",
    "                values = []\n",
    "                prev_row = row\n",
    "            return latex_str\n",
    "        \n",
    "    # Start recursive building\n",
    "    latex_body = recursive_build(df, group_cols)\n",
    "\n",
    "    # Complete LaTeX table\n",
    "    num_columns = len(group_cols) + len(value_cols)\n",
    "    col_format = 'l' * len(group_cols) + 'r' * len(value_cols)\n",
    "    latex_table = f\"\"\"\n",
    "\\\\begin{{tabular}}{{{col_format}}}\n",
    "\\\\toprule\n",
    "{' & '.join(group_cols)} & {' & '.join(value_cols)} \\\\\\\\\n",
    "\\\\midrule\n",
    "{latex_body}\n",
    "\\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "\"\"\"\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table with bold formatting and lines\n",
    "latex_table = generate_latex_table_with_lines(grouped_df, group_cols, metrics, best_values)\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "print(latex_table.replace(\"_\", \"\\_\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>alpha</th>\n",
       "      <th>fraction_cal_samples</th>\n",
       "      <th>model</th>\n",
       "      <th>score_bacc</th>\n",
       "      <th>score_acc</th>\n",
       "      <th>coverage_mean</th>\n",
       "      <th>efficiency_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.962440</td>\n",
       "      <td>0.963048</td>\n",
       "      <td>0.955721</td>\n",
       "      <td>0.986657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.929424</td>\n",
       "      <td>0.932836</td>\n",
       "      <td>0.950972</td>\n",
       "      <td>1.339303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.971482</td>\n",
       "      <td>0.972365</td>\n",
       "      <td>0.953279</td>\n",
       "      <td>0.968069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.959992</td>\n",
       "      <td>0.960742</td>\n",
       "      <td>0.953596</td>\n",
       "      <td>0.988331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.960163</td>\n",
       "      <td>0.960651</td>\n",
       "      <td>0.950339</td>\n",
       "      <td>1.217638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>1.430555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.982083</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.827778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.979583</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.780556</td>\n",
       "      <td>0.780556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.981816</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.566665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.982083</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset  alpha  fraction_cal_samples          model  \\\n",
       "0    PhishingWebsites (2)   0.05                   0.1  classifier_nn   \n",
       "1    PhishingWebsites (2)   0.05                   0.1          plnet   \n",
       "2    PhishingWebsites (2)   0.05                   0.1  random_forest   \n",
       "3    PhishingWebsites (2)   0.05                   0.2  classifier_nn   \n",
       "4    PhishingWebsites (2)   0.05                   0.2          plnet   \n",
       "..                    ...    ...                   ...            ...   \n",
       "175              wine (3)   0.20                   0.1          plnet   \n",
       "176              wine (3)   0.20                   0.1  random_forest   \n",
       "177              wine (3)   0.20                   0.2  classifier_nn   \n",
       "178              wine (3)   0.20                   0.2          plnet   \n",
       "179              wine (3)   0.20                   0.2  random_forest   \n",
       "\n",
       "     score_bacc  score_acc  coverage_mean  efficiency_mean  \n",
       "0      0.962440   0.963048       0.955721         0.986657  \n",
       "1      0.929424   0.932836       0.950972         1.339303  \n",
       "2      0.971482   0.972365       0.953279         0.968069  \n",
       "3      0.959992   0.960742       0.953596         0.988331  \n",
       "4      0.960163   0.960651       0.950339         1.217638  \n",
       "..          ...        ...            ...              ...  \n",
       "175    0.989167   0.986111       0.927778         1.430555  \n",
       "176    0.982083   0.977778       0.825000         0.827778  \n",
       "177    0.979583   0.977778       0.780556         0.780556  \n",
       "178    0.981816   0.977778       0.933333         1.566665  \n",
       "179    0.982083   0.977778       0.775000         0.775000  \n",
       "\n",
       "[180 rows x 8 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

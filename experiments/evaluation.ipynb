{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from py_experimenter.experimenter import PyExperimenter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import mysql.connector\n",
    "import openml\n",
    "\n",
    "\n",
    "from py_experimenter.database_connector_mysql import DatabaseConnectorMYSQL\n",
    "\n",
    "def connect(self):\n",
    "\n",
    "    db = mysql.connector.connect(\n",
    "        host=\"db01-kiml.kiml.ifi.lmu.de\",\n",
    "        user=\"jonas_h\",\n",
    "        password=\"thiswillnotactuallybevalidforverylongsodontcountonit\",\n",
    "        database=\"jonas_test\",\n",
    "        ssl_disabled=False,\n",
    "    )\n",
    "    return db\n",
    "\n",
    "\n",
    "def _start_transaction(self, connection, readonly=False):\n",
    "    if not readonly:\n",
    "        connection.start_transaction()\n",
    "\n",
    "\n",
    "DatabaseConnectorMYSQL.connect = connect\n",
    "DatabaseConnectorMYSQL._start_transaction = _start_transaction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:17:50,033  | py-experimenter - INFO     | Found 5 keyfields\n",
      "2024-10-17 15:17:50,035  | py-experimenter - INFO     | Found 9 resultfields\n",
      "2024-10-17 15:17:50,035  | py-experimenter - WARNING  | No logtables given\n",
      "2024-10-17 15:17:50,036  | py-experimenter - WARNING  | No custom section defined in config\n",
      "2024-10-17 15:17:50,036  | py-experimenter - WARNING  | No codecarbon section defined in config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:17:50,052  | py-experimenter - INFO     | Initialized and connected to database\n"
     ]
    }
   ],
   "source": [
    "experimenter = PyExperimenter(\n",
    "    experiment_configuration_file_path=\"./experiments/config/config.yml\",\n",
    ")\n",
    "exp_frame = experimenter.get_table()\n",
    "exp_frame = exp_frame[exp_frame.fraction_cal_samples >= 0.19999]\n",
    "exp_frame = exp_frame[exp_frame.openml_id != 39]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n",
      "/home/jonas/Documents/Research/dyad_ranking/torch_plnet/.venv/lib/python3.11/site-packages/openml/utils.py:461: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "datasets = {}\n",
    "num_classes = {}\n",
    "dataset_renamer = {}\n",
    "for id in exp_frame.openml_id.unique():\n",
    "    dataset = openml.datasets.get_dataset(id.item())\n",
    "    target_attribute = dataset.default_target_attribute\n",
    "    X, y, _, _ = dataset.get_data(target=target_attribute)\n",
    "    datasets[id] = dataset\n",
    "    dataset_renamer[id] = dataset.name\n",
    "    num_classes[id] = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "created    270\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_frame[exp_frame.model==\"plnet_cross_instance\"].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exp_frame\n",
    "\n",
    "exp_frame[\"dataset\"] =  exp_frame[\"openml_id\"].replace(dataset_renamer)\n",
    "exp_frame[\"num_classes\"] = exp_frame[\"openml_id\"].replace(num_classes)\n",
    "\n",
    "exp_frame[\"dataset\"] = exp_frame[\"dataset\"] + \" (\" + exp_frame[\"num_classes\"].astype(str) + \")\" \n",
    "\n",
    "# group_cols = ['dataset', 'alpha', 'fraction_cal_samples', 'model']\n",
    "group_cols = ['dataset', 'alpha', 'model']\n",
    "metrics_max = ['score_acc', 'coverage_mean']\n",
    "metrics_min = ['efficiency_mean']\n",
    "metrics = metrics_max + metrics_min\n",
    "\n",
    "grouped_df = df.groupby(group_cols).agg({metric: 'mean' for metric in metrics}).reset_index()\n",
    "agg_dict = {metric: 'max' for metric in metrics_max}\n",
    "agg_dict.update({metric: 'min' for metric in metrics_min})\n",
    "best_values = grouped_df.groupby(['dataset', 'alpha']).agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "dataset & alpha & model & score\\_acc & coverage\\_mean & efficiency\\_mean \\\\\n",
      "\\midrule\n",
      " \\multirow{12}{*}{PhishingWebsites (2)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.9614 & 0.9546 & 0.9888 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9607 & 0.9510 & 1.2198 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9709} & \\textbf{0.9552} & \\textbf{0.9734} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9611 & \\textbf{0.9058} & 0.9179 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9607 & 0.9039 & 1.0748 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9709} & 0.9031 & \\textbf{0.9106} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9599 & 0.8010 & \\textbf{0.8036} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9607 & \\textbf{0.8066} & 0.8929 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9709} & 0.8025 & 0.8058 \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{bank-marketing (2)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9046} & 0.9485 & \\textbf{1.1030} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.8835 & 0.9484 & 1.3721 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9016 & \\textbf{0.9511} & 1.1161 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9046} & 0.8975 & \\textbf{0.9864} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.8835 & \\textbf{0.8993} & 1.2356 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9021 & 0.8989 & 0.9943 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9046} & 0.8007 & \\textbf{0.8329} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.8835 & 0.7977 & 1.0275 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9024 & \\textbf{0.8018} & 0.8359 \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{breast-w (2)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9724} & 0.9536 & \\textbf{0.9776} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9693 & \\textbf{0.9579} & 1.0743 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9663 & 0.9541 & 0.9883 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9700} & 0.9093 & 0.9221 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9693 & \\textbf{0.9114} & 1.0007 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9671 & 0.8943 & \\textbf{0.9071} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9700} & 0.7979 & 0.8029 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9693 & \\textbf{0.8093} & 0.8764 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9671 & 0.7893 & \\textbf{0.7950} \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{credit-g (2)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.7270 & 0.9520 & \\textbf{1.5980} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.7275 & 0.9505 & 1.7080 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7279} & \\textbf{0.9554} & 1.6596 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.7270 & 0.9000 & \\textbf{1.4040} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.7275 & \\textbf{0.9115} & 1.5715 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7410} & 0.9020 & 1.4250 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.7270 & 0.8010 & \\textbf{1.1465} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.7275 & \\textbf{0.8215} & 1.3365 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7410} & 0.8080 & 1.1485 \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{dermatology (6)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.9716 & 0.9527 & \\textbf{0.9703} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9676 & 0.9554 & 3.5338 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9757} & \\textbf{0.9622} & 0.9797 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.9716 & 0.9176 & 0.9230 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9676 & \\textbf{0.9297} & 3.1662 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9757} & 0.9149 & \\textbf{0.9189} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.9718 & \\textbf{0.8364} & 0.8378 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9676 & 0.8230 & 2.4905 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9757} & 0.8351 & \\textbf{0.8351} \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{glass (6)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.6140 & 0.9581 & 2.9767 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.6186 & 0.9581 & 4.9349 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7233} & \\textbf{0.9674} & \\textbf{2.6093} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.6140 & 0.8791 & 2.0488 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.6186 & \\textbf{0.9070} & 3.8233 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7233} & 0.8651 & \\textbf{1.5930} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.6122 & 0.7693 & 1.5425 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.6186 & \\textbf{0.7977} & 2.7140 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.7233} & 0.7860 & \\textbf{1.1488} \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{iris (3)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9600} & 0.9200 & \\textbf{0.9567} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9600 & 0.9367 & 1.4233 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9524 & \\textbf{0.9405} & 1.0095 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9600} & 0.8600 & \\textbf{0.8700} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9600 & \\textbf{0.9100} & 1.3633 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9467 & 0.9067 & 0.9367 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9600} & 0.7533 & \\textbf{0.7533} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9600 & \\textbf{0.8033} & 1.2033 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9467 & 0.7900 & 0.7967 \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{vehicle (4)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.5594 & 0.9676 & \\textbf{2.6741} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.5894 & 0.9635 & 3.3965 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.5912} & \\textbf{0.9753} & 2.6771 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & 0.5596 & 0.9173 & 2.2972 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.5894 & 0.8971 & 3.1247 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.5912} & \\textbf{0.9182} & \\textbf{2.2241} \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & 0.5602 & \\textbf{0.8126} & 1.7122 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.5894 & 0.7947 & 2.6782 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.5912} & 0.8094 & \\textbf{1.6971} \\\\\n",
      "\\cline{1-6} \\multirow{12}{*}{wine (3)} &  \\multirow{4}{*}{0.05} &  \\multirow{1}{*}{classifier\\_nn} & 0.9778 & 0.9528 & \\textbf{0.9778} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & 0.9778 & 0.9528 & 1.6944 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & \\textbf{0.9841} & \\textbf{0.9782} & 0.9960 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.1} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9778} & 0.8861 & \\textbf{0.8861} \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9778} & \\textbf{0.9083} & 1.4250 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9778 & 0.8944 & 0.9000 \\\\\n",
      "\\cline{2-6} &  \\multirow{4}{*}{0.2} &  \\multirow{1}{*}{classifier\\_nn} & \\textbf{0.9778} & 0.7806 & 0.7806 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet} & \\textbf{0.9778} & \\textbf{0.8028} & 1.2028 \\\\\n",
      " &  &  \\multirow{1}{*}{plnet\\_cross\\_instance} & nan & nan & nan \\\\\n",
      " &  &  \\multirow{1}{*}{random\\_forest} & 0.9778 & 0.7750 & \\textbf{0.7750} \\\\\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_with_lines(df, group_cols, value_cols, best_values):\n",
    "    \"\"\"Generate a LaTeX table with multirow entries, bold the best values, and add lines between consecutive multirows.\"\"\"\n",
    "    \n",
    "    def format_value(value, group, metric, max=True):\n",
    "        \"\"\"Format the value, making the highest value bold.\"\"\"\n",
    "        max_value = best_values.loc[\n",
    "            (best_values['dataset'] == group['dataset']) & \n",
    "            (best_values['alpha'] == group['alpha']), metric].values[0]\n",
    "            # (best_values['fraction_cal_samples'] == group['fraction_cal_samples']), metric].values[0]\n",
    "        if value == max_value:\n",
    "            return f\"\\\\textbf{{{value:.4f}}}\"\n",
    "        else:\n",
    "            return f\"{value:.4f}\"\n",
    "    \n",
    "    def recursive_build(df, group_cols):\n",
    "        # if len(group_cols) == 1:\n",
    "            # Base case: only one group left, print it directly\n",
    "            latex_str = \"\"\n",
    "            prev_row = None\n",
    "            for row_id, row in df.iterrows():\n",
    "                latex_str_tmp = \"\"\n",
    "                col_id_list = []\n",
    "                for col_id, col in enumerate(group_cols):\n",
    "                    if prev_row is None or row[col] != prev_row[col]:\n",
    "                        col_id_list.append(col_id)\n",
    "                        filter_cols = group_cols[:col_id+1]\n",
    "                        indices = []\n",
    "                        values = []\n",
    "                        for fcol in filter_cols:\n",
    "                            indices.append(fcol)\n",
    "                            values.append(row[fcol])\n",
    "                        criteria = dict(zip(indices, values))\n",
    "                        # Filter the DataFrame using query\n",
    "                        mask = pd.Series([True] * len(df))\n",
    "\n",
    "                        # Iterate over criteria to apply conditions\n",
    "                        for key, value in criteria.items():\n",
    "                            mask = mask & (df[key] == value)\n",
    "\n",
    "                        # Filter the DataFrame\n",
    "                        filtered_df = df[mask]\n",
    "\n",
    "                        length = len(filtered_df)\n",
    "\n",
    "\n",
    "                        latex_str_tmp += f\" \\\\multirow{{{length}}}{{*}}{{{row[col]}}} & \"\n",
    "                        if col_id == len(group_cols) - 1:\n",
    "                            latex_str_tmp += \" & \".join([format_value(row[col], row, col) for col in value_cols]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "                        # if prev_row is not None and col_id < len(group_cols) - 1:\n",
    "                        # latex_str_tmp += \" \\\\\\\\ \\cline{%d-%d} \\\\\\\\\" % (col_id + 1, len(group_cols) + len(value_cols))\n",
    "\n",
    "                    else:\n",
    "                        latex_str_tmp += \" & \"\n",
    "                        if col_id == len(group_cols) - 1:\n",
    "                            latex_str_tmp += \" & \".join([format_value(row[col], row, col) for col in value_cols]) + \" \\\\\\\\\\n\"\n",
    "                if row_id > 0 and group_cols[min(col_id_list)] != \"model\":\n",
    "                    latex_str += \"\\\\cline{%d-%d}\" % (min(col_id_list)+1, len(group_cols) + len(value_cols))\n",
    "                latex_str += latex_str_tmp\n",
    "                indices = []\n",
    "                values = []\n",
    "                prev_row = row\n",
    "            return latex_str\n",
    "        \n",
    "    # Start recursive building\n",
    "    latex_body = recursive_build(df, group_cols)\n",
    "\n",
    "    # Complete LaTeX table\n",
    "    num_columns = len(group_cols) + len(value_cols)\n",
    "    col_format = 'l' * len(group_cols) + 'r' * len(value_cols)\n",
    "    latex_table = f\"\"\"\n",
    "\\\\begin{{tabular}}{{{col_format}}}\n",
    "\\\\toprule\n",
    "{' & '.join(group_cols)} & {' & '.join(value_cols)} \\\\\\\\\n",
    "\\\\midrule\n",
    "{latex_body}\n",
    "\\\\bottomrule\n",
    "\\\\end{{tabular}}\n",
    "\"\"\"\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table with bold formatting and lines\n",
    "latex_table = generate_latex_table_with_lines(grouped_df, group_cols, metrics, best_values)\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "print(latex_table.replace(\"_\", \"\\_\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>alpha</th>\n",
       "      <th>model</th>\n",
       "      <th>score_acc</th>\n",
       "      <th>coverage_mean</th>\n",
       "      <th>efficiency_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.961388</td>\n",
       "      <td>0.954638</td>\n",
       "      <td>0.988810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.960651</td>\n",
       "      <td>0.951018</td>\n",
       "      <td>1.219766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>plnet_cross_instance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.970873</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.973360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PhishingWebsites (2)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.961104</td>\n",
       "      <td>0.905765</td>\n",
       "      <td>0.917924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.10</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>classifier_nn</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.780556</td>\n",
       "      <td>0.780556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>plnet</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.802778</td>\n",
       "      <td>1.202778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>plnet_cross_instance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>wine (3)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset  alpha                 model  score_acc  \\\n",
       "0    PhishingWebsites (2)   0.05         classifier_nn   0.961388   \n",
       "1    PhishingWebsites (2)   0.05                 plnet   0.960651   \n",
       "2    PhishingWebsites (2)   0.05  plnet_cross_instance        NaN   \n",
       "3    PhishingWebsites (2)   0.05         random_forest   0.970873   \n",
       "4    PhishingWebsites (2)   0.10         classifier_nn   0.961104   \n",
       "..                    ...    ...                   ...        ...   \n",
       "103              wine (3)   0.10         random_forest   0.977778   \n",
       "104              wine (3)   0.20         classifier_nn   0.977778   \n",
       "105              wine (3)   0.20                 plnet   0.977778   \n",
       "106              wine (3)   0.20  plnet_cross_instance        NaN   \n",
       "107              wine (3)   0.20         random_forest   0.977778   \n",
       "\n",
       "     coverage_mean  efficiency_mean  \n",
       "0         0.954638         0.988810  \n",
       "1         0.951018         1.219766  \n",
       "2              NaN              NaN  \n",
       "3         0.955224         0.973360  \n",
       "4         0.905765         0.917924  \n",
       "..             ...              ...  \n",
       "103       0.894444         0.900000  \n",
       "104       0.780556         0.780556  \n",
       "105       0.802778         1.202778  \n",
       "106            NaN              NaN  \n",
       "107       0.775000         0.775000  \n",
       "\n",
       "[108 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
